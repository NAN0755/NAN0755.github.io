<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/sports-and-competition-32x.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/sports-and-competition-16x.png">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"zengzeyu.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":"valine","storage":true,"lazyload":true,"nav":null,"activeClass":"valine"},"algolia":{"appID":"IEEVBE18SX","apiKey":"2ed347de4115ebbf86b2fdb5ed80c2c3","indexName":"my_blog","hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="此系列为 PyTorch model 转 TRT engine 系列第三章。 至于为什么选 PyTorch 而不是 TensorFlow，是因为笔者对 PyTorch 最为熟悉，另外 PyTorch 的易用性和动态图特点，使得在学术界也广泛采用，新的模型更新也 release 较快。本文所用的开源项目包含：detectron2，ONNX，ONNX-simplifier，TensorRT。">
<meta property="og:type" content="article">
<meta property="og:title" content="TensorRT 教程（三）：PyTorch模型转ONNX模型">
<meta property="og:url" content="http://zengzeyu.com/2020/08/06/tensorrt_03_pytorch2onnx/index.html">
<meta property="og:site_name" content="Zeyu&#39;s Blog">
<meta property="og:description" content="此系列为 PyTorch model 转 TRT engine 系列第三章。 至于为什么选 PyTorch 而不是 TensorFlow，是因为笔者对 PyTorch 最为熟悉，另外 PyTorch 的易用性和动态图特点，使得在学术界也广泛采用，新的模型更新也 release 较快。本文所用的开源项目包含：detectron2，ONNX，ONNX-simplifier，TensorRT。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://zengzeyu.com/images/20_08_06/Screenshot-from-2020-07-21-17-49-57.png">
<meta property="article:published_time" content="2020-08-06T11:15:02.000Z">
<meta property="article:modified_time" content="2020-08-06T14:16:23.958Z">
<meta property="article:author" content="Zeyu">
<meta property="article:tag" content="DL">
<meta property="article:tag" content="CV">
<meta property="article:tag" content="TensorRT">
<meta property="article:tag" content="Model Deployment">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://zengzeyu.com/images/20_08_06/Screenshot-from-2020-07-21-17-49-57.png">

<link rel="canonical" href="http://zengzeyu.com/2020/08/06/tensorrt_03_pytorch2onnx/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>TensorRT 教程（三）：PyTorch模型转ONNX模型 | Zeyu's Blog</title>
  
    <script>
      function sendPageView() {
        if (CONFIG.hostname !== location.hostname) return;
        var uid = localStorage.getItem('uid') || (Math.random() + '.' + Math.random());
        localStorage.setItem('uid', uid);
        navigator.sendBeacon('https://www.google-analytics.com/collect', new URLSearchParams({
          v  : 1,
          tid: 'UA-172735623-1',
          cid: uid,
          t  : 'pageview',
          dp : encodeURIComponent(location.pathname)
        }));
      }
      document.addEventListener('pjax:complete', sendPageView);
      sendPageView();
    </script>


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?5bb12350481c6ccda395fbe33bd0dc13";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Zeyu's Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Zeyu's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">19</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">26</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://zengzeyu.com/2020/08/06/tensorrt_03_pytorch2onnx/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/bear.jpg">
      <meta itemprop="name" content="Zeyu">
      <meta itemprop="description" content="Done is better than perfect.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zeyu's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          TensorRT 教程（三）：PyTorch模型转ONNX模型
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-08-06 19:15:02" itemprop="dateCreated datePublished" datetime="2020-08-06T19:15:02+08:00">2020-08-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-08-06 22:16:23" itemprop="dateModified" datetime="2020-08-06T22:16:23+08:00">2020-08-06</time>
              </span>

          
            <span id="/2020/08/06/tensorrt_03_pytorch2onnx/" class="post-meta-item leancloud_visitors" data-flag-title="TensorRT 教程（三）：PyTorch模型转ONNX模型" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2020/08/06/tensorrt_03_pytorch2onnx/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/08/06/tensorrt_03_pytorch2onnx/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><em>此系列为 PyTorch model 转 TRT engine 系列第三章。</em></p>
<p>至于为什么选 PyTorch 而不是 TensorFlow，是因为笔者对 PyTorch 最为熟悉，另外 PyTorch 的易用性和动态图特点，使得在学术界也广泛采用，新的模型更新也 release 较快。本文所用的开源项目包含：<a href="https://github.com/facebookresearch/detectron2" target="_blank" rel="noopener">detectron2</a>，<a href="https://github.com/onnx/onnx" target="_blank" rel="noopener">ONNX</a>，<a href="https://github.com/daquexian/onnx-simplifier" target="_blank" rel="noopener">ONNX-simplifier</a>，<a href="https://github.com/NVIDIA/TensorRT" target="_blank" rel="noopener">TensorRT</a>。<a id="more"></a></p>
<h2 id="1-安装-ONNX"><a href="#1-安装-ONNX" class="headerlink" title="1. 安装 ONNX"></a>1. 安装 ONNX</h2><p>关于<a href="https://github.com/onnx/onnx" target="_blank" rel="noopener">ONNX</a>的介绍，请参见其官网。简单来说，ONNX 是一种充作中间转换的角色，将训练时候的不同开源库训练得到的model 转换成为不同的另一种 model 的表示方法。最常见的就是本文即将提到的 PyTorch 转 ONNX 再转 TensorRT 的工作方式。ONNX 本身还带有可运行的底层库 <a href="https://github.com/microsoft/onnxruntime" target="_blank" rel="noopener">ONNX runtime</a>，不过一般不使用。</p>
<p>考虑到我们后面对 ONNX 需要做一些自定义操作，因此建议源码安装，方便进行修改。在 <code>detectron2</code> 文件夹下新建文件夹 <code>thirdlibs</code>，进入文件夹运行如下命令：</p>
<ol>
<li>下载 ONNX： <code>git clone https://github.com/onnx/onnx.git</code></li>
<li>更新子模块： <code>cd onnx &amp;&amp; git submodule update --init --recursive</code></li>
<li>安装： <code>python setup.py develop  # 由于频繁更改，所以建议使用 develop，不使用 install</code></li>
<li>测试： <code>python -c &quot;import onnx&quot;</code></li>
</ol>
<p>如果不报错即安装成功。</p>
<h2 id="2-ResNet50-的-PyTorch-模型"><a href="#2-ResNet50-的-PyTorch-模型" class="headerlink" title="2. ResNet50 的 PyTorch 模型"></a>2. ResNet50 的 PyTorch 模型</h2><p>使用 detectron2 训练 Faster R-CNN 教程可参考<a href="https://github.com/facebookresearch/detectron2/blob/master/GETTING_STARTED.md#training--evaluation-in-command-line" target="_blank" rel="noopener">官网教程</a>，此处我们使用 detectron2  <a href="https://github.com/facebookresearch/detectron2/blob/master/MODEL_ZOO.md" target="_blank" rel="noopener">MODEL_ZOO</a> 中的已经训练好的 Faster R-CNN 模型，其Backbone 即为 ResNet50，<code>config</code> 文件为 detectron2 默认配置：<code>../configs/PascalVOC-Detection/faster_rcnn_R_50_FPN.yaml</code>。关于 Faster R-CNN 的网络结构可参看本站前一篇博文：Mask R-CNN 模型结构详解 。当然，我们也可以先不考虑数值的正确性，即我们只随机初始化模型之后并不训练网络，这样可以快速的测试 ONNX 和 TRT 对 op 的支持情况。通常在训练自己的数据期间，进行模型部署的开发，提高效率。</p>
<h2 id="3-PyTorch-模型转-ONNX-模型"><a href="#3-PyTorch-模型转-ONNX-模型" class="headerlink" title="3. PyTorch 模型转 ONNX 模型"></a>3. PyTorch 模型转 ONNX 模型</h2><p>Detectron2 在早先版本并不支持 Faster R-CNN 的转换，而且只支持转到 caffe2 模型。Caffe2 模型的转换也是通过 ONNX 作为媒介进行，这里使用 detectron2 转到 Caffe2 的中间ONNX模型，是因为 Caffe2 的中间转换做了很多 ONNX 的 model 图优化，对某些 op 进行了 merge。当然也可不使用该方式进行，使用 ONNX 源生的 op ，但是转换得到的 ONNX 模型可视化出来会有 op 没有进行优化。</p>
<h3 id="3-1-利用-Detectron2-自带-Caffe2-模型转换模块"><a href="#3-1-利用-Detectron2-自带-Caffe2-模型转换模块" class="headerlink" title="3.1 利用 Detectron2 自带 Caffe2 模型转换模块"></a>3.1 利用 Detectron2 自带 Caffe2 模型转换模块</h3><p>在 <code>detectron2/projects</code> 路径下新建文件夹命名为 <code>fasterrcnn_trt</code>，然后新建 python 文件<code>convert_fasterrcnn_onnx.py</code>，拷贝<code>detectron2/tools/deploy/caffe2_converter.py</code> 内容到该文件中，并对函数稍作修改如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    parser = argparse.ArgumentParser(description=<span class="string">"Convert a model to Caffe2"</span>)</span><br><span class="line">    parser.add_argument(<span class="string">"--config-file"</span>, default=<span class="string">""</span>, metavar=<span class="string">"FILE"</span>, help=<span class="string">"path to config file"</span>)</span><br><span class="line">    parser.add_argument(<span class="string">"--run-eval"</span>, action=<span class="string">"store_true"</span>)</span><br><span class="line">    parser.add_argument(<span class="string">"--output"</span>, help=<span class="string">"output directory for the converted caffe2 model"</span>)</span><br><span class="line">    parser.add_argument(</span><br><span class="line">        <span class="string">"opts"</span>,</span><br><span class="line">        help=<span class="string">"Modify config options using the command-line"</span>,</span><br><span class="line">        default=<span class="literal">None</span>,</span><br><span class="line">        nargs=argparse.REMAINDER,</span><br><span class="line">    )</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line">    logger = setup_logger()</span><br><span class="line">    logger.info(<span class="string">"Command line arguments: "</span> + str(args))</span><br><span class="line"></span><br><span class="line">    cfg = setup_cfg(args)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># create a torch model</span></span><br><span class="line">    torch_model = build_model(cfg)</span><br><span class="line">    DetectionCheckpointer(torch_model).resume_or_load(cfg.MODEL.WEIGHTS)</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>在<code>faster_rcnn_trt</code> 文件夹中运行如下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python convert_fasterrcnn_onnx.py --config-file ../../configs/PascalVOC-Detection/faster_rcnn_R_50_FPN.yaml --output ./onnx_model --run-eval MODEL.WEIGHTS detectron2://COCO-Detection/faster_rcnn_R_50_FPN_1x/137257794/model_final_b275ba.pkl MODEL.DEVICE cpu</span><br></pre></td></tr></table></figure>

<p>首先会从 MODEL_ZOO 中下载已经训练好的 Faster R-CNN 模型。然后进行 parse ，会看到输出的 log 信息，大致如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">......</span><br><span class="line"><span class="meta">%</span><span class="bash">318 : Float(1, 3, 800, 1216) = onnx::Cast[to=1](%316)</span></span><br><span class="line"><span class="meta"> %</span><span class="bash">319 : Float(1, 3, 800, 1216) = onnx::Sub(%318, %_wrapped_model.pixel_mean) </span></span><br><span class="line"><span class="meta"> %</span><span class="bash">320 : Float(1, 3, 800, 1216) = onnx::Div(%319, %_wrapped_model.pixel_std) </span></span><br><span class="line"><span class="meta"> %</span><span class="bash">input.1 : Float(1, 3, 800, 1216) = _caffe2::AliasWithName[name=<span class="string">"normalized_data"</span>, is_backward=0](%320) </span></span><br><span class="line"><span class="meta"> %</span><span class="bash">322 : Float(1, 64, 400, 608) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 7], pads=[3, 3, 3, 3], strides=[2, 2]](%input.1, %_wrapped_model.backbone.bottom_up.stem.conv1.weight) </span></span><br><span class="line"><span class="meta"> %</span><span class="bash">323 : Float(1, 64, 400, 608) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%322, %_wrapped_model.backbone.bottom_up.stem.conv1.norm.weight, %_wrapped_model.backbone.bottom_up.stem.conv1.norm.bias, %_wrapped_model.backbone.bottom_up.stem.conv1.norm.running_mean, %_wrapped_model.backbone.bottom_up.stem.conv1.norm.running_var) </span></span><br><span class="line"><span class="meta"> %</span><span class="bash">324 : Float(1, 64, 400, 608) = onnx::Relu(%323)</span></span><br><span class="line"><span class="meta"> %</span><span class="bash">325 : Float(1, 64, 200, 304) = onnx::MaxPool[kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%324) </span></span><br><span class="line"> ......</span><br></pre></td></tr></table></figure>

<p>我们可以用 <a href="https://github.com/lutzroeder/netron" target="_blank" rel="noopener">netron</a> 对生成的 ONNX 模型进行可视化：</p>
<p><img data-src="/images/20_08_06/Screenshot-from-2020-07-21-17-49-57.png"></p>
<h3 id="3-2-使用源生-ONNX-进行转换"><a href="#3-2-使用源生-ONNX-进行转换" class="headerlink" title="3.2 使用源生 ONNX 进行转换"></a>3.2 使用源生 ONNX 进行转换</h3><p>为了达到训练过程的友好，detectron2 在<code>forward</code>时对输入数据进行了封装，以其中一张图为例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[&#123;<span class="string">'file_name'</span>: <span class="string">'coco/val2017/000000000139.jpg'</span>, <span class="string">'height'</span>: <span class="number">426</span>, <span class="string">'width'</span>: <span class="number">640</span>, <span class="string">'image_id'</span>: <span class="number">139</span>, <span class="string">'image'</span>: tensor([[[ <span class="number">73</span>,  <span class="number">74</span>,  <span class="number">76</span>,  ...,  <span class="number">39</span>,  <span class="number">38</span>,  <span class="number">37</span>],</span><br><span class="line">         [ <span class="number">74</span>,  <span class="number">75</span>,  <span class="number">77</span>,  ...,  <span class="number">40</span>,  <span class="number">39</span>,  <span class="number">38</span>],</span><br><span class="line">         [ <span class="number">76</span>,  <span class="number">77</span>,  <span class="number">78</span>,  ...,  <span class="number">41</span>,  <span class="number">40</span>,  <span class="number">39</span>],</span><br><span class="line">         ...,</span><br><span class="line">         [<span class="number">152</span>, <span class="number">152</span>, <span class="number">153</span>,  ..., <span class="number">109</span>,  <span class="number">98</span>,  <span class="number">92</span>],</span><br><span class="line">         [<span class="number">151</span>, <span class="number">151</span>, <span class="number">152</span>,  ...,  <span class="number">76</span>,  <span class="number">67</span>,  <span class="number">62</span>],</span><br><span class="line">         [<span class="number">150</span>, <span class="number">150</span>, <span class="number">151</span>,  ...,  <span class="number">57</span>,  <span class="number">49</span>,  <span class="number">45</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">136</span>, <span class="number">138</span>, <span class="number">141</span>,  ...,  <span class="number">75</span>,  <span class="number">72</span>,  <span class="number">71</span>],</span><br><span class="line">         [<span class="number">137</span>, <span class="number">139</span>, <span class="number">142</span>,  ...,  <span class="number">76</span>,  <span class="number">73</span>,  <span class="number">72</span>],</span><br><span class="line">         [<span class="number">140</span>, <span class="number">141</span>, <span class="number">143</span>,  ...,  <span class="number">78</span>,  <span class="number">75</span>,  <span class="number">74</span>],</span><br><span class="line">         ...,</span><br><span class="line">         [<span class="number">183</span>, <span class="number">183</span>, <span class="number">184</span>,  ..., <span class="number">105</span>,  <span class="number">89</span>,  <span class="number">80</span>],</span><br><span class="line">         [<span class="number">183</span>, <span class="number">183</span>, <span class="number">184</span>,  ...,  <span class="number">72</span>,  <span class="number">62</span>,  <span class="number">55</span>],</span><br><span class="line">         [<span class="number">183</span>, <span class="number">183</span>, <span class="number">184</span>,  ...,  <span class="number">54</span>,  <span class="number">46</span>,  <span class="number">41</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">170</span>, <span class="number">171</span>, <span class="number">172</span>,  ...,  <span class="number">68</span>,  <span class="number">69</span>,  <span class="number">70</span>],</span><br><span class="line">         [<span class="number">171</span>, <span class="number">172</span>, <span class="number">173</span>,  ...,  <span class="number">69</span>,  <span class="number">70</span>,  <span class="number">70</span>],</span><br><span class="line">         [<span class="number">172</span>, <span class="number">173</span>, <span class="number">174</span>,  ...,  <span class="number">71</span>,  <span class="number">71</span>,  <span class="number">71</span>],</span><br><span class="line">         ...,</span><br><span class="line">         [<span class="number">186</span>, <span class="number">186</span>, <span class="number">187</span>,  ..., <span class="number">181</span>, <span class="number">176</span>, <span class="number">173</span>],</span><br><span class="line">         [<span class="number">186</span>, <span class="number">186</span>, <span class="number">187</span>,  ..., <span class="number">144</span>, <span class="number">136</span>, <span class="number">131</span>],</span><br><span class="line">         [<span class="number">186</span>, <span class="number">186</span>, <span class="number">187</span>,  ..., <span class="number">123</span>, <span class="number">113</span>, <span class="number">107</span>]]], dtype=torch.uint8)&#125;]</span><br></pre></td></tr></table></figure>

<p>如果直接使用上面输出导出 ONNX 模型，会遇到如下错误：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">RuntimeError: Only tuples, lists <span class="keyword">and</span> Variables supported <span class="keyword">as</span> JIT inputs/outputs. Dictionaries <span class="keyword">and</span> strings are also accepted but their usage <span class="keyword">is</span> <span class="keyword">not</span> recommended. But got unsupported type int</span><br></pre></td></tr></table></figure>

<p>因此，需要对 detectron2 进行定制化修改，使其适应 ONNX 模型的导出要求。</p>
<p>需要做的工作：</p>
<ol>
<li>修改 detectron2 build 模型时的接口，使 <code>forward</code>过程输入不需要支持输入 image 的 <code>filename</code>等值</li>
<li>修改 input ，使 input 为列表或字典，包括以下信息： feature map，image size，缩放比例信息</li>
</ol>
<p>以 backbone ResNet50 为例：</p>
<p>首先新建 class ：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResNet50</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, cfg, torch_model)</span>:</span></span><br><span class="line">        selfcfg = cfg</span><br><span class="line">        self.model = torch_model</span><br><span class="line">        self.eval()</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, input)</span>:</span></span><br><span class="line">        images = input[<span class="string">"images"</span>]</span><br><span class="line">        features = self.model.backbone(images)</span><br><span class="line">        <span class="keyword">return</span> features</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">convert_input</span><span class="params">(self, inputs)</span>:</span></span><br><span class="line">        images = self.model.preprocess_image(batched_inputs)</span><br><span class="line">        min_size = <span class="number">800</span></span><br><span class="line">        max_size = <span class="number">1333</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(batched_inputs)):</span><br><span class="line">            s = max(batched_inputs[i][<span class="string">"height"</span>] * <span class="number">1.0</span> / min_size,</span><br><span class="line">                    batched_inputs[i][<span class="string">"width"</span>] * <span class="number">1.0</span> / max_size)</span><br><span class="line">            scales.append((s,))</span><br><span class="line">        im_info = []</span><br><span class="line">        <span class="keyword">for</span> image_size, scale <span class="keyword">in</span> zip(images.image_sizes, scales):</span><br><span class="line">            im_info.append([*image_size, *scale])</span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">"images"</span>: images.tensor,</span><br><span class="line">            <span class="string">"image_sizes"</span>: torch.tensor(images.image_sizes),</span><br><span class="line">            <span class="string">"im_info"</span>: torch.tensor(im_info, device=images.tensor.device),</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>

<p>经过以上修改，即可导出 ONNX 源生 model。或者更改 ONNX 默认输入方式，使其支持 detectron2 的输入类型。</p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>本文介绍了 ONNX 和在 detectron2 框架下导出 Faster R-CNN ONNX 模型的两种方式。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ol>
<li><a href="https://github.com/onnx/onnx" target="_blank" rel="noopener">ONNX</a></li>
<li><a href="https://github.com/pytorch/pytorch" target="_blank" rel="noopener">PyTorch</a></li>
<li><a href="%5Bhttp://lierhua.top/2018/01/15/%E5%BD%92%E6%A1%A3/Python%E5%8F%91%E5%B8%83%E5%B7%A5%E5%85%B7setuptools%E7%9A%84%E7%94%A8%E6%B3%95/%5D(http://lierhua.top/2018/01/15/%E5%BD%92%E6%A1%A3/Python%E5%8F%91%E5%B8%83%E5%B7%A5%E5%85%B7setuptools%E7%9A%84%E7%94%A8%E6%B3%95/)">Python发布工具setuptools的用法</a></li>
<li><a href="https://github.com/facebookresearch/detectron2/blob/master/MODEL_ZOO.md" target="_blank" rel="noopener">detectron2 MODEL_ZOO</a></li>
</ol>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/DL/" rel="tag"># DL</a>
              <a href="/tags/CV/" rel="tag"># CV</a>
              <a href="/tags/TensorRT/" rel="tag"># TensorRT</a>
              <a href="/tags/Model-Deployment/" rel="tag"># Model Deployment</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/07/09/tensorrt_02_introduction/" rel="prev" title="TensorRT 教程（二）：TensorRT 源码简介">
      <i class="fa fa-chevron-left"></i> TensorRT 教程（二）：TensorRT 源码简介
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-安装-ONNX"><span class="nav-text">1. 安装 ONNX</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-ResNet50-的-PyTorch-模型"><span class="nav-text">2. ResNet50 的 PyTorch 模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-PyTorch-模型转-ONNX-模型"><span class="nav-text">3. PyTorch 模型转 ONNX 模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-利用-Detectron2-自带-Caffe2-模型转换模块"><span class="nav-text">3.1 利用 Detectron2 自带 Caffe2 模型转换模块</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-使用源生-ONNX-进行转换"><span class="nav-text">3.2 使用源生 ONNX 进行转换</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Conclusion"><span class="nav-text">Conclusion</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Reference"><span class="nav-text">Reference</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zeyu"
      src="/images/bear.jpg">
  <p class="site-author-name" itemprop="name">Zeyu</p>
  <div class="site-description" itemprop="description">Done is better than perfect.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
        
          <span class="site-state-item-count">26</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags">
          
        <span class="site-state-item-count">19</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zeyu-hello" title="GitHub → https://github.com/zeyu-hello" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zengzeyu@hotmail.com" title="E-mail → mailto:zengzeyu@hotmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-mail</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2017 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="bug"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ZYU</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>






<script>
  (function() {
    function leancloudSelector(url) {
      url = encodeURI(url);
      return document.getElementById(url).querySelector('.leancloud-visitors-count');
    }

    function addCount(Counter) {
      var visitors = document.querySelector('.leancloud_visitors');
      var url = decodeURI(visitors.id);
      var title = visitors.dataset.flagTitle;

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url })))
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length > 0) {
            var counter = results[0];
            leancloudSelector(url).innerText = counter.time + 1;
            Counter('put', '/classes/Counter/' + counter.objectId, { time: { '__op': 'Increment', 'amount': 1 } })
              .catch(error => {
                console.error('Failed to save visitor count', error);
              });
          } else {
              Counter('post', '/classes/Counter', { title, url, time: 1 })
                .then(response => response.json())
                .then(() => {
                  leancloudSelector(url).innerText = 1;
                })
                .catch(error => {
                  console.error('Failed to create', error);
                });
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    function showTime(Counter) {
      var visitors = document.querySelectorAll('.leancloud_visitors');
      var entries = [...visitors].map(element => {
        return decodeURI(element.id);
      });

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url: { '$in': entries } })))
        .then(response => response.json())
        .then(({ results }) => {
          for (let url of entries) {
            let target = results.find(item => item.url === url);
            leancloudSelector(url).innerText = target ? target.time : 0;
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    let { app_id, app_key, server_url } = {"enable":true,"app_id":"g992xG0S8k31XQHoAEAhRQbE-gzGzoHsz","app_key":"BdWgkDuuoBKUAUvH1b0e3RJF","server_url":null,"security":false};
    function fetchData(api_server) {
      var Counter = (method, url, data) => {
        return fetch(`${api_server}/1.1${url}`, {
          method,
          headers: {
            'X-LC-Id'     : app_id,
            'X-LC-Key'    : app_key,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      if (CONFIG.page.isPost) {
        if (CONFIG.hostname !== location.hostname) return;
        addCount(Counter);
      } else if (document.querySelectorAll('.post-title-link').length >= 1) {
        showTime(Counter);
      }
    }

    let api_server = app_id.slice(-9) !== '-MdYXbMMI' ? server_url : `https://${app_id.slice(0, 8).toLowerCase()}.api.lncldglobal.com`;

    if (api_server) {
      fetchData(api_server);
    } else {
      fetch('https://app-router.leancloud.cn/2/route?appId=' + app_id)
        .then(response => response.json())
        .then(({ api_server }) => {
          fetchData('https://' + api_server);
        });
    }
  })();
</script>


      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  
  <script>
    (function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();
  </script>




  
<script src="/js/local-search.js"></script>













  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : true,
      appId      : 'g992xG0S8k31XQHoAEAhRQbE-gzGzoHsz',
      appKey     : 'BdWgkDuuoBKUAUvH1b0e3RJF',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : true,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
