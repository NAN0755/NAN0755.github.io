<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"zengzeyu.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":"valine","storage":true,"lazyload":true,"nav":null,"activeClass":"valine"},"algolia":{"appID":"IEEVBE18SX","apiKey":"2ed347de4115ebbf86b2fdb5ed80c2c3","indexName":"my_blog","hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="FCN(fully convolutional networks，全卷积神经网络)的图片语义分割（semantic segmentation）论文：Fully Convolutional Networks for Semantic Segmentation。全卷积网络首现于这篇文章。这篇文章是将CNN结构应用到图像语义分割领域并取得突出结果的开山之作，因而拿到了CVPR 2015年的Best pa">
<meta property="og:type" content="article">
<meta property="og:title" content="FCN-PCL 应用解析">
<meta property="og:url" content="http://zengzeyu.com/2018/03/15/fcn_alexnet_pcl/index.html">
<meta property="og:site_name" content="Zeyu&#39;s Blog">
<meta property="og:description" content="FCN(fully convolutional networks，全卷积神经网络)的图片语义分割（semantic segmentation）论文：Fully Convolutional Networks for Semantic Segmentation。全卷积网络首现于这篇文章。这篇文章是将CNN结构应用到图像语义分割领域并取得突出结果的开山之作，因而拿到了CVPR 2015年的Best pa">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/10028058-453277040a9c3cc9.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/10028058-5b105644ace02a05.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/10028058-39bef235c497ef5b.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/10028058-f14bf66059d90048.gif?imageMogr2/auto-orient/strip">
<meta property="article:published_time" content="2018-03-15T15:47:44.000Z">
<meta property="article:modified_time" content="2020-07-15T04:56:16.179Z">
<meta property="article:author" content="Zeyu">
<meta property="article:tag" content="DL">
<meta property="article:tag" content="PCL">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://upload-images.jianshu.io/upload_images/10028058-453277040a9c3cc9.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">

<link rel="canonical" href="http://zengzeyu.com/2018/03/15/fcn_alexnet_pcl/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>FCN-PCL 应用解析 | Zeyu's Blog</title>
  
    <script>
      function sendPageView() {
        if (CONFIG.hostname !== location.hostname) return;
        var uid = localStorage.getItem('uid') || (Math.random() + '.' + Math.random());
        localStorage.setItem('uid', uid);
        navigator.sendBeacon('https://www.google-analytics.com/collect', new URLSearchParams({
          v  : 1,
          tid: 'UA-172735623-1',
          cid: uid,
          t  : 'pageview',
          dp : encodeURIComponent(location.pathname)
        }));
      }
      document.addEventListener('pjax:complete', sendPageView);
      sendPageView();
    </script>


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?5bb12350481c6ccda395fbe33bd0dc13";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Zeyu's Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Zeyu's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">19</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">25</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://zengzeyu.com/2018/03/15/fcn_alexnet_pcl/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/bear.jpg">
      <meta itemprop="name" content="Zeyu">
      <meta itemprop="description" content="Done is better than perfect.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zeyu's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          FCN-PCL 应用解析
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-03-15 23:47:44" itemprop="dateCreated datePublished" datetime="2018-03-15T23:47:44+08:00">2018-03-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-07-15 12:56:16" itemprop="dateModified" datetime="2020-07-15T12:56:16+08:00">2020-07-15</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/DL/" itemprop="url" rel="index"><span itemprop="name">DL</span></a>
                </span>
            </span>

          
            <span id="/2018/03/15/fcn_alexnet_pcl/" class="post-meta-item leancloud_visitors" data-flag-title="FCN-PCL 应用解析" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2018/03/15/fcn_alexnet_pcl/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2018/03/15/fcn_alexnet_pcl/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>FCN(fully convolutional networks，全卷积神经网络)的图片语义分割（semantic segmentation）论文：<a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf" target="_blank" rel="noopener">Fully Convolutional Networks for Semantic Segmentation</a>。全卷积网络首现于这篇文章。这篇文章是将CNN结构应用到图像语义分割领域并取得突出结果的开山之作，因而拿到了CVPR 2015年的Best paper honorable mention。图像语义分割，简而言之就是对一张图片上的所有像素点进行分类。<a id="more"></a>如下图就是一个语义分割例子，不同颜色像素代表不同类别：</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/10028058-453277040a9c3cc9.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="原图"><br><img data-src="http://upload-images.jianshu.io/upload_images/10028058-5b105644ace02a05.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="语义分割（semantic segmentation）"></p>
<p>UCB的FCN源码Github地址：<a href="https://github.com/shelhamer/fcn.berkeleyvision.org" target="_blank" rel="noopener">https://github.com/shelhamer/fcn.berkeleyvision.org</a><br>源码中一共包含了4种网络结构模型：*<strong>nyud-fcn**<em>、</em></strong>pascalcontext-fcn*<strong>、**<em>siftflow-fcn</em></strong>、*<strong>voc-fcn**<em>。每一种网络结构根据提取卷积层不同，又分了3-4个不等的网络类别。<br>工作中个人的数据类型和格式不一定与</em></strong>voc-fcn-alexnet*<strong>源代码提供的数据接口相同或类似（图片），如本文接下来要输入网络模型的数据类型为由激光雷达（LiDAR）扫描得到的点云数据（**<em>.pcd</em></strong>），那么如何进行实际操作呢？下面一步一步进行。</p>
<h2 id="1-激光雷达数据转换"><a href="#1-激光雷达数据转换" class="headerlink" title="1. 激光雷达数据转换"></a>1. 激光雷达数据转换</h2><hr>
<h3 id="1-1-激光雷达点云数据介绍"><a href="#1-1-激光雷达点云数据介绍" class="headerlink" title="1.1 激光雷达点云数据介绍"></a>1.1 激光雷达点云数据介绍</h3><p>首先介绍机械式旋转激光雷达生成的数据格式，激光雷达内部电机以一定角速度旋转，通过固定于其上的激光发射器和激光接收器测量激光雷达到障碍物的距离。以速腾聚创公司生产的16线激光雷达<a href="http://www.robosense.cn/rslidar/RS-LiDAR-16" target="_blank" rel="noopener">RS-LiDAR-16</a>为例，每秒进行10次360°旋转(10Hz)，每次旋转扫描得到周围场景的信息，每一线激光旋转一周得到2016个点，储存在 <strong><em>.pcd</em></strong> 格式文件中。以二维彩色图像的方式（如*<strong>.png**<em>）来理解</em></strong>.pcd*<strong>文件，16线代表图片高度，2016代表图片宽度，一共16x2016=32256个像素点。每个点 **<em>point</em></strong> 的数据有[*<strong>x***, *</strong>y*<strong>, **<em>z</em></strong>, <strong><em>intensity</em></strong>]，与二维图片中的RGB通道（RGB chanel）是同样的道理，每一个数据代表一个通道。</p>
<p><img data-src="https://upload-images.jianshu.io/upload_images/10028058-39bef235c497ef5b.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="速腾聚创 RS-LiDAR-16"></p>
<p><img data-src="https://upload-images.jianshu.io/upload_images/10028058-f14bf66059d90048.gif?imageMogr2/auto-orient/strip" alt="激光雷达点云示意图"></p>
<h3 id="1-2-点云预处理"><a href="#1-2-点云预处理" class="headerlink" title="1.2 点云预处理"></a>1.2 点云预处理</h3><p>根据点云数据特征属性对其进行预处理，每个 <strong><em>point</em></strong> 的处理后特征有[*<strong>row***, *</strong>column*<strong>, **<em>height</em></strong>, <strong><em>range</em></strong>, <strong><em>mark</em></strong>]分别代表 <strong><em>point</em></strong> 的：[*<strong>行序号***， *</strong>列标号*<strong>， **<em>高度</em></strong>， <strong><em>距离</em></strong>， <strong><em>属性</em></strong>]，其中 <strong><em>height</em></strong> 与 <strong><em>z</em></strong> 值相等，*<strong>range*** 由 *</strong>sqrt(x^2 + y^2 + z^2)<strong>* 计算得出， *</strong>mark*** 为通过决策树（Decision tree）方式对 <strong><em>point</em></strong> 进行分类得到属性：障碍物点（obstacle mark）或地面点（ground mark），与ground true图片道理相同，作为训练预测分类的结果参考标准用于计算loss。这里作用相当于，人工添加了更多的特征通道，方便进行分类和预测。<br>以上预处理得到的数据通过<strong>cnpy</strong>库转换为 <strong><em>.npy</em></strong> 格式的二进制文件，方便NumPy对数据进行读取，<strong>cnpy</strong>库使用教程请移步：<a href="https://www.jianshu.com/p/a35d5f62f164" target="_blank" rel="noopener">cnpy库使用笔记</a>以及<a href="https://link.jianshu.com/?t=https%253A%252F%252Fgithub.com%252Frogersce%252Fcnpy%252Fblob%252Fmaster%252Fexample1.cpp" target="_blank" rel="noopener">官方example</a>。每一帧点云数据储存为一个 <strong><em>.npy</em></strong> 格式文件，命名方式越简单越好，方便读取排序，本文直接以序号作为文件名**[0.npy, 1.npy, …, n.npy ]**。</p>
<h2 id="2-FCN-AlexNet的点云数据分类任务"><a href="#2-FCN-AlexNet的点云数据分类任务" class="headerlink" title="2. FCN-AlexNet的点云数据分类任务"></a>2. FCN-AlexNet的点云数据分类任务</h2><hr>
<p><strong>FCN-AlexNet的点云数据分类任务工程包含：</strong></p>
<ul>
<li>5个<strong>Python</strong>文件： <strong>pcl_data_layer.py</strong>， <strong>net.py</strong>， <strong>solver.py</strong>， <strong>surgery.py</strong>， <strong>score.py</strong></li>
<li>3个<strong>prototxt</strong>文件: <strong>train.prototxt</strong>， <strong>val.prototxt</strong>， <strong>solver.prototxt</strong></li>
<li>1个<strong>caffe_model</strong>文件： <strong>fcn-alexnet-pascal.caffemodel</strong></li>
</ul>
<h3 id="2-1-FCN-AlexNet读取数据层（Data-layer）"><a href="#2-1-FCN-AlexNet读取数据层（Data-layer）" class="headerlink" title="2.1 FCN-AlexNet读取数据层（Data layer）"></a>2.1 FCN-AlexNet读取数据层（Data layer）</h3><p>文件命名为<strong>pcl_data_layer.py</strong>，该文件内包含<code>class PCLSegDataLayer()</code>类函数：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">import caffe</span><br><span class="line">import numpy as np</span><br><span class="line">import random</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">class PCLSegDataLayer(caffe.Layer):</span><br><span class="line"></span><br><span class="line">    def setup(self, bottom, top):</span><br><span class="line"></span><br><span class="line">        params &#x3D; eval(self.param_str)</span><br><span class="line">        self.npy_dir &#x3D; params[&quot;pcl_dir&quot;]</span><br><span class="line">        self.list_name &#x3D; list()</span><br><span class="line"></span><br><span class="line">        # two tops: data and label</span><br><span class="line">        if len(top) !&#x3D; 2:</span><br><span class="line">            raise Exception(&quot;Need to define two tops: data and label.&quot;)</span><br><span class="line">        # data layers have no bottoms</span><br><span class="line">        if len(bottom) !&#x3D; 0:</span><br><span class="line">            raise Exception(&quot;Do not define a bottom.&quot;)</span><br><span class="line"></span><br><span class="line">        self.load_file_name( self.npy_dir, self.list_name )</span><br><span class="line">        self.idx &#x3D; 0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def reshape(self, bottom, top):</span><br><span class="line">        self.data, self.label &#x3D; self.load_file( self.idx )</span><br><span class="line">        # reshape tops to fit (leading 1 is for batch dimension)</span><br><span class="line">        top[0].reshape(1, *self.data.shape)</span><br><span class="line">        top[1].reshape(1, *self.label.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def forward(self, bottom, top):</span><br><span class="line">        # assign output</span><br><span class="line">        top[0].data[...] &#x3D; self.data</span><br><span class="line">        top[1].data[...] &#x3D; self.label</span><br><span class="line"></span><br><span class="line">        # pick next input</span><br><span class="line">        self.idx +&#x3D; 1</span><br><span class="line">        if self.idx &#x3D;&#x3D; len(self.list_name):</span><br><span class="line">            self.idx &#x3D; 0</span><br><span class="line"></span><br><span class="line">    def backward(self, top, propagate_down, bottom):</span><br><span class="line">        pass</span><br><span class="line"></span><br><span class="line">    def load_file(self, idx):</span><br><span class="line">        in_file &#x3D; np.load(self.list_name[idx]) #[mark, row, col, height, range]</span><br><span class="line">        in_data &#x3D; in_file[:,:,1:-1]</span><br><span class="line">        in_data &#x3D; in_data.transpose((2, 0, 1))</span><br><span class="line">        in_label &#x3D; in_file[:,:,0]</span><br><span class="line">        return in_data, in_label</span><br><span class="line"></span><br><span class="line">    def load_file_name(self, path, list_name):</span><br><span class="line">        for file in os.listdir(path):</span><br><span class="line">            file_path &#x3D; os.path.join(path, file)</span><br><span class="line">            if os.path.isdir(file_path):</span><br><span class="line">                os.listdir(file_path, list_name)</span><br><span class="line">            else:</span><br><span class="line">                list_name.append(file_path)</span><br></pre></td></tr></table></figure>
<ul>
<li>setup()： 建立类时的参数</li>
<li>reshape()： 根据输入调整模型入口大小</li>
<li>forward()： 前向传播，由于是数据输入层，所以输出为原点云数据及其分类label</li>
<li>backward()： 后向传播，数据层没有后向传播，所以舍弃</li>
<li>load_file_name()： 读取指定文件夹内 <strong><em>.npy</em></strong> 格式文件并储存如列表list</li>
<li>load_file()： 载入单个**<em>.npy**</em> 文件，并按照储存顺序对属性进行分类，输出data和label</li>
</ul>
<h3 id="2-2-FCN-AlexNet模型定义函数（net-py）"><a href="#2-2-FCN-AlexNet模型定义函数（net-py）" class="headerlink" title="2.2 FCN-AlexNet模型定义函数（net.py）"></a>2.2 FCN-AlexNet模型定义函数（net.py）</h3><p><strong>net.py</strong>文件用于生成<strong>net.prototxt</strong>文件，其定义了整个模型的结构和模型每层的各个参数。当然，模型网络结构可以利用官方已经训练好的<strong>fcn-alexnet-pascal.caffemodel</strong>来导出，也可以使用<strong>net.py</strong>自己生成，为了简化操作，本文使用<strong>fcn-alexnet-pascal.caffemodel</strong>来导出模型网络结构。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line">sys.path.append(&#39;..&#x2F;..&#x2F;python&#39;)</span><br><span class="line"></span><br><span class="line">import caffe</span><br><span class="line">from caffe import layers as L, params as P</span><br><span class="line">from caffe.coord_map import crop</span><br><span class="line"></span><br><span class="line">def conv_relu(bottom, ks, nout, stride&#x3D;1, pad&#x3D;0, group&#x3D;1):</span><br><span class="line">    conv &#x3D; L.Convolution(bottom, kernel_size&#x3D;ks, stride&#x3D;stride,</span><br><span class="line">                                num_output&#x3D;nout, pad&#x3D;pad, group&#x3D;group)</span><br><span class="line">    return conv, L.ReLU(conv, in_place&#x3D;True)</span><br><span class="line"></span><br><span class="line">def max_pool(bottom, ks, stride&#x3D;1):</span><br><span class="line">    return L.Pooling(bottom, pool&#x3D;P.Pooling.MAX, kernel_size&#x3D;ks, stride&#x3D;stride)</span><br><span class="line"></span><br><span class="line">def fcn(split):</span><br><span class="line">    n &#x3D; caffe.NetSpec()</span><br><span class="line">    pydata_params &#x3D; dict()</span><br><span class="line">    pydata_params[&#39;pcl_dir&#39;] &#x3D; &#39;..&#x2F;fcn_data_gen&#x2F;data&#x2F;npy&#39; #.npy files path</span><br><span class="line">    pylayer &#x3D; &#39;PCLSegDataLayer&#39;</span><br><span class="line">    n.data, n.label &#x3D; L.Python(module&#x3D;&#39;pcl_data_layer&#39;, layer&#x3D;pylayer,</span><br><span class="line">            ntop&#x3D;2, param_str&#x3D;str(pydata_params))</span><br><span class="line"></span><br><span class="line">    # the base net</span><br><span class="line">    n.conv1, n.relu1 &#x3D; conv_relu(n.data, 11, 96, stride&#x3D;4, pad&#x3D;100)</span><br><span class="line">    n.pool1 &#x3D; max_pool(n.relu1, 3, stride&#x3D;2)</span><br><span class="line">    n.norm1 &#x3D; L.LRN(n.pool1, local_size&#x3D;5, alpha&#x3D;1e-4, beta&#x3D;0.75)</span><br><span class="line">    n.conv2, n.relu2 &#x3D; conv_relu(n.norm1, 5, 256, pad&#x3D;2, group&#x3D;2)</span><br><span class="line">    n.pool2 &#x3D; max_pool(n.relu2, 3, stride&#x3D;2)</span><br><span class="line">    n.norm2 &#x3D; L.LRN(n.pool2, local_size&#x3D;5, alpha&#x3D;1e-4, beta&#x3D;0.75)</span><br><span class="line">    n.conv3, n.relu3 &#x3D; conv_relu(n.norm2, 3, 384, pad&#x3D;1)</span><br><span class="line">    n.conv4, n.relu4 &#x3D; conv_relu(n.relu3, 3, 384, pad&#x3D;1, group&#x3D;2)</span><br><span class="line">    n.conv5, n.relu5 &#x3D; conv_relu(n.relu4, 3, 256, pad&#x3D;1, group&#x3D;2)</span><br><span class="line">    n.pool5 &#x3D; max_pool(n.relu5, 3, stride&#x3D;2)</span><br><span class="line"></span><br><span class="line">    # fully conv</span><br><span class="line">    n.fc6, n.relu6 &#x3D; conv_relu(n.pool5, 6, 4096)</span><br><span class="line">    n.drop6 &#x3D; L.Dropout(n.relu6, dropout_ratio&#x3D;0.5, in_place&#x3D;True)</span><br><span class="line">    n.fc7, n.relu7 &#x3D; conv_relu(n.drop6, 1, 4096)</span><br><span class="line">    n.drop7 &#x3D; L.Dropout(n.relu7, dropout_ratio&#x3D;0.5, in_place&#x3D;True)</span><br><span class="line"></span><br><span class="line">    n.score_fr &#x3D; L.Convolution(n.drop7, num_output&#x3D;21, kernel_size&#x3D;1, pad&#x3D;0,</span><br><span class="line">        param&#x3D;[dict(lr_mult&#x3D;1, decay_mult&#x3D;1), dict(lr_mult&#x3D;2, decay_mult&#x3D;0)])</span><br><span class="line">    n.upscore &#x3D; L.Deconvolution(n.score_fr,</span><br><span class="line">        convolution_param&#x3D;dict(num_output&#x3D;21, kernel_size&#x3D;63, stride&#x3D;32,</span><br><span class="line">            bias_term&#x3D;False),</span><br><span class="line">        param&#x3D;[dict(lr_mult&#x3D;0)])</span><br><span class="line">    n.score &#x3D; crop(n.upscore, n.data)</span><br><span class="line">    n.loss &#x3D; L.SoftmaxWithLoss(n.score, n.label,</span><br><span class="line">            loss_param&#x3D;dict(normalize&#x3D;True, ignore_label&#x3D;255))</span><br><span class="line"></span><br><span class="line">    return n.to_proto()</span><br><span class="line"></span><br><span class="line">def make_net():</span><br><span class="line">    with open(&#39;train.prototxt&#39;, &#39;w&#39;) as f:</span><br><span class="line">        f.write(str(fcn(&#39;train&#39;)))</span><br><span class="line"></span><br><span class="line">    with open(&#39;val.prototxt&#39;, &#39;w&#39;) as f:</span><br><span class="line">        f.write(str(fcn(&#39;seg11valid&#39;)))</span><br><span class="line"></span><br><span class="line">if __name__ &#x3D;&#x3D; &#39;__main__&#39;:</span><br><span class="line">    make_net()</span><br></pre></td></tr></table></figure>
<ul>
<li>conv_relu()： 定义卷积层输入参数</li>
<li>max_pool()： 定义池化层输入参数</li>
<li>fcn()： 定义模型网络结构</li>
</ul>
<h4 id="fcn-模型结构详解"><a href="#fcn-模型结构详解" class="headerlink" title="fcn()模型结构详解"></a>fcn()模型结构详解</h4><p>这里建议结合AlexNet原论文<a href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf" target="_blank" rel="noopener">ImageNet Classification with Deep Convolutional Neural Networks</a>一起看，并参考<a href="http://simtalk.cn/2016/09/20/AlexNet/" target="_blank" rel="noopener">AlexNet模型结构图例</a>来进行比较好理解每个参数的意义。</p>
<h5 id="1-数据输入层"><a href="#1-数据输入层" class="headerlink" title="(1). 数据输入层"></a>(1). 数据输入层</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">n &#x3D; caffe.NetSpec()</span><br><span class="line">pydata_params &#x3D; dict()</span><br><span class="line">pydata_params[&#39;pcl_dir&#39;] &#x3D; &#39;..&#x2F;fcn_data_gen&#x2F;data&#x2F;npy&#39; #.npy files path</span><br><span class="line">pylayer &#x3D; &#39;PCLSegDataLayer&#39;</span><br><span class="line">n.data, n.label &#x3D; L.Python(module&#x3D;&#39;pcl_data_layer&#39;, layer&#x3D;pylayer,</span><br><span class="line">        ntop&#x3D;2, param_str&#x3D;str(pydata_params))</span><br></pre></td></tr></table></figure>
<p>找到<code>pcl_data_layer.py</code>文件中的<code>PCLSegDataLayer</code>函数，使用该类处理数据方式作为模型数据输入层函数。</p>
<h5 id="2-第一个卷积层"><a href="#2-第一个卷积层" class="headerlink" title="(2). 第一个卷积层"></a>(2). 第一个卷积层</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">n.conv1, n.relu1 &#x3D; conv_relu(n.data, 11, 96, stride&#x3D;4, pad&#x3D;100)</span><br><span class="line">n.pool1 &#x3D; max_pool(n.relu1, 3, stride&#x3D;2)</span><br><span class="line">n.norm1 &#x3D; L.LRN(n.pool1, local_size&#x3D;5, alpha&#x3D;1e-4, beta&#x3D;0.75)</span><br></pre></td></tr></table></figure>
<p>关于为何<code>pad=100</code>，此文中有详细解释：<a href="https://zhuanlan.zhihu.com/p/22976342" target="_blank" rel="noopener">FCN学习:Semantic Segmentation</a></p>
<h5 id="3-第二个卷积层"><a href="#3-第二个卷积层" class="headerlink" title="(3). 第二个卷积层"></a>(3). 第二个卷积层</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">n.conv2, n.relu2 &#x3D; conv_relu(n.norm1, 5, 256, pad&#x3D;2, group&#x3D;2)</span><br><span class="line">n.pool2 &#x3D; max_pool(n.relu2, 3, stride&#x3D;2)</span><br><span class="line">n.norm2 &#x3D; L.LRN(n.pool2, local_size&#x3D;5, alpha&#x3D;1e-4, beta&#x3D;0.75)</span><br></pre></td></tr></table></figure>

<h5 id="4-第三个卷积层"><a href="#4-第三个卷积层" class="headerlink" title="(4). 第三个卷积层"></a>(4). 第三个卷积层</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">n.conv3, n.relu3 &#x3D; conv_relu(n.norm2, 3, 384, pad&#x3D;1)</span><br></pre></td></tr></table></figure>

<h5 id="5-第四个卷积层"><a href="#5-第四个卷积层" class="headerlink" title="(5). 第四个卷积层"></a>(5). 第四个卷积层</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">n.conv4, n.relu4 &#x3D; conv_relu(n.relu3, 3, 384, pad&#x3D;1, group&#x3D;2)</span><br></pre></td></tr></table></figure>

<h5 id="6-第五个卷积层"><a href="#6-第五个卷积层" class="headerlink" title="(6). 第五个卷积层"></a>(6). 第五个卷积层</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">n.conv5, n.relu5 &#x3D; conv_relu(n.relu4, 3, 256, pad&#x3D;1, group&#x3D;2)</span><br><span class="line">n.pool5 &#x3D; max_pool(n.relu5, 3, stride&#x3D;2)</span><br></pre></td></tr></table></figure>

<h5 id="7-第六个全连接层"><a href="#7-第六个全连接层" class="headerlink" title="(7). 第六个全连接层"></a>(7). 第六个全连接层</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">n.fc6, n.relu6 &#x3D; conv_relu(n.pool5, 6, 4096)</span><br><span class="line">n.drop6 &#x3D; L.Dropout(n.relu6, dropout_ratio&#x3D;0.5, in_place&#x3D;True)</span><br></pre></td></tr></table></figure>

<h5 id="8-第七个全连接层"><a href="#8-第七个全连接层" class="headerlink" title="(8). 第七个全连接层"></a>(8). 第七个全连接层</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">n.fc7, n.relu7 &#x3D; conv_relu(n.drop6, 1, 4096)</span><br><span class="line">n.drop7 &#x3D; L.Dropout(n.relu7, dropout_ratio&#x3D;0.5, in_place&#x3D;True)</span><br></pre></td></tr></table></figure>

<h5 id="9-第八个全连接层"><a href="#9-第八个全连接层" class="headerlink" title="(9). 第八个全连接层"></a>(9). 第八个全连接层</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">n.score_fr &#x3D; L.Convolution(n.drop7, num_output&#x3D;21, kernel_size&#x3D;1, pad&#x3D;0,</span><br><span class="line">    param&#x3D;[dict(lr_mult&#x3D;1, decay_mult&#x3D;1), dict(lr_mult&#x3D;2, decay_mult&#x3D;0)])</span><br><span class="line">n.upscore &#x3D; L.Deconvolution(n.score_fr,</span><br><span class="line">    convolution_param&#x3D;dict(num_output&#x3D;21, kernel_size&#x3D;63, stride&#x3D;32,</span><br><span class="line">        bias_term&#x3D;False),</span><br><span class="line">    param&#x3D;[dict(lr_mult&#x3D;0)])</span><br><span class="line">n.score &#x3D; crop(n.upscore, n.data)</span><br><span class="line">n.loss &#x3D; L.SoftmaxWithLoss(n.score, n.label,</span><br><span class="line">        loss_param&#x3D;dict(normalize&#x3D;True, ignore_label&#x3D;255))</span><br></pre></td></tr></table></figure>



<h3 id="2-3-FCN-AlexNet求解函数（solve-py）"><a href="#2-3-FCN-AlexNet求解函数（solve-py）" class="headerlink" title="2.3 FCN-AlexNet求解函数（solve.py）"></a>2.3 FCN-AlexNet求解函数（solve.py）</h3><p><strong>solve.py</strong> 文件是整个模型的入口，它整合各个文件，输入外部参数，对结果进行求解并输出。由 <strong>solve.py</strong> 生成的 <strong>solver.prototxt</strong> 文件定义了求解函数的结构。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">import caffe</span><br><span class="line">import surgery, score</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import os</span><br><span class="line">import sys</span><br><span class="line"></span><br><span class="line">try:</span><br><span class="line">    import setproctitle</span><br><span class="line">    setproctitle.setproctitle(os.path.basename(os.getcwd()))</span><br><span class="line">except:</span><br><span class="line">    pass</span><br><span class="line"></span><br><span class="line">weights &#x3D; &#39;..&#x2F;ilsvrc-nets&#x2F;fcn-alexnet-pascal.caffemodel&#39;</span><br><span class="line"></span><br><span class="line"># init</span><br><span class="line"># caffe.set_device(int(sys.argv[0]))</span><br><span class="line"># caffe.set_mode_gpu()</span><br><span class="line"></span><br><span class="line">solver &#x3D; caffe.SGDSolver(&#39;solver.prototxt&#39;)</span><br><span class="line">solver.net.copy_from(weights)</span><br><span class="line"></span><br><span class="line"># surgeries</span><br><span class="line">interp_layers &#x3D; [k for k in solver.net.params.keys() if &#39;up&#39; in k]</span><br><span class="line">surgery.interp(solver.net, interp_layers)</span><br><span class="line"></span><br><span class="line"># scoring</span><br><span class="line">val &#x3D; np.loadtxt(&#39;..&#x2F;data&#x2F;pascal&#x2F;seg11valid.txt&#39;, dtype&#x3D;str)</span><br><span class="line"></span><br><span class="line">for _ in range(25):</span><br><span class="line">    solver.step(4000)</span><br><span class="line">    score.seg_tests(solver, False, val, layer&#x3D;&#39;score&#39;)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>weights = &#39;../ilsvrc-nets/fcn-alexnet-pascal.caffemodel&#39;</code>： 导入训练好的模型，可在[Netscope]中输入<strong>net.prototxt</strong>来进行网络结构可视化</li>
<li><code># caffe.set_device(int(sys.argv[0]))</code><br><code># caffe.set_mode_gpu()</code>： 设置gpu来进行训练，本人电脑使用gpu报错，所以没有使用</li>
<li><code>solver = caffe.SGDSolver(&#39;solver.prototxt&#39;)</code><br><code>solver.net.copy_from(weights)</code>：设置求解器模型</li>
<li><code># surgeries</code>： （待补充）</li>
<li><code># scoring</code> ： （待补充）</li>
</ul>
<h2 id="3-点云分割试验结果"><a href="#3-点云分割试验结果" class="headerlink" title="3. 点云分割试验结果"></a>3. 点云分割试验结果</h2><hr>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br><span class="line">589</span><br><span class="line">590</span><br><span class="line">591</span><br><span class="line">592</span><br><span class="line">593</span><br><span class="line">594</span><br><span class="line">595</span><br><span class="line">596</span><br><span class="line">597</span><br><span class="line">598</span><br><span class="line">599</span><br><span class="line">600</span><br><span class="line">601</span><br><span class="line">602</span><br><span class="line">603</span><br><span class="line">604</span><br><span class="line">605</span><br><span class="line">606</span><br><span class="line">607</span><br><span class="line">608</span><br><span class="line">609</span><br><span class="line">610</span><br><span class="line">611</span><br><span class="line">612</span><br><span class="line">613</span><br><span class="line">614</span><br><span class="line">615</span><br><span class="line">616</span><br><span class="line">617</span><br><span class="line">618</span><br><span class="line">619</span><br><span class="line">620</span><br><span class="line">621</span><br><span class="line">622</span><br><span class="line">623</span><br><span class="line">624</span><br><span class="line">625</span><br><span class="line">626</span><br><span class="line">627</span><br><span class="line">628</span><br><span class="line">629</span><br><span class="line">630</span><br><span class="line">631</span><br><span class="line">632</span><br><span class="line">633</span><br><span class="line">634</span><br><span class="line">635</span><br><span class="line">636</span><br><span class="line">637</span><br><span class="line">638</span><br><span class="line">639</span><br><span class="line">640</span><br><span class="line">641</span><br><span class="line">642</span><br><span class="line">643</span><br><span class="line">644</span><br><span class="line">645</span><br><span class="line">646</span><br><span class="line">647</span><br><span class="line">648</span><br><span class="line">649</span><br><span class="line">650</span><br><span class="line">651</span><br><span class="line">652</span><br><span class="line">653</span><br><span class="line">654</span><br><span class="line">655</span><br><span class="line">656</span><br><span class="line">657</span><br><span class="line">658</span><br><span class="line">659</span><br><span class="line">660</span><br><span class="line">661</span><br><span class="line">662</span><br><span class="line">663</span><br><span class="line">664</span><br><span class="line">665</span><br><span class="line">666</span><br><span class="line">667</span><br><span class="line">668</span><br><span class="line">669</span><br><span class="line">670</span><br><span class="line">671</span><br><span class="line">672</span><br><span class="line">673</span><br><span class="line">674</span><br><span class="line">675</span><br><span class="line">676</span><br><span class="line">677</span><br><span class="line">678</span><br><span class="line">679</span><br><span class="line">680</span><br><span class="line">681</span><br><span class="line">682</span><br><span class="line">683</span><br><span class="line">684</span><br><span class="line">685</span><br><span class="line">686</span><br><span class="line">687</span><br><span class="line">688</span><br><span class="line">689</span><br><span class="line">690</span><br><span class="line">691</span><br><span class="line">692</span><br><span class="line">693</span><br><span class="line">694</span><br><span class="line">695</span><br><span class="line">696</span><br><span class="line">697</span><br><span class="line">698</span><br><span class="line">699</span><br><span class="line">700</span><br><span class="line">701</span><br><span class="line">702</span><br><span class="line">703</span><br><span class="line">704</span><br><span class="line">705</span><br><span class="line">706</span><br><span class="line">707</span><br><span class="line">708</span><br><span class="line">709</span><br><span class="line">710</span><br><span class="line">711</span><br><span class="line">712</span><br><span class="line">713</span><br><span class="line">714</span><br><span class="line">715</span><br><span class="line">716</span><br><span class="line">717</span><br><span class="line">718</span><br><span class="line">719</span><br><span class="line">720</span><br><span class="line">721</span><br><span class="line">722</span><br><span class="line">723</span><br><span class="line">724</span><br><span class="line">725</span><br><span class="line">726</span><br><span class="line">727</span><br><span class="line">728</span><br><span class="line">729</span><br><span class="line">730</span><br><span class="line">731</span><br><span class="line">732</span><br><span class="line">733</span><br><span class="line">734</span><br><span class="line">735</span><br><span class="line">736</span><br><span class="line">737</span><br><span class="line">738</span><br><span class="line">739</span><br><span class="line">740</span><br><span class="line">741</span><br><span class="line">742</span><br><span class="line">743</span><br><span class="line">744</span><br><span class="line">745</span><br><span class="line">746</span><br><span class="line">747</span><br><span class="line">748</span><br><span class="line">749</span><br><span class="line">750</span><br><span class="line">751</span><br><span class="line">752</span><br><span class="line">753</span><br><span class="line">754</span><br><span class="line">755</span><br><span class="line">756</span><br><span class="line">757</span><br><span class="line">758</span><br><span class="line">759</span><br><span class="line">760</span><br><span class="line">761</span><br><span class="line">762</span><br><span class="line">763</span><br><span class="line">764</span><br><span class="line">765</span><br><span class="line">766</span><br><span class="line">767</span><br><span class="line">768</span><br><span class="line">769</span><br><span class="line">770</span><br><span class="line">771</span><br><span class="line">772</span><br><span class="line">773</span><br><span class="line">774</span><br><span class="line">775</span><br><span class="line">776</span><br><span class="line">777</span><br><span class="line">778</span><br><span class="line">779</span><br><span class="line">780</span><br><span class="line">781</span><br><span class="line">782</span><br><span class="line">783</span><br><span class="line">784</span><br><span class="line">785</span><br><span class="line">786</span><br><span class="line">787</span><br><span class="line">788</span><br><span class="line">789</span><br><span class="line">790</span><br><span class="line">791</span><br><span class="line">792</span><br><span class="line">793</span><br><span class="line">794</span><br><span class="line">795</span><br><span class="line">796</span><br><span class="line">797</span><br><span class="line">798</span><br><span class="line">799</span><br><span class="line">800</span><br><span class="line">801</span><br><span class="line">802</span><br><span class="line">803</span><br><span class="line">804</span><br><span class="line">805</span><br><span class="line">806</span><br><span class="line">807</span><br><span class="line">808</span><br><span class="line">809</span><br><span class="line">810</span><br><span class="line">811</span><br><span class="line">812</span><br><span class="line">813</span><br><span class="line">814</span><br><span class="line">815</span><br><span class="line">816</span><br><span class="line">817</span><br><span class="line">818</span><br><span class="line">819</span><br><span class="line">820</span><br><span class="line">821</span><br><span class="line">822</span><br><span class="line">823</span><br><span class="line">824</span><br><span class="line">825</span><br><span class="line">826</span><br><span class="line">827</span><br><span class="line">828</span><br><span class="line">829</span><br><span class="line">830</span><br><span class="line">831</span><br><span class="line">832</span><br><span class="line">833</span><br><span class="line">834</span><br><span class="line">835</span><br><span class="line">836</span><br><span class="line">837</span><br><span class="line">838</span><br><span class="line">839</span><br><span class="line">840</span><br><span class="line">841</span><br><span class="line">842</span><br><span class="line">843</span><br><span class="line">844</span><br><span class="line">845</span><br><span class="line">846</span><br><span class="line">847</span><br><span class="line">848</span><br><span class="line">849</span><br><span class="line">850</span><br><span class="line">851</span><br><span class="line">852</span><br><span class="line">853</span><br><span class="line">854</span><br><span class="line">855</span><br><span class="line">856</span><br><span class="line">857</span><br><span class="line">858</span><br><span class="line">859</span><br><span class="line">860</span><br><span class="line">861</span><br><span class="line">862</span><br><span class="line">863</span><br><span class="line">864</span><br><span class="line">865</span><br><span class="line">866</span><br><span class="line">867</span><br><span class="line">868</span><br><span class="line">869</span><br><span class="line">870</span><br><span class="line">871</span><br><span class="line">872</span><br><span class="line">873</span><br><span class="line">874</span><br><span class="line">875</span><br><span class="line">876</span><br><span class="line">877</span><br><span class="line">878</span><br><span class="line">879</span><br><span class="line">880</span><br><span class="line">881</span><br><span class="line">882</span><br><span class="line">883</span><br><span class="line">884</span><br><span class="line">885</span><br><span class="line">886</span><br><span class="line">887</span><br><span class="line">888</span><br><span class="line">889</span><br><span class="line">890</span><br><span class="line">891</span><br><span class="line">892</span><br><span class="line">893</span><br><span class="line">894</span><br><span class="line">895</span><br><span class="line">896</span><br><span class="line">897</span><br><span class="line">898</span><br><span class="line">899</span><br><span class="line">900</span><br><span class="line">901</span><br><span class="line">902</span><br><span class="line">903</span><br><span class="line">904</span><br><span class="line">905</span><br><span class="line">906</span><br><span class="line">907</span><br><span class="line">908</span><br><span class="line">909</span><br><span class="line">910</span><br><span class="line">911</span><br><span class="line">912</span><br><span class="line">913</span><br><span class="line">914</span><br><span class="line">915</span><br><span class="line">916</span><br><span class="line">917</span><br><span class="line">918</span><br><span class="line">919</span><br><span class="line">920</span><br><span class="line">921</span><br><span class="line">922</span><br><span class="line">923</span><br><span class="line">924</span><br><span class="line">925</span><br><span class="line">926</span><br><span class="line">927</span><br><span class="line">928</span><br><span class="line">929</span><br><span class="line">930</span><br><span class="line">931</span><br><span class="line">932</span><br><span class="line">933</span><br><span class="line">934</span><br><span class="line">935</span><br><span class="line">936</span><br><span class="line">937</span><br><span class="line">938</span><br><span class="line">939</span><br><span class="line">940</span><br><span class="line">941</span><br><span class="line">942</span><br><span class="line">943</span><br><span class="line">944</span><br><span class="line">945</span><br><span class="line">946</span><br><span class="line">947</span><br><span class="line">948</span><br><span class="line">949</span><br><span class="line">950</span><br><span class="line">951</span><br><span class="line">952</span><br><span class="line">953</span><br><span class="line">954</span><br><span class="line">955</span><br><span class="line">956</span><br><span class="line">957</span><br><span class="line">958</span><br><span class="line">959</span><br><span class="line">960</span><br><span class="line">961</span><br><span class="line">962</span><br><span class="line">963</span><br><span class="line">964</span><br><span class="line">965</span><br><span class="line">966</span><br><span class="line">967</span><br><span class="line">968</span><br><span class="line">969</span><br><span class="line">970</span><br><span class="line">971</span><br><span class="line">972</span><br><span class="line">973</span><br><span class="line">974</span><br><span class="line">975</span><br><span class="line">976</span><br><span class="line">977</span><br><span class="line">978</span><br><span class="line">979</span><br><span class="line">980</span><br><span class="line">981</span><br><span class="line">982</span><br><span class="line">983</span><br><span class="line">984</span><br><span class="line">985</span><br><span class="line">986</span><br><span class="line">987</span><br><span class="line">988</span><br><span class="line">989</span><br><span class="line">990</span><br><span class="line">991</span><br><span class="line">992</span><br><span class="line">993</span><br><span class="line">994</span><br><span class="line">995</span><br><span class="line">996</span><br><span class="line">997</span><br><span class="line">998</span><br><span class="line">999</span><br><span class="line">1000</span><br><span class="line">1001</span><br><span class="line">1002</span><br><span class="line">1003</span><br><span class="line">1004</span><br><span class="line">1005</span><br><span class="line">1006</span><br><span class="line">1007</span><br><span class="line">1008</span><br><span class="line">1009</span><br><span class="line">1010</span><br><span class="line">1011</span><br><span class="line">1012</span><br><span class="line">1013</span><br><span class="line">1014</span><br><span class="line">1015</span><br><span class="line">1016</span><br><span class="line">1017</span><br><span class="line">1018</span><br><span class="line">1019</span><br><span class="line">1020</span><br><span class="line">1021</span><br><span class="line">1022</span><br><span class="line">1023</span><br><span class="line">1024</span><br><span class="line">1025</span><br><span class="line">1026</span><br><span class="line">1027</span><br><span class="line">1028</span><br><span class="line">1029</span><br><span class="line">1030</span><br><span class="line">1031</span><br><span class="line">1032</span><br><span class="line">1033</span><br><span class="line">1034</span><br><span class="line">1035</span><br><span class="line">1036</span><br><span class="line">1037</span><br><span class="line">1038</span><br><span class="line">1039</span><br><span class="line">1040</span><br><span class="line">1041</span><br><span class="line">1042</span><br><span class="line">1043</span><br><span class="line">1044</span><br><span class="line">1045</span><br><span class="line">1046</span><br><span class="line">1047</span><br><span class="line">1048</span><br><span class="line">1049</span><br><span class="line">1050</span><br><span class="line">1051</span><br><span class="line">1052</span><br><span class="line">1053</span><br><span class="line">1054</span><br><span class="line">1055</span><br><span class="line">1056</span><br><span class="line">1057</span><br><span class="line">1058</span><br><span class="line">1059</span><br><span class="line">1060</span><br><span class="line">1061</span><br><span class="line">1062</span><br><span class="line">1063</span><br><span class="line">1064</span><br><span class="line">1065</span><br><span class="line">1066</span><br><span class="line">1067</span><br><span class="line">1068</span><br><span class="line">1069</span><br><span class="line">1070</span><br><span class="line">1071</span><br><span class="line">1072</span><br><span class="line">1073</span><br><span class="line">1074</span><br><span class="line">1075</span><br><span class="line">1076</span><br><span class="line">1077</span><br><span class="line">1078</span><br></pre></td><td class="code"><pre><span class="line">pydev debugger: process 9249 is connecting</span><br><span class="line"></span><br><span class="line">Connected to pydev debugger (build 173.4301.16)</span><br><span class="line">WARNING: Logging before InitGoogleLogging() is written to STDERR</span><br><span class="line">I0313 11:41:39.369604  9249 solver.cpp:45] Initializing solver from parameters: </span><br><span class="line">train_net: &quot;train.prototxt&quot;</span><br><span class="line">test_net: &quot;val.prototxt&quot;</span><br><span class="line">test_iter: 736</span><br><span class="line">test_interval: 999999999</span><br><span class="line">base_lr: 0.0001</span><br><span class="line">display: 20</span><br><span class="line">max_iter: 100000</span><br><span class="line">lr_policy: &quot;fixed&quot;</span><br><span class="line">momentum: 0.9</span><br><span class="line">weight_decay: 0.0005</span><br><span class="line">snapshot: 4000</span><br><span class="line">snapshot_prefix: &quot;snapshot&#x2F;train&quot;</span><br><span class="line">test_initialization: false</span><br><span class="line">average_loss: 20</span><br><span class="line">iter_size: 20</span><br><span class="line">I0313 11:41:39.369671  9249 solver.cpp:92] Creating training net from train_net file: train.prototxt</span><br><span class="line">I0313 11:41:39.370101  9249 net.cpp:51] Initializing net from parameters: </span><br><span class="line">state &#123;</span><br><span class="line">  phase: TRAIN</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;data&quot;</span><br><span class="line">  type: &quot;Python&quot;</span><br><span class="line">  top: &quot;data&quot;</span><br><span class="line">  top: &quot;label&quot;</span><br><span class="line">  python_param &#123;</span><br><span class="line">    module: &quot;pcl_data_layer&quot;</span><br><span class="line">    layer: &quot;PCLSegDataLayer&quot;</span><br><span class="line">    param_str: &quot;&#123;\&#39;pcl_dir\&#39;: \&#39;&#x2F;home&#x2F;zzy&#x2F;CLionProjects&#x2F;ROS_Project&#x2F;ws&#x2F;src&#x2F;fcn_data_gen&#x2F;data&#x2F;npy\&#39;&#125;&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;conv1&quot;</span><br><span class="line">  type: &quot;Convolution&quot;</span><br><span class="line">  bottom: &quot;data&quot;</span><br><span class="line">  top: &quot;conv1&quot;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 96</span><br><span class="line">    pad: 100</span><br><span class="line">    kernel_size: 11</span><br><span class="line">    group: 1</span><br><span class="line">    stride: 4</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;relu1&quot;</span><br><span class="line">  type: &quot;ReLU&quot;</span><br><span class="line">  bottom: &quot;conv1&quot;</span><br><span class="line">  top: &quot;conv1&quot;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;pool1&quot;</span><br><span class="line">  type: &quot;Pooling&quot;</span><br><span class="line">  bottom: &quot;conv1&quot;</span><br><span class="line">  top: &quot;pool1&quot;</span><br><span class="line">  pooling_param &#123;</span><br><span class="line">    pool: MAX</span><br><span class="line">    kernel_size: 3</span><br><span class="line">    stride: 2</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;norm1&quot;</span><br><span class="line">  type: &quot;LRN&quot;</span><br><span class="line">  bottom: &quot;pool1&quot;</span><br><span class="line">  top: &quot;norm1&quot;</span><br><span class="line">  lrn_param &#123;</span><br><span class="line">    local_size: 5</span><br><span class="line">    alpha: 0.0001</span><br><span class="line">    beta: 0.75</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;conv2&quot;</span><br><span class="line">  type: &quot;Convolution&quot;</span><br><span class="line">  bottom: &quot;norm1&quot;</span><br><span class="line">  top: &quot;conv2&quot;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 256</span><br><span class="line">    pad: 2</span><br><span class="line">    kernel_size: 5</span><br><span class="line">    group: 2</span><br><span class="line">    stride: 1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;relu2&quot;</span><br><span class="line">  type: &quot;ReLU&quot;</span><br><span class="line">  bottom: &quot;conv2&quot;</span><br><span class="line">  top: &quot;conv2&quot;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;pool2&quot;</span><br><span class="line">  type: &quot;Pooling&quot;</span><br><span class="line">  bottom: &quot;conv2&quot;</span><br><span class="line">  top: &quot;pool2&quot;</span><br><span class="line">  pooling_param &#123;</span><br><span class="line">    pool: MAX</span><br><span class="line">    kernel_size: 3</span><br><span class="line">    stride: 2</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;norm2&quot;</span><br><span class="line">  type: &quot;LRN&quot;</span><br><span class="line">  bottom: &quot;pool2&quot;</span><br><span class="line">  top: &quot;norm2&quot;</span><br><span class="line">  lrn_param &#123;</span><br><span class="line">    local_size: 5</span><br><span class="line">    alpha: 0.0001</span><br><span class="line">    beta: 0.75</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;conv3&quot;</span><br><span class="line">  type: &quot;Convolution&quot;</span><br><span class="line">  bottom: &quot;norm2&quot;</span><br><span class="line">  top: &quot;conv3&quot;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 384</span><br><span class="line">    pad: 1</span><br><span class="line">    kernel_size: 3</span><br><span class="line">    group: 1</span><br><span class="line">    stride: 1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;relu3&quot;</span><br><span class="line">  type: &quot;ReLU&quot;</span><br><span class="line">  bottom: &quot;conv3&quot;</span><br><span class="line">  top: &quot;conv3&quot;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;conv4&quot;</span><br><span class="line">  type: &quot;Convolution&quot;</span><br><span class="line">  bottom: &quot;conv3&quot;</span><br><span class="line">  top: &quot;conv4&quot;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 384</span><br><span class="line">    pad: 1</span><br><span class="line">    kernel_size: 3</span><br><span class="line">    group: 2</span><br><span class="line">    stride: 1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;relu4&quot;</span><br><span class="line">  type: &quot;ReLU&quot;</span><br><span class="line">  bottom: &quot;conv4&quot;</span><br><span class="line">  top: &quot;conv4&quot;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;conv5&quot;</span><br><span class="line">  type: &quot;Convolution&quot;</span><br><span class="line">  bottom: &quot;conv4&quot;</span><br><span class="line">  top: &quot;conv5&quot;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 256</span><br><span class="line">    pad: 1</span><br><span class="line">    kernel_size: 3</span><br><span class="line">    group: 2</span><br><span class="line">    stride: 1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;relu5&quot;</span><br><span class="line">  type: &quot;ReLU&quot;</span><br><span class="line">  bottom: &quot;conv5&quot;</span><br><span class="line">  top: &quot;conv5&quot;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;pool5&quot;</span><br><span class="line">  type: &quot;Pooling&quot;</span><br><span class="line">  bottom: &quot;conv5&quot;</span><br><span class="line">  top: &quot;pool5&quot;</span><br><span class="line">  pooling_param &#123;</span><br><span class="line">    pool: MAX</span><br><span class="line">    kernel_size: 3</span><br><span class="line">    stride: 2</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;fc6&quot;</span><br><span class="line">  type: &quot;Convolution&quot;</span><br><span class="line">  bottom: &quot;pool5&quot;</span><br><span class="line">  top: &quot;fc6&quot;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 4096</span><br><span class="line">    pad: 0</span><br><span class="line">    kernel_size: 6</span><br><span class="line">    group: 1</span><br><span class="line">    stride: 1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;relu6&quot;</span><br><span class="line">  type: &quot;ReLU&quot;</span><br><span class="line">  bottom: &quot;fc6&quot;</span><br><span class="line">  top: &quot;fc6&quot;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;drop6&quot;</span><br><span class="line">  type: &quot;Dropout&quot;</span><br><span class="line">  bottom: &quot;fc6&quot;</span><br><span class="line">  top: &quot;fc6&quot;</span><br><span class="line">  dropout_param &#123;</span><br><span class="line">    dropout_ratio: 0.5</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;fc7&quot;</span><br><span class="line">  type: &quot;Convolution&quot;</span><br><span class="line">  bottom: &quot;fc6&quot;</span><br><span class="line">  top: &quot;fc7&quot;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 4096</span><br><span class="line">    pad: 0</span><br><span class="line">    kernel_size: 1</span><br><span class="line">    group: 1</span><br><span class="line">    stride: 1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;relu7&quot;</span><br><span class="line">  type: &quot;ReLU&quot;</span><br><span class="line">  bottom: &quot;fc7&quot;</span><br><span class="line">  top: &quot;fc7&quot;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;drop7&quot;</span><br><span class="line">  type: &quot;Dropout&quot;</span><br><span class="line">  bottom: &quot;fc7&quot;</span><br><span class="line">  top: &quot;fc7&quot;</span><br><span class="line">  dropout_param &#123;</span><br><span class="line">    dropout_ratio: 0.5</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;score_fr&quot;</span><br><span class="line">  type: &quot;Convolution&quot;</span><br><span class="line">  bottom: &quot;fc7&quot;</span><br><span class="line">  top: &quot;score_fr&quot;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 1</span><br><span class="line">    decay_mult: 1</span><br><span class="line">  &#125;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 2</span><br><span class="line">    decay_mult: 0</span><br><span class="line">  &#125;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 21</span><br><span class="line">    pad: 0</span><br><span class="line">    kernel_size: 1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;upscore&quot;</span><br><span class="line">  type: &quot;Deconvolution&quot;</span><br><span class="line">  bottom: &quot;score_fr&quot;</span><br><span class="line">  top: &quot;upscore&quot;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 0</span><br><span class="line">  &#125;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 21</span><br><span class="line">    bias_term: false</span><br><span class="line">    kernel_size: 63</span><br><span class="line">    stride: 32</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;score&quot;</span><br><span class="line">  type: &quot;Crop&quot;</span><br><span class="line">  bottom: &quot;upscore&quot;</span><br><span class="line">  bottom: &quot;data&quot;</span><br><span class="line">  top: &quot;score&quot;</span><br><span class="line">  crop_param &#123;</span><br><span class="line">    axis: 2</span><br><span class="line">    offset: 18</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;loss&quot;</span><br><span class="line">  type: &quot;SoftmaxWithLoss&quot;</span><br><span class="line">  bottom: &quot;score&quot;</span><br><span class="line">  bottom: &quot;label&quot;</span><br><span class="line">  top: &quot;loss&quot;</span><br><span class="line">  loss_param &#123;</span><br><span class="line">    ignore_label: 255</span><br><span class="line">    normalize: true</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">I0313 11:41:39.370163  9249 layer_factory.hpp:77] Creating layer data</span><br><span class="line">I0313 11:41:39.370743  9249 net.cpp:84] Creating Layer data</span><br><span class="line">I0313 11:41:39.370753  9249 net.cpp:380] data -&gt; data</span><br><span class="line">I0313 11:41:39.370759  9249 net.cpp:380] data -&gt; label</span><br><span class="line">I0313 11:41:39.372340  9249 net.cpp:122] Setting up data</span><br><span class="line">I0313 11:41:39.372354  9249 net.cpp:129] Top shape: 1 3 16 2016 (96768)</span><br><span class="line">I0313 11:41:39.372357  9249 net.cpp:129] Top shape: 1 16 2016 (32256)</span><br><span class="line">I0313 11:41:39.372360  9249 net.cpp:137] Memory required for data: 516096</span><br><span class="line">I0313 11:41:39.372364  9249 layer_factory.hpp:77] Creating layer data_data_0_split</span><br><span class="line">I0313 11:41:39.372370  9249 net.cpp:84] Creating Layer data_data_0_split</span><br><span class="line">I0313 11:41:39.372372  9249 net.cpp:406] data_data_0_split &lt;- data</span><br><span class="line">I0313 11:41:39.372376  9249 net.cpp:380] data_data_0_split -&gt; data_data_0_split_0</span><br><span class="line">I0313 11:41:39.372382  9249 net.cpp:380] data_data_0_split -&gt; data_data_0_split_1</span><br><span class="line">I0313 11:41:39.372387  9249 net.cpp:122] Setting up data_data_0_split</span><br><span class="line">I0313 11:41:39.372391  9249 net.cpp:129] Top shape: 1 3 16 2016 (96768)</span><br><span class="line">I0313 11:41:39.372395  9249 net.cpp:129] Top shape: 1 3 16 2016 (96768)</span><br><span class="line">I0313 11:41:39.372397  9249 net.cpp:137] Memory required for data: 1290240</span><br><span class="line">I0313 11:41:39.372400  9249 layer_factory.hpp:77] Creating layer conv1</span><br><span class="line">I0313 11:41:39.372406  9249 net.cpp:84] Creating Layer conv1</span><br><span class="line">I0313 11:41:39.372409  9249 net.cpp:406] conv1 &lt;- data_data_0_split_0</span><br><span class="line">I0313 11:41:39.372412  9249 net.cpp:380] conv1 -&gt; conv1</span><br><span class="line">I0313 11:41:39.372515  9249 net.cpp:122] Setting up conv1</span><br><span class="line">I0313 11:41:39.372521  9249 net.cpp:129] Top shape: 1 96 52 552 (2755584)</span><br><span class="line">I0313 11:41:39.372524  9249 net.cpp:137] Memory required for data: 12312576</span><br><span class="line">I0313 11:41:39.372531  9249 layer_factory.hpp:77] Creating layer relu1</span><br><span class="line">I0313 11:41:39.372535  9249 net.cpp:84] Creating Layer relu1</span><br><span class="line">I0313 11:41:39.372539  9249 net.cpp:406] relu1 &lt;- conv1</span><br><span class="line">I0313 11:41:39.372541  9249 net.cpp:367] relu1 -&gt; conv1 (in-place)</span><br><span class="line">I0313 11:41:39.372546  9249 net.cpp:122] Setting up relu1</span><br><span class="line">I0313 11:41:39.372550  9249 net.cpp:129] Top shape: 1 96 52 552 (2755584)</span><br><span class="line">I0313 11:41:39.372552  9249 net.cpp:137] Memory required for data: 23334912</span><br><span class="line">I0313 11:41:39.372555  9249 layer_factory.hpp:77] Creating layer pool1</span><br><span class="line">I0313 11:41:39.372558  9249 net.cpp:84] Creating Layer pool1</span><br><span class="line">I0313 11:41:39.372560  9249 net.cpp:406] pool1 &lt;- conv1</span><br><span class="line">I0313 11:41:39.372565  9249 net.cpp:380] pool1 -&gt; pool1</span><br><span class="line">I0313 11:41:39.372573  9249 net.cpp:122] Setting up pool1</span><br><span class="line">I0313 11:41:39.372576  9249 net.cpp:129] Top shape: 1 96 26 276 (688896)</span><br><span class="line">I0313 11:41:39.372579  9249 net.cpp:137] Memory required for data: 26090496</span><br><span class="line">I0313 11:41:39.372581  9249 layer_factory.hpp:77] Creating layer norm1</span><br><span class="line">I0313 11:41:39.372586  9249 net.cpp:84] Creating Layer norm1</span><br><span class="line">I0313 11:41:39.372588  9249 net.cpp:406] norm1 &lt;- pool1</span><br><span class="line">I0313 11:41:39.372593  9249 net.cpp:380] norm1 -&gt; norm1</span><br><span class="line">I0313 11:41:39.372599  9249 net.cpp:122] Setting up norm1</span><br><span class="line">I0313 11:41:39.372602  9249 net.cpp:129] Top shape: 1 96 26 276 (688896)</span><br><span class="line">I0313 11:41:39.372604  9249 net.cpp:137] Memory required for data: 28846080</span><br><span class="line">I0313 11:41:39.372607  9249 layer_factory.hpp:77] Creating layer conv2</span><br><span class="line">I0313 11:41:39.372611  9249 net.cpp:84] Creating Layer conv2</span><br><span class="line">I0313 11:41:39.372613  9249 net.cpp:406] conv2 &lt;- norm1</span><br><span class="line">I0313 11:41:39.372617  9249 net.cpp:380] conv2 -&gt; conv2</span><br><span class="line">I0313 11:41:39.373008  9249 net.cpp:122] Setting up conv2</span><br><span class="line">I0313 11:41:39.373013  9249 net.cpp:129] Top shape: 1 256 26 276 (1837056)</span><br><span class="line">I0313 11:41:39.373015  9249 net.cpp:137] Memory required for data: 36194304</span><br><span class="line">I0313 11:41:39.373021  9249 layer_factory.hpp:77] Creating layer relu2</span><br><span class="line">I0313 11:41:39.373025  9249 net.cpp:84] Creating Layer relu2</span><br><span class="line">I0313 11:41:39.373028  9249 net.cpp:406] relu2 &lt;- conv2</span><br><span class="line">I0313 11:41:39.373030  9249 net.cpp:367] relu2 -&gt; conv2 (in-place)</span><br><span class="line">I0313 11:41:39.373034  9249 net.cpp:122] Setting up relu2</span><br><span class="line">I0313 11:41:39.373039  9249 net.cpp:129] Top shape: 1 256 26 276 (1837056)</span><br><span class="line">I0313 11:41:39.373040  9249 net.cpp:137] Memory required for data: 43542528</span><br><span class="line">I0313 11:41:39.373042  9249 layer_factory.hpp:77] Creating layer pool2</span><br><span class="line">I0313 11:41:39.373046  9249 net.cpp:84] Creating Layer pool2</span><br><span class="line">I0313 11:41:39.373049  9249 net.cpp:406] pool2 &lt;- conv2</span><br><span class="line">I0313 11:41:39.373052  9249 net.cpp:380] pool2 -&gt; pool2</span><br><span class="line">I0313 11:41:39.373057  9249 net.cpp:122] Setting up pool2</span><br><span class="line">I0313 11:41:39.373061  9249 net.cpp:129] Top shape: 1 256 13 138 (459264)</span><br><span class="line">I0313 11:41:39.373064  9249 net.cpp:137] Memory required for data: 45379584</span><br><span class="line">I0313 11:41:39.373065  9249 layer_factory.hpp:77] Creating layer norm2</span><br><span class="line">I0313 11:41:39.373070  9249 net.cpp:84] Creating Layer norm2</span><br><span class="line">I0313 11:41:39.373071  9249 net.cpp:406] norm2 &lt;- pool2</span><br><span class="line">I0313 11:41:39.373075  9249 net.cpp:380] norm2 -&gt; norm2</span><br><span class="line">I0313 11:41:39.373080  9249 net.cpp:122] Setting up norm2</span><br><span class="line">I0313 11:41:39.373082  9249 net.cpp:129] Top shape: 1 256 13 138 (459264)</span><br><span class="line">I0313 11:41:39.373085  9249 net.cpp:137] Memory required for data: 47216640</span><br><span class="line">I0313 11:41:39.373087  9249 layer_factory.hpp:77] Creating layer conv3</span><br><span class="line">I0313 11:41:39.373091  9249 net.cpp:84] Creating Layer conv3</span><br><span class="line">I0313 11:41:39.373093  9249 net.cpp:406] conv3 &lt;- norm2</span><br><span class="line">I0313 11:41:39.373096  9249 net.cpp:380] conv3 -&gt; conv3</span><br><span class="line">I0313 11:41:39.373900  9249 net.cpp:122] Setting up conv3</span><br><span class="line">I0313 11:41:39.373906  9249 net.cpp:129] Top shape: 1 384 13 138 (688896)</span><br><span class="line">I0313 11:41:39.373909  9249 net.cpp:137] Memory required for data: 49972224</span><br><span class="line">I0313 11:41:39.373914  9249 layer_factory.hpp:77] Creating layer relu3</span><br><span class="line">I0313 11:41:39.373919  9249 net.cpp:84] Creating Layer relu3</span><br><span class="line">I0313 11:41:39.373921  9249 net.cpp:406] relu3 &lt;- conv3</span><br><span class="line">I0313 11:41:39.373924  9249 net.cpp:367] relu3 -&gt; conv3 (in-place)</span><br><span class="line">I0313 11:41:39.373929  9249 net.cpp:122] Setting up relu3</span><br><span class="line">I0313 11:41:39.373931  9249 net.cpp:129] Top shape: 1 384 13 138 (688896)</span><br><span class="line">I0313 11:41:39.373934  9249 net.cpp:137] Memory required for data: 52727808</span><br><span class="line">I0313 11:41:39.373936  9249 layer_factory.hpp:77] Creating layer conv4</span><br><span class="line">I0313 11:41:39.373941  9249 net.cpp:84] Creating Layer conv4</span><br><span class="line">I0313 11:41:39.373944  9249 net.cpp:406] conv4 &lt;- conv3</span><br><span class="line">I0313 11:41:39.373947  9249 net.cpp:380] conv4 -&gt; conv4</span><br><span class="line">I0313 11:41:39.374778  9249 net.cpp:122] Setting up conv4</span><br><span class="line">I0313 11:41:39.374783  9249 net.cpp:129] Top shape: 1 384 13 138 (688896)</span><br><span class="line">I0313 11:41:39.374785  9249 net.cpp:137] Memory required for data: 55483392</span><br><span class="line">I0313 11:41:39.374789  9249 layer_factory.hpp:77] Creating layer relu4</span><br><span class="line">I0313 11:41:39.374794  9249 net.cpp:84] Creating Layer relu4</span><br><span class="line">I0313 11:41:39.374795  9249 net.cpp:406] relu4 &lt;- conv4</span><br><span class="line">I0313 11:41:39.374800  9249 net.cpp:367] relu4 -&gt; conv4 (in-place)</span><br><span class="line">I0313 11:41:39.374804  9249 net.cpp:122] Setting up relu4</span><br><span class="line">I0313 11:41:39.374807  9249 net.cpp:129] Top shape: 1 384 13 138 (688896)</span><br><span class="line">I0313 11:41:39.374809  9249 net.cpp:137] Memory required for data: 58238976</span><br><span class="line">I0313 11:41:39.374811  9249 layer_factory.hpp:77] Creating layer conv5</span><br><span class="line">I0313 11:41:39.374816  9249 net.cpp:84] Creating Layer conv5</span><br><span class="line">I0313 11:41:39.374819  9249 net.cpp:406] conv5 &lt;- conv4</span><br><span class="line">I0313 11:41:39.374824  9249 net.cpp:380] conv5 -&gt; conv5</span><br><span class="line">I0313 11:41:39.375376  9249 net.cpp:122] Setting up conv5</span><br><span class="line">I0313 11:41:39.375382  9249 net.cpp:129] Top shape: 1 256 13 138 (459264)</span><br><span class="line">I0313 11:41:39.375385  9249 net.cpp:137] Memory required for data: 60076032</span><br><span class="line">I0313 11:41:39.375392  9249 layer_factory.hpp:77] Creating layer relu5</span><br><span class="line">I0313 11:41:39.375397  9249 net.cpp:84] Creating Layer relu5</span><br><span class="line">I0313 11:41:39.375399  9249 net.cpp:406] relu5 &lt;- conv5</span><br><span class="line">I0313 11:41:39.375402  9249 net.cpp:367] relu5 -&gt; conv5 (in-place)</span><br><span class="line">I0313 11:41:39.375406  9249 net.cpp:122] Setting up relu5</span><br><span class="line">I0313 11:41:39.375409  9249 net.cpp:129] Top shape: 1 256 13 138 (459264)</span><br><span class="line">I0313 11:41:39.375412  9249 net.cpp:137] Memory required for data: 61913088</span><br><span class="line">I0313 11:41:39.375414  9249 layer_factory.hpp:77] Creating layer pool5</span><br><span class="line">I0313 11:41:39.375421  9249 net.cpp:84] Creating Layer pool5</span><br><span class="line">I0313 11:41:39.375422  9249 net.cpp:406] pool5 &lt;- conv5</span><br><span class="line">I0313 11:41:39.375425  9249 net.cpp:380] pool5 -&gt; pool5</span><br><span class="line">I0313 11:41:39.375432  9249 net.cpp:122] Setting up pool5</span><br><span class="line">I0313 11:41:39.375434  9249 net.cpp:129] Top shape: 1 256 6 69 (105984)</span><br><span class="line">I0313 11:41:39.375437  9249 net.cpp:137] Memory required for data: 62337024</span><br><span class="line">I0313 11:41:39.375439  9249 layer_factory.hpp:77] Creating layer fc6</span><br><span class="line">I0313 11:41:39.375444  9249 net.cpp:84] Creating Layer fc6</span><br><span class="line">I0313 11:41:39.375447  9249 net.cpp:406] fc6 &lt;- pool5</span><br><span class="line">I0313 11:41:39.375452  9249 net.cpp:380] fc6 -&gt; fc6</span><br><span class="line">I0313 11:41:39.404399  9249 net.cpp:122] Setting up fc6</span><br><span class="line">I0313 11:41:39.404426  9249 net.cpp:129] Top shape: 1 4096 1 64 (262144)</span><br><span class="line">I0313 11:41:39.404430  9249 net.cpp:137] Memory required for data: 63385600</span><br><span class="line">I0313 11:41:39.404438  9249 layer_factory.hpp:77] Creating layer relu6</span><br><span class="line">I0313 11:41:39.404445  9249 net.cpp:84] Creating Layer relu6</span><br><span class="line">I0313 11:41:39.404449  9249 net.cpp:406] relu6 &lt;- fc6</span><br><span class="line">I0313 11:41:39.404453  9249 net.cpp:367] relu6 -&gt; fc6 (in-place)</span><br><span class="line">I0313 11:41:39.404460  9249 net.cpp:122] Setting up relu6</span><br><span class="line">I0313 11:41:39.404464  9249 net.cpp:129] Top shape: 1 4096 1 64 (262144)</span><br><span class="line">I0313 11:41:39.404466  9249 net.cpp:137] Memory required for data: 64434176</span><br><span class="line">I0313 11:41:39.404469  9249 layer_factory.hpp:77] Creating layer drop6</span><br><span class="line">I0313 11:41:39.404474  9249 net.cpp:84] Creating Layer drop6</span><br><span class="line">I0313 11:41:39.404476  9249 net.cpp:406] drop6 &lt;- fc6</span><br><span class="line">I0313 11:41:39.404481  9249 net.cpp:367] drop6 -&gt; fc6 (in-place)</span><br><span class="line">I0313 11:41:39.404486  9249 net.cpp:122] Setting up drop6</span><br><span class="line">I0313 11:41:39.404489  9249 net.cpp:129] Top shape: 1 4096 1 64 (262144)</span><br><span class="line">I0313 11:41:39.404492  9249 net.cpp:137] Memory required for data: 65482752</span><br><span class="line">I0313 11:41:39.404495  9249 layer_factory.hpp:77] Creating layer fc7</span><br><span class="line">I0313 11:41:39.404500  9249 net.cpp:84] Creating Layer fc7</span><br><span class="line">I0313 11:41:39.404503  9249 net.cpp:406] fc7 &lt;- fc6</span><br><span class="line">I0313 11:41:39.404506  9249 net.cpp:380] fc7 -&gt; fc7</span><br><span class="line">I0313 11:41:39.417629  9249 net.cpp:122] Setting up fc7</span><br><span class="line">I0313 11:41:39.417654  9249 net.cpp:129] Top shape: 1 4096 1 64 (262144)</span><br><span class="line">I0313 11:41:39.417657  9249 net.cpp:137] Memory required for data: 66531328</span><br><span class="line">I0313 11:41:39.417665  9249 layer_factory.hpp:77] Creating layer relu7</span><br><span class="line">I0313 11:41:39.417672  9249 net.cpp:84] Creating Layer relu7</span><br><span class="line">I0313 11:41:39.417676  9249 net.cpp:406] relu7 &lt;- fc7</span><br><span class="line">I0313 11:41:39.417680  9249 net.cpp:367] relu7 -&gt; fc7 (in-place)</span><br><span class="line">I0313 11:41:39.417687  9249 net.cpp:122] Setting up relu7</span><br><span class="line">I0313 11:41:39.417690  9249 net.cpp:129] Top shape: 1 4096 1 64 (262144)</span><br><span class="line">I0313 11:41:39.417693  9249 net.cpp:137] Memory required for data: 67579904</span><br><span class="line">I0313 11:41:39.417696  9249 layer_factory.hpp:77] Creating layer drop7</span><br><span class="line">I0313 11:41:39.417703  9249 net.cpp:84] Creating Layer drop7</span><br><span class="line">I0313 11:41:39.417706  9249 net.cpp:406] drop7 &lt;- fc7</span><br><span class="line">I0313 11:41:39.417709  9249 net.cpp:367] drop7 -&gt; fc7 (in-place)</span><br><span class="line">I0313 11:41:39.417713  9249 net.cpp:122] Setting up drop7</span><br><span class="line">I0313 11:41:39.417716  9249 net.cpp:129] Top shape: 1 4096 1 64 (262144)</span><br><span class="line">I0313 11:41:39.417719  9249 net.cpp:137] Memory required for data: 68628480</span><br><span class="line">I0313 11:41:39.417721  9249 layer_factory.hpp:77] Creating layer score_fr</span><br><span class="line">I0313 11:41:39.417727  9249 net.cpp:84] Creating Layer score_fr</span><br><span class="line">I0313 11:41:39.417729  9249 net.cpp:406] score_fr &lt;- fc7</span><br><span class="line">I0313 11:41:39.417734  9249 net.cpp:380] score_fr -&gt; score_fr</span><br><span class="line">I0313 11:41:39.417858  9249 net.cpp:122] Setting up score_fr</span><br><span class="line">I0313 11:41:39.417865  9249 net.cpp:129] Top shape: 1 21 1 64 (1344)</span><br><span class="line">I0313 11:41:39.417867  9249 net.cpp:137] Memory required for data: 68633856</span><br><span class="line">I0313 11:41:39.417871  9249 layer_factory.hpp:77] Creating layer upscore</span><br><span class="line">I0313 11:41:39.417877  9249 net.cpp:84] Creating Layer upscore</span><br><span class="line">I0313 11:41:39.417881  9249 net.cpp:406] upscore &lt;- score_fr</span><br><span class="line">I0313 11:41:39.417884  9249 net.cpp:380] upscore -&gt; upscore</span><br><span class="line">I0313 11:41:39.419461  9249 net.cpp:122] Setting up upscore</span><br><span class="line">I0313 11:41:39.419472  9249 net.cpp:129] Top shape: 1 21 63 2079 (2750517)</span><br><span class="line">I0313 11:41:39.419476  9249 net.cpp:137] Memory required for data: 79635924</span><br><span class="line">I0313 11:41:39.419484  9249 layer_factory.hpp:77] Creating layer score</span><br><span class="line">I0313 11:41:39.419497  9249 net.cpp:84] Creating Layer score</span><br><span class="line">I0313 11:41:39.419499  9249 net.cpp:406] score &lt;- upscore</span><br><span class="line">I0313 11:41:39.419503  9249 net.cpp:406] score &lt;- data_data_0_split_1</span><br><span class="line">I0313 11:41:39.419507  9249 net.cpp:380] score -&gt; score</span><br><span class="line">I0313 11:41:39.419517  9249 net.cpp:122] Setting up score</span><br><span class="line">I0313 11:41:39.419539  9249 net.cpp:129] Top shape: 1 21 16 2016 (677376)</span><br><span class="line">I0313 11:41:39.419543  9249 net.cpp:137] Memory required for data: 82345428</span><br><span class="line">I0313 11:41:39.419544  9249 layer_factory.hpp:77] Creating layer loss</span><br><span class="line">I0313 11:41:39.419554  9249 net.cpp:84] Creating Layer loss</span><br><span class="line">I0313 11:41:39.419558  9249 net.cpp:406] loss &lt;- score</span><br><span class="line">I0313 11:41:39.419560  9249 net.cpp:406] loss &lt;- label</span><br><span class="line">I0313 11:41:39.419564  9249 net.cpp:380] loss -&gt; loss</span><br><span class="line">I0313 11:41:39.419572  9249 layer_factory.hpp:77] Creating layer loss</span><br><span class="line">I0313 11:41:39.420116  9249 net.cpp:122] Setting up loss</span><br><span class="line">I0313 11:41:39.420122  9249 net.cpp:129] Top shape: (1)</span><br><span class="line">I0313 11:41:39.420125  9249 net.cpp:132]     with loss weight 1</span><br><span class="line">I0313 11:41:39.420135  9249 net.cpp:137] Memory required for data: 82345432</span><br><span class="line">I0313 11:41:39.420137  9249 net.cpp:198] loss needs backward computation.</span><br><span class="line">I0313 11:41:39.420140  9249 net.cpp:198] score needs backward computation.</span><br><span class="line">I0313 11:41:39.420143  9249 net.cpp:198] upscore needs backward computation.</span><br><span class="line">I0313 11:41:39.420145  9249 net.cpp:198] score_fr needs backward computation.</span><br><span class="line">I0313 11:41:39.420148  9249 net.cpp:198] drop7 needs backward computation.</span><br><span class="line">I0313 11:41:39.420151  9249 net.cpp:198] relu7 needs backward computation.</span><br><span class="line">I0313 11:41:39.420155  9249 net.cpp:198] fc7 needs backward computation.</span><br><span class="line">I0313 11:41:39.420156  9249 net.cpp:198] drop6 needs backward computation.</span><br><span class="line">I0313 11:41:39.420159  9249 net.cpp:198] relu6 needs backward computation.</span><br><span class="line">I0313 11:41:39.420161  9249 net.cpp:198] fc6 needs backward computation.</span><br><span class="line">I0313 11:41:39.420164  9249 net.cpp:198] pool5 needs backward computation.</span><br><span class="line">I0313 11:41:39.420167  9249 net.cpp:198] relu5 needs backward computation.</span><br><span class="line">I0313 11:41:39.420169  9249 net.cpp:198] conv5 needs backward computation.</span><br><span class="line">I0313 11:41:39.420172  9249 net.cpp:198] relu4 needs backward computation.</span><br><span class="line">I0313 11:41:39.420176  9249 net.cpp:198] conv4 needs backward computation.</span><br><span class="line">I0313 11:41:39.420177  9249 net.cpp:198] relu3 needs backward computation.</span><br><span class="line">I0313 11:41:39.420181  9249 net.cpp:198] conv3 needs backward computation.</span><br><span class="line">I0313 11:41:39.420183  9249 net.cpp:198] norm2 needs backward computation.</span><br><span class="line">I0313 11:41:39.420186  9249 net.cpp:198] pool2 needs backward computation.</span><br><span class="line">I0313 11:41:39.420189  9249 net.cpp:198] relu2 needs backward computation.</span><br><span class="line">I0313 11:41:39.420192  9249 net.cpp:198] conv2 needs backward computation.</span><br><span class="line">I0313 11:41:39.420194  9249 net.cpp:198] norm1 needs backward computation.</span><br><span class="line">I0313 11:41:39.420197  9249 net.cpp:198] pool1 needs backward computation.</span><br><span class="line">I0313 11:41:39.420200  9249 net.cpp:198] relu1 needs backward computation.</span><br><span class="line">I0313 11:41:39.420203  9249 net.cpp:198] conv1 needs backward computation.</span><br><span class="line">I0313 11:41:39.420207  9249 net.cpp:200] data_data_0_split does not need backward computation.</span><br><span class="line">I0313 11:41:39.420210  9249 net.cpp:200] data does not need backward computation.</span><br><span class="line">I0313 11:41:39.420212  9249 net.cpp:242] This network produces output loss</span><br><span class="line">I0313 11:41:39.420224  9249 net.cpp:255] Network initialization done.</span><br><span class="line">I0313 11:41:39.420586  9249 solver.cpp:190] Creating test net (#0) specified by test_net file: val.prototxt</span><br><span class="line">I0313 11:41:39.420764  9249 net.cpp:51] Initializing net from parameters: </span><br><span class="line">state &#123;</span><br><span class="line">  phase: TEST</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;data&quot;</span><br><span class="line">  type: &quot;Python&quot;</span><br><span class="line">  top: &quot;data&quot;</span><br><span class="line">  top: &quot;label&quot;</span><br><span class="line">  python_param &#123;</span><br><span class="line">    module: &quot;pcl_data_layer&quot;</span><br><span class="line">    layer: &quot;PCLSegDataLayer&quot;</span><br><span class="line">    param_str: &quot;&#123;\&#39;pcl_dir\&#39;: \&#39;&#x2F;home&#x2F;zzy&#x2F;CLionProjects&#x2F;ROS_Project&#x2F;ws&#x2F;src&#x2F;fcn_data_gen&#x2F;data&#x2F;npy\&#39;&#125;&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;conv1&quot;</span><br><span class="line">  type: &quot;Convolution&quot;</span><br><span class="line">  bottom: &quot;data&quot;</span><br><span class="line">  top: &quot;conv1&quot;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 96</span><br><span class="line">    pad: 100</span><br><span class="line">    kernel_size: 11</span><br><span class="line">    group: 1</span><br><span class="line">    stride: 4</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;relu1&quot;</span><br><span class="line">  type: &quot;ReLU&quot;</span><br><span class="line">  bottom: &quot;conv1&quot;</span><br><span class="line">  top: &quot;conv1&quot;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;pool1&quot;</span><br><span class="line">  type: &quot;Pooling&quot;</span><br><span class="line">  bottom: &quot;conv1&quot;</span><br><span class="line">  top: &quot;pool1&quot;</span><br><span class="line">  pooling_param &#123;</span><br><span class="line">    pool: MAX</span><br><span class="line">    kernel_size: 3</span><br><span class="line">    stride: 2</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;norm1&quot;</span><br><span class="line">  type: &quot;LRN&quot;</span><br><span class="line">  bottom: &quot;pool1&quot;</span><br><span class="line">  top: &quot;norm1&quot;</span><br><span class="line">  lrn_param &#123;</span><br><span class="line">    local_size: 5</span><br><span class="line">    alpha: 0.0001</span><br><span class="line">    beta: 0.75</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;conv2&quot;</span><br><span class="line">  type: &quot;Convolution&quot;</span><br><span class="line">  bottom: &quot;norm1&quot;</span><br><span class="line">  top: &quot;conv2&quot;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 256</span><br><span class="line">    pad: 2</span><br><span class="line">    kernel_size: 5</span><br><span class="line">    group: 2</span><br><span class="line">    stride: 1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;relu2&quot;</span><br><span class="line">  type: &quot;ReLU&quot;</span><br><span class="line">  bottom: &quot;conv2&quot;</span><br><span class="line">  top: &quot;conv2&quot;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;pool2&quot;</span><br><span class="line">  type: &quot;Pooling&quot;</span><br><span class="line">  bottom: &quot;conv2&quot;</span><br><span class="line">  top: &quot;pool2&quot;</span><br><span class="line">  pooling_param &#123;</span><br><span class="line">    pool: MAX</span><br><span class="line">    kernel_size: 3</span><br><span class="line">    stride: 2</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;norm2&quot;</span><br><span class="line">  type: &quot;LRN&quot;</span><br><span class="line">  bottom: &quot;pool2&quot;</span><br><span class="line">  top: &quot;norm2&quot;</span><br><span class="line">  lrn_param &#123;</span><br><span class="line">    local_size: 5</span><br><span class="line">    alpha: 0.0001</span><br><span class="line">    beta: 0.75</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;conv3&quot;</span><br><span class="line">  type: &quot;Convolution&quot;</span><br><span class="line">  bottom: &quot;norm2&quot;</span><br><span class="line">  top: &quot;conv3&quot;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 384</span><br><span class="line">    pad: 1</span><br><span class="line">    kernel_size: 3</span><br><span class="line">    group: 1</span><br><span class="line">    stride: 1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;relu3&quot;</span><br><span class="line">  type: &quot;ReLU&quot;</span><br><span class="line">  bottom: &quot;conv3&quot;</span><br><span class="line">  top: &quot;conv3&quot;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;conv4&quot;</span><br><span class="line">  type: &quot;Convolution&quot;</span><br><span class="line">  bottom: &quot;conv3&quot;</span><br><span class="line">  top: &quot;conv4&quot;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 384</span><br><span class="line">    pad: 1</span><br><span class="line">    kernel_size: 3</span><br><span class="line">    group: 2</span><br><span class="line">    stride: 1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;relu4&quot;</span><br><span class="line">  type: &quot;ReLU&quot;</span><br><span class="line">  bottom: &quot;conv4&quot;</span><br><span class="line">  top: &quot;conv4&quot;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;conv5&quot;</span><br><span class="line">  type: &quot;Convolution&quot;</span><br><span class="line">  bottom: &quot;conv4&quot;</span><br><span class="line">  top: &quot;conv5&quot;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 256</span><br><span class="line">    pad: 1</span><br><span class="line">    kernel_size: 3</span><br><span class="line">    group: 2</span><br><span class="line">    stride: 1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;relu5&quot;</span><br><span class="line">  type: &quot;ReLU&quot;</span><br><span class="line">  bottom: &quot;conv5&quot;</span><br><span class="line">  top: &quot;conv5&quot;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;pool5&quot;</span><br><span class="line">  type: &quot;Pooling&quot;</span><br><span class="line">  bottom: &quot;conv5&quot;</span><br><span class="line">  top: &quot;pool5&quot;</span><br><span class="line">  pooling_param &#123;</span><br><span class="line">    pool: MAX</span><br><span class="line">    kernel_size: 3</span><br><span class="line">    stride: 2</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;fc6&quot;</span><br><span class="line">  type: &quot;Convolution&quot;</span><br><span class="line">  bottom: &quot;pool5&quot;</span><br><span class="line">  top: &quot;fc6&quot;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 4096</span><br><span class="line">    pad: 0</span><br><span class="line">    kernel_size: 6</span><br><span class="line">    group: 1</span><br><span class="line">    stride: 1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;relu6&quot;</span><br><span class="line">  type: &quot;ReLU&quot;</span><br><span class="line">  bottom: &quot;fc6&quot;</span><br><span class="line">  top: &quot;fc6&quot;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;drop6&quot;</span><br><span class="line">  type: &quot;Dropout&quot;</span><br><span class="line">  bottom: &quot;fc6&quot;</span><br><span class="line">  top: &quot;fc6&quot;</span><br><span class="line">  dropout_param &#123;</span><br><span class="line">    dropout_ratio: 0.5</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;fc7&quot;</span><br><span class="line">  type: &quot;Convolution&quot;</span><br><span class="line">  bottom: &quot;fc6&quot;</span><br><span class="line">  top: &quot;fc7&quot;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 4096</span><br><span class="line">    pad: 0</span><br><span class="line">    kernel_size: 1</span><br><span class="line">    group: 1</span><br><span class="line">    stride: 1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;relu7&quot;</span><br><span class="line">  type: &quot;ReLU&quot;</span><br><span class="line">  bottom: &quot;fc7&quot;</span><br><span class="line">  top: &quot;fc7&quot;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;drop7&quot;</span><br><span class="line">  type: &quot;Dropout&quot;</span><br><span class="line">  bottom: &quot;fc7&quot;</span><br><span class="line">  top: &quot;fc7&quot;</span><br><span class="line">  dropout_param &#123;</span><br><span class="line">    dropout_ratio: 0.5</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;score_fr&quot;</span><br><span class="line">  type: &quot;Convolution&quot;</span><br><span class="line">  bottom: &quot;fc7&quot;</span><br><span class="line">  top: &quot;score_fr&quot;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 1</span><br><span class="line">    decay_mult: 1</span><br><span class="line">  &#125;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 2</span><br><span class="line">    decay_mult: 0</span><br><span class="line">  &#125;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 21</span><br><span class="line">    pad: 0</span><br><span class="line">    kernel_size: 1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;upscore&quot;</span><br><span class="line">  type: &quot;Deconvolution&quot;</span><br><span class="line">  bottom: &quot;score_fr&quot;</span><br><span class="line">  top: &quot;upscore&quot;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 0</span><br><span class="line">  &#125;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 21</span><br><span class="line">    bias_term: false</span><br><span class="line">    kernel_size: 63</span><br><span class="line">    stride: 32</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;score&quot;</span><br><span class="line">  type: &quot;Crop&quot;</span><br><span class="line">  bottom: &quot;upscore&quot;</span><br><span class="line">  bottom: &quot;data&quot;</span><br><span class="line">  top: &quot;score&quot;</span><br><span class="line">  crop_param &#123;</span><br><span class="line">    axis: 2</span><br><span class="line">    offset: 18</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;loss&quot;</span><br><span class="line">  type: &quot;SoftmaxWithLoss&quot;</span><br><span class="line">  bottom: &quot;score&quot;</span><br><span class="line">  bottom: &quot;label&quot;</span><br><span class="line">  top: &quot;loss&quot;</span><br><span class="line">  loss_param &#123;</span><br><span class="line">    ignore_label: 255</span><br><span class="line">    normalize: true</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">I0313 11:41:39.420830  9249 layer_factory.hpp:77] Creating layer data</span><br><span class="line">I0313 11:41:39.420866  9249 net.cpp:84] Creating Layer data</span><br><span class="line">I0313 11:41:39.420871  9249 net.cpp:380] data -&gt; data</span><br><span class="line">I0313 11:41:39.420877  9249 net.cpp:380] data -&gt; label</span><br><span class="line">I0313 11:41:39.422286  9249 net.cpp:122] Setting up data</span><br><span class="line">I0313 11:41:39.422296  9249 net.cpp:129] Top shape: 1 3 16 2016 (96768)</span><br><span class="line">I0313 11:41:39.422299  9249 net.cpp:129] Top shape: 1 16 2016 (32256)</span><br><span class="line">I0313 11:41:39.422302  9249 net.cpp:137] Memory required for data: 516096</span><br><span class="line">I0313 11:41:39.422305  9249 layer_factory.hpp:77] Creating layer data_data_0_split</span><br><span class="line">I0313 11:41:39.422310  9249 net.cpp:84] Creating Layer data_data_0_split</span><br><span class="line">I0313 11:41:39.422313  9249 net.cpp:406] data_data_0_split &lt;- data</span><br><span class="line">I0313 11:41:39.422317  9249 net.cpp:380] data_data_0_split -&gt; data_data_0_split_0</span><br><span class="line">I0313 11:41:39.422322  9249 net.cpp:380] data_data_0_split -&gt; data_data_0_split_1</span><br><span class="line">I0313 11:41:39.422327  9249 net.cpp:122] Setting up data_data_0_split</span><br><span class="line">I0313 11:41:39.422332  9249 net.cpp:129] Top shape: 1 3 16 2016 (96768)</span><br><span class="line">I0313 11:41:39.422334  9249 net.cpp:129] Top shape: 1 3 16 2016 (96768)</span><br><span class="line">I0313 11:41:39.422338  9249 net.cpp:137] Memory required for data: 1290240</span><br><span class="line">I0313 11:41:39.422339  9249 layer_factory.hpp:77] Creating layer conv1</span><br><span class="line">I0313 11:41:39.422346  9249 net.cpp:84] Creating Layer conv1</span><br><span class="line">I0313 11:41:39.422349  9249 net.cpp:406] conv1 &lt;- data_data_0_split_0</span><br><span class="line">I0313 11:41:39.422353  9249 net.cpp:380] conv1 -&gt; conv1</span><br><span class="line">I0313 11:41:39.422446  9249 net.cpp:122] Setting up conv1</span><br><span class="line">I0313 11:41:39.422451  9249 net.cpp:129] Top shape: 1 96 52 552 (2755584)</span><br><span class="line">I0313 11:41:39.422454  9249 net.cpp:137] Memory required for data: 12312576</span><br><span class="line">I0313 11:41:39.422461  9249 layer_factory.hpp:77] Creating layer relu1</span><br><span class="line">I0313 11:41:39.422466  9249 net.cpp:84] Creating Layer relu1</span><br><span class="line">I0313 11:41:39.422469  9249 net.cpp:406] relu1 &lt;- conv1</span><br><span class="line">I0313 11:41:39.422472  9249 net.cpp:367] relu1 -&gt; conv1 (in-place)</span><br><span class="line">I0313 11:41:39.422477  9249 net.cpp:122] Setting up relu1</span><br><span class="line">I0313 11:41:39.422479  9249 net.cpp:129] Top shape: 1 96 52 552 (2755584)</span><br><span class="line">I0313 11:41:39.422482  9249 net.cpp:137] Memory required for data: 23334912</span><br><span class="line">I0313 11:41:39.422484  9249 layer_factory.hpp:77] Creating layer pool1</span><br><span class="line">I0313 11:41:39.422488  9249 net.cpp:84] Creating Layer pool1</span><br><span class="line">I0313 11:41:39.422490  9249 net.cpp:406] pool1 &lt;- conv1</span><br><span class="line">I0313 11:41:39.422495  9249 net.cpp:380] pool1 -&gt; pool1</span><br><span class="line">I0313 11:41:39.422502  9249 net.cpp:122] Setting up pool1</span><br><span class="line">I0313 11:41:39.422504  9249 net.cpp:129] Top shape: 1 96 26 276 (688896)</span><br><span class="line">I0313 11:41:39.422507  9249 net.cpp:137] Memory required for data: 26090496</span><br><span class="line">I0313 11:41:39.422508  9249 layer_factory.hpp:77] Creating layer norm1</span><br><span class="line">I0313 11:41:39.422513  9249 net.cpp:84] Creating Layer norm1</span><br><span class="line">I0313 11:41:39.422516  9249 net.cpp:406] norm1 &lt;- pool1</span><br><span class="line">I0313 11:41:39.422519  9249 net.cpp:380] norm1 -&gt; norm1</span><br><span class="line">I0313 11:41:39.422524  9249 net.cpp:122] Setting up norm1</span><br><span class="line">I0313 11:41:39.422528  9249 net.cpp:129] Top shape: 1 96 26 276 (688896)</span><br><span class="line">I0313 11:41:39.422529  9249 net.cpp:137] Memory required for data: 28846080</span><br><span class="line">I0313 11:41:39.422531  9249 layer_factory.hpp:77] Creating layer conv2</span><br><span class="line">I0313 11:41:39.422536  9249 net.cpp:84] Creating Layer conv2</span><br><span class="line">I0313 11:41:39.422539  9249 net.cpp:406] conv2 &lt;- norm1</span><br><span class="line">I0313 11:41:39.422543  9249 net.cpp:380] conv2 -&gt; conv2</span><br><span class="line">I0313 11:41:39.422933  9249 net.cpp:122] Setting up conv2</span><br><span class="line">I0313 11:41:39.422940  9249 net.cpp:129] Top shape: 1 256 26 276 (1837056)</span><br><span class="line">I0313 11:41:39.422941  9249 net.cpp:137] Memory required for data: 36194304</span><br><span class="line">I0313 11:41:39.422947  9249 layer_factory.hpp:77] Creating layer relu2</span><br><span class="line">I0313 11:41:39.422951  9249 net.cpp:84] Creating Layer relu2</span><br><span class="line">I0313 11:41:39.422955  9249 net.cpp:406] relu2 &lt;- conv2</span><br><span class="line">I0313 11:41:39.422958  9249 net.cpp:367] relu2 -&gt; conv2 (in-place)</span><br><span class="line">I0313 11:41:39.422962  9249 net.cpp:122] Setting up relu2</span><br><span class="line">I0313 11:41:39.422966  9249 net.cpp:129] Top shape: 1 256 26 276 (1837056)</span><br><span class="line">I0313 11:41:39.422967  9249 net.cpp:137] Memory required for data: 43542528</span><br><span class="line">I0313 11:41:39.422971  9249 layer_factory.hpp:77] Creating layer pool2</span><br><span class="line">I0313 11:41:39.422973  9249 net.cpp:84] Creating Layer pool2</span><br><span class="line">I0313 11:41:39.422976  9249 net.cpp:406] pool2 &lt;- conv2</span><br><span class="line">I0313 11:41:39.422979  9249 net.cpp:380] pool2 -&gt; pool2</span><br><span class="line">I0313 11:41:39.422984  9249 net.cpp:122] Setting up pool2</span><br><span class="line">I0313 11:41:39.422988  9249 net.cpp:129] Top shape: 1 256 13 138 (459264)</span><br><span class="line">I0313 11:41:39.422991  9249 net.cpp:137] Memory required for data: 45379584</span><br><span class="line">I0313 11:41:39.422992  9249 layer_factory.hpp:77] Creating layer norm2</span><br><span class="line">I0313 11:41:39.422997  9249 net.cpp:84] Creating Layer norm2</span><br><span class="line">I0313 11:41:39.422999  9249 net.cpp:406] norm2 &lt;- pool2</span><br><span class="line">I0313 11:41:39.423003  9249 net.cpp:380] norm2 -&gt; norm2</span><br><span class="line">I0313 11:41:39.423008  9249 net.cpp:122] Setting up norm2</span><br><span class="line">I0313 11:41:39.423012  9249 net.cpp:129] Top shape: 1 256 13 138 (459264)</span><br><span class="line">I0313 11:41:39.423013  9249 net.cpp:137] Memory required for data: 47216640</span><br><span class="line">I0313 11:41:39.423015  9249 layer_factory.hpp:77] Creating layer conv3</span><br><span class="line">I0313 11:41:39.423020  9249 net.cpp:84] Creating Layer conv3</span><br><span class="line">I0313 11:41:39.423023  9249 net.cpp:406] conv3 &lt;- norm2</span><br><span class="line">I0313 11:41:39.423027  9249 net.cpp:380] conv3 -&gt; conv3</span><br><span class="line">I0313 11:41:39.423882  9249 net.cpp:122] Setting up conv3</span><br><span class="line">I0313 11:41:39.423888  9249 net.cpp:129] Top shape: 1 384 13 138 (688896)</span><br><span class="line">I0313 11:41:39.423892  9249 net.cpp:137] Memory required for data: 49972224</span><br><span class="line">I0313 11:41:39.423897  9249 layer_factory.hpp:77] Creating layer relu3</span><br><span class="line">I0313 11:41:39.423902  9249 net.cpp:84] Creating Layer relu3</span><br><span class="line">I0313 11:41:39.423904  9249 net.cpp:406] relu3 &lt;- conv3</span><br><span class="line">I0313 11:41:39.423907  9249 net.cpp:367] relu3 -&gt; conv3 (in-place)</span><br><span class="line">I0313 11:41:39.423912  9249 net.cpp:122] Setting up relu3</span><br><span class="line">I0313 11:41:39.423914  9249 net.cpp:129] Top shape: 1 384 13 138 (688896)</span><br><span class="line">I0313 11:41:39.423918  9249 net.cpp:137] Memory required for data: 52727808</span><br><span class="line">I0313 11:41:39.423919  9249 layer_factory.hpp:77] Creating layer conv4</span><br><span class="line">I0313 11:41:39.423923  9249 net.cpp:84] Creating Layer conv4</span><br><span class="line">I0313 11:41:39.423925  9249 net.cpp:406] conv4 &lt;- conv3</span><br><span class="line">I0313 11:41:39.423930  9249 net.cpp:380] conv4 -&gt; conv4</span><br><span class="line">I0313 11:41:39.424738  9249 net.cpp:122] Setting up conv4</span><br><span class="line">I0313 11:41:39.424744  9249 net.cpp:129] Top shape: 1 384 13 138 (688896)</span><br><span class="line">I0313 11:41:39.424747  9249 net.cpp:137] Memory required for data: 55483392</span><br><span class="line">I0313 11:41:39.424751  9249 layer_factory.hpp:77] Creating layer relu4</span><br><span class="line">I0313 11:41:39.424756  9249 net.cpp:84] Creating Layer relu4</span><br><span class="line">I0313 11:41:39.424757  9249 net.cpp:406] relu4 &lt;- conv4</span><br><span class="line">I0313 11:41:39.424762  9249 net.cpp:367] relu4 -&gt; conv4 (in-place)</span><br><span class="line">I0313 11:41:39.424764  9249 net.cpp:122] Setting up relu4</span><br><span class="line">I0313 11:41:39.424767  9249 net.cpp:129] Top shape: 1 384 13 138 (688896)</span><br><span class="line">I0313 11:41:39.424770  9249 net.cpp:137] Memory required for data: 58238976</span><br><span class="line">I0313 11:41:39.424772  9249 layer_factory.hpp:77] Creating layer conv5</span><br><span class="line">I0313 11:41:39.424777  9249 net.cpp:84] Creating Layer conv5</span><br><span class="line">I0313 11:41:39.424779  9249 net.cpp:406] conv5 &lt;- conv4</span><br><span class="line">I0313 11:41:39.424784  9249 net.cpp:380] conv5 -&gt; conv5</span><br><span class="line">I0313 11:41:39.425376  9249 net.cpp:122] Setting up conv5</span><br><span class="line">I0313 11:41:39.425384  9249 net.cpp:129] Top shape: 1 256 13 138 (459264)</span><br><span class="line">I0313 11:41:39.425385  9249 net.cpp:137] Memory required for data: 60076032</span><br><span class="line">I0313 11:41:39.425393  9249 layer_factory.hpp:77] Creating layer relu5</span><br><span class="line">I0313 11:41:39.425397  9249 net.cpp:84] Creating Layer relu5</span><br><span class="line">I0313 11:41:39.425400  9249 net.cpp:406] relu5 &lt;- conv5</span><br><span class="line">I0313 11:41:39.425403  9249 net.cpp:367] relu5 -&gt; conv5 (in-place)</span><br><span class="line">I0313 11:41:39.425406  9249 net.cpp:122] Setting up relu5</span><br><span class="line">I0313 11:41:39.425410  9249 net.cpp:129] Top shape: 1 256 13 138 (459264)</span><br><span class="line">I0313 11:41:39.425412  9249 net.cpp:137] Memory required for data: 61913088</span><br><span class="line">I0313 11:41:39.425415  9249 layer_factory.hpp:77] Creating layer pool5</span><br><span class="line">I0313 11:41:39.425420  9249 net.cpp:84] Creating Layer pool5</span><br><span class="line">I0313 11:41:39.425423  9249 net.cpp:406] pool5 &lt;- conv5</span><br><span class="line">I0313 11:41:39.425426  9249 net.cpp:380] pool5 -&gt; pool5</span><br><span class="line">I0313 11:41:39.425432  9249 net.cpp:122] Setting up pool5</span><br><span class="line">I0313 11:41:39.425436  9249 net.cpp:129] Top shape: 1 256 6 69 (105984)</span><br><span class="line">I0313 11:41:39.425437  9249 net.cpp:137] Memory required for data: 62337024</span><br><span class="line">I0313 11:41:39.425441  9249 layer_factory.hpp:77] Creating layer fc6</span><br><span class="line">I0313 11:41:39.425446  9249 net.cpp:84] Creating Layer fc6</span><br><span class="line">I0313 11:41:39.425448  9249 net.cpp:406] fc6 &lt;- pool5</span><br><span class="line">I0313 11:41:39.425452  9249 net.cpp:380] fc6 -&gt; fc6</span><br><span class="line">I0313 11:41:39.454087  9249 net.cpp:122] Setting up fc6</span><br><span class="line">I0313 11:41:39.454115  9249 net.cpp:129] Top shape: 1 4096 1 64 (262144)</span><br><span class="line">I0313 11:41:39.454118  9249 net.cpp:137] Memory required for data: 63385600</span><br><span class="line">I0313 11:41:39.454126  9249 layer_factory.hpp:77] Creating layer relu6</span><br><span class="line">I0313 11:41:39.454134  9249 net.cpp:84] Creating Layer relu6</span><br><span class="line">I0313 11:41:39.454138  9249 net.cpp:406] relu6 &lt;- fc6</span><br><span class="line">I0313 11:41:39.454143  9249 net.cpp:367] relu6 -&gt; fc6 (in-place)</span><br><span class="line">I0313 11:41:39.454149  9249 net.cpp:122] Setting up relu6</span><br><span class="line">I0313 11:41:39.454152  9249 net.cpp:129] Top shape: 1 4096 1 64 (262144)</span><br><span class="line">I0313 11:41:39.454155  9249 net.cpp:137] Memory required for data: 64434176</span><br><span class="line">I0313 11:41:39.454157  9249 layer_factory.hpp:77] Creating layer drop6</span><br><span class="line">I0313 11:41:39.454162  9249 net.cpp:84] Creating Layer drop6</span><br><span class="line">I0313 11:41:39.454165  9249 net.cpp:406] drop6 &lt;- fc6</span><br><span class="line">I0313 11:41:39.454169  9249 net.cpp:367] drop6 -&gt; fc6 (in-place)</span><br><span class="line">I0313 11:41:39.454174  9249 net.cpp:122] Setting up drop6</span><br><span class="line">I0313 11:41:39.454177  9249 net.cpp:129] Top shape: 1 4096 1 64 (262144)</span><br><span class="line">I0313 11:41:39.454180  9249 net.cpp:137] Memory required for data: 65482752</span><br><span class="line">I0313 11:41:39.454182  9249 layer_factory.hpp:77] Creating layer fc7</span><br><span class="line">I0313 11:41:39.454188  9249 net.cpp:84] Creating Layer fc7</span><br><span class="line">I0313 11:41:39.454190  9249 net.cpp:406] fc7 &lt;- fc6</span><br><span class="line">I0313 11:41:39.454195  9249 net.cpp:380] fc7 -&gt; fc7</span><br><span class="line">I0313 11:41:39.467375  9249 net.cpp:122] Setting up fc7</span><br><span class="line">I0313 11:41:39.467401  9249 net.cpp:129] Top shape: 1 4096 1 64 (262144)</span><br><span class="line">I0313 11:41:39.467403  9249 net.cpp:137] Memory required for data: 66531328</span><br><span class="line">I0313 11:41:39.467411  9249 layer_factory.hpp:77] Creating layer relu7</span><br><span class="line">I0313 11:41:39.467418  9249 net.cpp:84] Creating Layer relu7</span><br><span class="line">I0313 11:41:39.467422  9249 net.cpp:406] relu7 &lt;- fc7</span><br><span class="line">I0313 11:41:39.467427  9249 net.cpp:367] relu7 -&gt; fc7 (in-place)</span><br><span class="line">I0313 11:41:39.467433  9249 net.cpp:122] Setting up relu7</span><br><span class="line">I0313 11:41:39.467437  9249 net.cpp:129] Top shape: 1 4096 1 64 (262144)</span><br><span class="line">I0313 11:41:39.467439  9249 net.cpp:137] Memory required for data: 67579904</span><br><span class="line">I0313 11:41:39.467442  9249 layer_factory.hpp:77] Creating layer drop7</span><br><span class="line">I0313 11:41:39.467449  9249 net.cpp:84] Creating Layer drop7</span><br><span class="line">I0313 11:41:39.467452  9249 net.cpp:406] drop7 &lt;- fc7</span><br><span class="line">I0313 11:41:39.467455  9249 net.cpp:367] drop7 -&gt; fc7 (in-place)</span><br><span class="line">I0313 11:41:39.467460  9249 net.cpp:122] Setting up drop7</span><br><span class="line">I0313 11:41:39.467463  9249 net.cpp:129] Top shape: 1 4096 1 64 (262144)</span><br><span class="line">I0313 11:41:39.467465  9249 net.cpp:137] Memory required for data: 68628480</span><br><span class="line">I0313 11:41:39.467468  9249 layer_factory.hpp:77] Creating layer score_fr</span><br><span class="line">I0313 11:41:39.467474  9249 net.cpp:84] Creating Layer score_fr</span><br><span class="line">I0313 11:41:39.467476  9249 net.cpp:406] score_fr &lt;- fc7</span><br><span class="line">I0313 11:41:39.467481  9249 net.cpp:380] score_fr -&gt; score_fr</span><br><span class="line">I0313 11:41:39.467617  9249 net.cpp:122] Setting up score_fr</span><br><span class="line">I0313 11:41:39.467622  9249 net.cpp:129] Top shape: 1 21 1 64 (1344)</span><br><span class="line">I0313 11:41:39.467624  9249 net.cpp:137] Memory required for data: 68633856</span><br><span class="line">I0313 11:41:39.467629  9249 layer_factory.hpp:77] Creating layer upscore</span><br><span class="line">I0313 11:41:39.467635  9249 net.cpp:84] Creating Layer upscore</span><br><span class="line">I0313 11:41:39.467638  9249 net.cpp:406] upscore &lt;- score_fr</span><br><span class="line">I0313 11:41:39.467643  9249 net.cpp:380] upscore -&gt; upscore</span><br><span class="line">I0313 11:41:39.469235  9249 net.cpp:122] Setting up upscore</span><br><span class="line">I0313 11:41:39.469246  9249 net.cpp:129] Top shape: 1 21 63 2079 (2750517)</span><br><span class="line">I0313 11:41:39.469249  9249 net.cpp:137] Memory required for data: 79635924</span><br><span class="line">I0313 11:41:39.469259  9249 layer_factory.hpp:77] Creating layer score</span><br><span class="line">I0313 11:41:39.469266  9249 net.cpp:84] Creating Layer score</span><br><span class="line">I0313 11:41:39.469269  9249 net.cpp:406] score &lt;- upscore</span><br><span class="line">I0313 11:41:39.469272  9249 net.cpp:406] score &lt;- data_data_0_split_1</span><br><span class="line">I0313 11:41:39.469276  9249 net.cpp:380] score -&gt; score</span><br><span class="line">I0313 11:41:39.469285  9249 net.cpp:122] Setting up score</span><br><span class="line">I0313 11:41:39.469288  9249 net.cpp:129] Top shape: 1 21 16 2016 (677376)</span><br><span class="line">I0313 11:41:39.469290  9249 net.cpp:137] Memory required for data: 82345428</span><br><span class="line">I0313 11:41:39.469293  9249 layer_factory.hpp:77] Creating layer loss</span><br><span class="line">I0313 11:41:39.469300  9249 net.cpp:84] Creating Layer loss</span><br><span class="line">I0313 11:41:39.469301  9249 net.cpp:406] loss &lt;- score</span><br><span class="line">I0313 11:41:39.469305  9249 net.cpp:406] loss &lt;- label</span><br><span class="line">I0313 11:41:39.469308  9249 net.cpp:380] loss -&gt; loss</span><br><span class="line">I0313 11:41:39.469314  9249 layer_factory.hpp:77] Creating layer loss</span><br><span class="line">I0313 11:41:39.469894  9249 net.cpp:122] Setting up loss</span><br><span class="line">I0313 11:41:39.469900  9249 net.cpp:129] Top shape: (1)</span><br><span class="line">I0313 11:41:39.469903  9249 net.cpp:132]     with loss weight 1</span><br><span class="line">I0313 11:41:39.469913  9249 net.cpp:137] Memory required for data: 82345432</span><br><span class="line">I0313 11:41:39.469915  9249 net.cpp:198] loss needs backward computation.</span><br><span class="line">I0313 11:41:39.469918  9249 net.cpp:198] score needs backward computation.</span><br><span class="line">I0313 11:41:39.469920  9249 net.cpp:198] upscore needs backward computation.</span><br><span class="line">I0313 11:41:39.469923  9249 net.cpp:198] score_fr needs backward computation.</span><br><span class="line">I0313 11:41:39.469926  9249 net.cpp:198] drop7 needs backward computation.</span><br><span class="line">I0313 11:41:39.469929  9249 net.cpp:198] relu7 needs backward computation.</span><br><span class="line">I0313 11:41:39.469931  9249 net.cpp:198] fc7 needs backward computation.</span><br><span class="line">I0313 11:41:39.469934  9249 net.cpp:198] drop6 needs backward computation.</span><br><span class="line">I0313 11:41:39.469936  9249 net.cpp:198] relu6 needs backward computation.</span><br><span class="line">I0313 11:41:39.469939  9249 net.cpp:198] fc6 needs backward computation.</span><br><span class="line">I0313 11:41:39.469943  9249 net.cpp:198] pool5 needs backward computation.</span><br><span class="line">I0313 11:41:39.469945  9249 net.cpp:198] relu5 needs backward computation.</span><br><span class="line">I0313 11:41:39.469947  9249 net.cpp:198] conv5 needs backward computation.</span><br><span class="line">I0313 11:41:39.469950  9249 net.cpp:198] relu4 needs backward computation.</span><br><span class="line">I0313 11:41:39.469952  9249 net.cpp:198] conv4 needs backward computation.</span><br><span class="line">I0313 11:41:39.469955  9249 net.cpp:198] relu3 needs backward computation.</span><br><span class="line">I0313 11:41:39.469957  9249 net.cpp:198] conv3 needs backward computation.</span><br><span class="line">I0313 11:41:39.469960  9249 net.cpp:198] norm2 needs backward computation.</span><br><span class="line">I0313 11:41:39.469964  9249 net.cpp:198] pool2 needs backward computation.</span><br><span class="line">I0313 11:41:39.469965  9249 net.cpp:198] relu2 needs backward computation.</span><br><span class="line">I0313 11:41:39.469969  9249 net.cpp:198] conv2 needs backward computation.</span><br><span class="line">I0313 11:41:39.469971  9249 net.cpp:198] norm1 needs backward computation.</span><br><span class="line">I0313 11:41:39.469974  9249 net.cpp:198] pool1 needs backward computation.</span><br><span class="line">I0313 11:41:39.469979  9249 net.cpp:198] relu1 needs backward computation.</span><br><span class="line">I0313 11:41:39.469981  9249 net.cpp:198] conv1 needs backward computation.</span><br><span class="line">I0313 11:41:39.469985  9249 net.cpp:200] data_data_0_split does not need backward computation.</span><br><span class="line">I0313 11:41:39.469987  9249 net.cpp:200] data does not need backward computation.</span><br><span class="line">I0313 11:41:39.469990  9249 net.cpp:242] This network produces output loss</span><br><span class="line">I0313 11:41:39.470001  9249 net.cpp:255] Network initialization done.</span><br><span class="line">I0313 11:41:39.470055  9249 solver.cpp:57] Solver scaffolding done.</span><br><span class="line">I0313 11:42:40.745103  9249 solver.cpp:239] Iteration 0 (-1.4013e-45 iter&#x2F;s, 61.136s&#x2F;20 iters), loss &#x3D; 4.54161</span><br><span class="line">I0313 11:42:40.745129  9249 solver.cpp:258]     Train net output #0: loss &#x3D; 4.00278 (* 1 &#x3D; 4.00278 loss)</span><br><span class="line">I0313 11:42:40.745136  9249 sgd_solver.cpp:112] Iteration 0, lr &#x3D; 0.0001</span><br><span class="line">I0313 12:02:52.273387  9249 solver.cpp:239] Iteration 20 (0.0165081 iter&#x2F;s, 1211.53s&#x2F;20 iters), loss &#x3D; 17.0233</span><br><span class="line">I0313 12:02:52.273416  9249 solver.cpp:258]     Train net output #0: loss &#x3D; 19.2508 (* 1 &#x3D; 19.2508 loss)</span><br><span class="line">I0313 12:02:52.273422  9249 sgd_solver.cpp:112] Iteration 20, lr &#x3D; 0.0001</span><br><span class="line">I0313 12:23:09.810516  9249 solver.cpp:239] Iteration 40 (0.0164266 iter&#x2F;s, 1217.54s&#x2F;20 iters), loss &#x3D; 26.7316</span><br><span class="line">I0313 12:23:09.810544  9249 solver.cpp:258]     Train net output #0: loss &#x3D; 30.1355 (* 1 &#x3D; 30.1355 loss)</span><br><span class="line">I0313 12:23:09.810550  9249 sgd_solver.cpp:112] Iteration 40, lr &#x3D; 0.0001</span><br><span class="line">I0313 12:43:32.716285  9249 solver.cpp:239] Iteration 60 (0.0163545 iter&#x2F;s, 1222.91s&#x2F;20 iters), loss &#x3D; 30.2106</span><br><span class="line">I0313 12:43:32.716313  9249 solver.cpp:258]     Train net output #0: loss &#x3D; 22.8696 (* 1 &#x3D; 22.8696 loss)</span><br><span class="line">I0313 12:43:32.716320  9249 sgd_solver.cpp:112] Iteration 60, lr &#x3D; 0.0001</span><br><span class="line">I0313 13:03:49.434516  9249 solver.cpp:239] Iteration 80 (0.0164377 iter&#x2F;s, 1216.72s&#x2F;20 iters), loss &#x3D; 31.0818</span><br><span class="line">I0313 13:03:49.434543  9249 solver.cpp:258]     Train net output #0: loss &#x3D; 23.1428 (* 1 &#x3D; 23.1428 loss)</span><br><span class="line">I0313 13:03:49.434551  9249 sgd_solver.cpp:112] Iteration 80, lr &#x3D; 0.0001</span><br><span class="line">I0313 13:23:51.860294  9249 solver.cpp:239] Iteration 100 (0.0166331 iter&#x2F;s, 1202.43s&#x2F;20 iters), loss &#x3D; 32.5238</span><br><span class="line">I0313 13:23:51.860322  9249 solver.cpp:258]     Train net output #0: loss &#x3D; 35.1909 (* 1 &#x3D; 35.1909 loss)</span><br><span class="line">I0313 13:23:51.860328  9249 sgd_solver.cpp:112] Iteration 100, lr &#x3D; 0.0001</span><br><span class="line">I0313 13:43:38.481149  9249 solver.cpp:239] Iteration 120 (0.0168546 iter&#x2F;s, 1186.62s&#x2F;20 iters), loss &#x3D; 33.0024</span><br><span class="line">I0313 13:43:38.481176  9249 solver.cpp:258]     Train net output #0: loss &#x3D; 40.9104 (* 1 &#x3D; 40.9104 loss)</span><br><span class="line">I0313 13:43:38.481182  9249 sgd_solver.cpp:112] Iteration 120, lr &#x3D; 0.0001</span><br><span class="line">I0313 14:03:27.667078  9249 solver.cpp:239] Iteration 140 (0.0168182 iter&#x2F;s, 1189.19s&#x2F;20 iters), loss &#x3D; 36.4908</span><br><span class="line">I0313 14:03:27.667104  9249 solver.cpp:258]     Train net output #0: loss &#x3D; 53.9975 (* 1 &#x3D; 53.9975 loss)</span><br><span class="line">I0313 14:03:27.667111  9249 sgd_solver.cpp:112] Iteration 140, lr &#x3D; 0.0001</span><br><span class="line">I0313 14:23:25.009404  9249 solver.cpp:239] Iteration 160 (0.0167037 iter&#x2F;s, 1197.34s&#x2F;20 iters), loss &#x3D; 52.2285</span><br><span class="line">I0313 14:23:25.009431  9249 solver.cpp:258]     Train net output #0: loss &#x3D; 26.9314 (* 1 &#x3D; 26.9314 loss)</span><br><span class="line">I0313 14:23:25.009438  9249 sgd_solver.cpp:112] Iteration 160, lr &#x3D; 0.0001</span><br><span class="line">I0313 14:43:35.026921  9249 solver.cpp:239] Iteration 180 (0.0165287 iter&#x2F;s, 1210.02s&#x2F;20 iters), loss &#x3D; 33.087</span><br><span class="line">I0313 14:43:35.026950  9249 solver.cpp:258]     Train net output #0: loss &#x3D; 44.6887 (* 1 &#x3D; 44.6887 loss)</span><br><span class="line">I0313 14:43:35.026957  9249 sgd_solver.cpp:112] Iteration 180, lr &#x3D; 0.0001</span><br><span class="line">I0313 15:03:45.718956  9249 solver.cpp:239] Iteration 200 (0.0165195 iter&#x2F;s, 1210.69s&#x2F;20 iters), loss &#x3D; 33.0793</span><br><span class="line">I0313 15:03:45.718984  9249 solver.cpp:258]     Train net output #0: loss &#x3D; 34.2235 (* 1 &#x3D; 34.2235 loss)</span><br><span class="line">I0313 15:03:45.718991  9249 sgd_solver.cpp:112] Iteration 200, lr &#x3D; 0.0001</span><br><span class="line">I0313 15:24:27.503715  9249 solver.cpp:239] Iteration 220 (0.0161059 iter&#x2F;s, 1241.78s&#x2F;20 iters), loss &#x3D; 33.1698</span><br><span class="line">I0313 15:24:27.503741  9249 solver.cpp:258]     Train net output #0: loss &#x3D; 45.0323 (* 1 &#x3D; 45.0323 loss)</span><br><span class="line">I0313 15:24:27.503748  9249 sgd_solver.cpp:112] Iteration 220, lr &#x3D; 0.0001</span><br><span class="line">I0313 15:44:53.585564  9249 solver.cpp:239] Iteration 240 (0.0163121 iter&#x2F;s, 1226.08s&#x2F;20 iters), loss &#x3D; 35.7697</span><br><span class="line">I0313 15:44:53.585592  9249 solver.cpp:258]     Train net output #0: loss &#x3D; 45.5302 (* 1 &#x3D; 45.5302 loss)</span><br><span class="line">I0313 15:44:53.585598  9249 sgd_solver.cpp:112] Iteration 240, lr &#x3D; 0.0001</span><br><span class="line">I0313 16:04:44.744935  9249 solver.cpp:239] Iteration 260 (0.0167904 iter&#x2F;s, 1191.16s&#x2F;20 iters), loss &#x3D; 29.4003</span><br><span class="line">I0313 16:04:44.744963  9249 solver.cpp:258]     Train net output #0: loss &#x3D; 19.9242 (* 1 &#x3D; 19.9242 loss)</span><br><span class="line">I0313 16:04:44.744969  9249 sgd_solver.cpp:112] Iteration 260, lr &#x3D; 0.0001</span><br><span class="line">I0313 16:24:00.216655  9249 solver.cpp:239] Iteration 280 (0.017309 iter&#x2F;s, 1155.47s&#x2F;20 iters), loss &#x3D; 24.0391</span><br><span class="line">I0313 16:24:00.216681  9249 solver.cpp:258]     Train net output #0: loss &#x3D; 35.6398 (* 1 &#x3D; 35.6398 loss)</span><br><span class="line">I0313 16:24:00.216687  9249 sgd_solver.cpp:112] Iteration 280, lr &#x3D; 0.0001</span><br><span class="line">I0313 16:43:22.672458  9249 solver.cpp:239] Iteration 300 (0.017205 iter&#x2F;s, 1162.45s&#x2F;20 iters), loss &#x3D; 33.2369</span><br><span class="line">I0313 16:43:22.672485  9249 solver.cpp:258]     Train net output #0: loss &#x3D; 38.8301 (* 1 &#x3D; 38.8301 loss)</span><br><span class="line">I0313 16:43:22.672492  9249 sgd_solver.cpp:112] Iteration 300, lr &#x3D; 0.0001</span><br><span class="line">I0313 17:02:56.876072  9249 solver.cpp:239] Iteration 320 (0.0170328 iter&#x2F;s, 1174.2s&#x2F;20 iters), loss &#x3D; 33.7243</span><br><span class="line">I0313 17:02:56.876101  9249 solver.cpp:258]     Train net output #0: loss &#x3D; 33.6585 (* 1 &#x3D; 33.6585 loss)</span><br><span class="line">I0313 17:02:56.876106  9249 sgd_solver.cpp:112] Iteration 320, lr &#x3D; 0.0001</span><br></pre></td></tr></table></figure>
<p>可以看到在未更改其他网络参数的情况下，loss居高不下，本文着重与对<strong>Data layer</strong>的理解，下一篇文章将对网络结构内部进行优化，以达到点云数据loss达到预期的目标。</p>
<hr>
<p>参考文献：</p>
<ol>
<li><a href="https://zhuanlan.zhihu.com/p/22976342" target="_blank" rel="noopener">FCN学习:Semantic Segmentation</a></li>
<li><a href="http://simtalk.cn/2016/09/20/AlexNet/" target="_blank" rel="noopener">AlexNet</a></li>
</ol>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/DL/" rel="tag"># DL</a>
              <a href="/tags/PCL/" rel="tag"># PCL</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2018/03/15/cnpy_note/" rel="prev" title="cnpy 库使用笔记">
      <i class="fa fa-chevron-left"></i> cnpy 库使用笔记
    </a></div>
      <div class="post-nav-item">
    <a href="/2018/03/21/geometry_feature_segmentation_for_ground_point/" rel="next" title="基于几何特征的地面点云分割">
      基于几何特征的地面点云分割 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-激光雷达数据转换"><span class="nav-text">1. 激光雷达数据转换</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-激光雷达点云数据介绍"><span class="nav-text">1.1 激光雷达点云数据介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-点云预处理"><span class="nav-text">1.2 点云预处理</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-FCN-AlexNet的点云数据分类任务"><span class="nav-text">2. FCN-AlexNet的点云数据分类任务</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-FCN-AlexNet读取数据层（Data-layer）"><span class="nav-text">2.1 FCN-AlexNet读取数据层（Data layer）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-FCN-AlexNet模型定义函数（net-py）"><span class="nav-text">2.2 FCN-AlexNet模型定义函数（net.py）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#fcn-模型结构详解"><span class="nav-text">fcn()模型结构详解</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-数据输入层"><span class="nav-text">(1). 数据输入层</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-第一个卷积层"><span class="nav-text">(2). 第一个卷积层</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-第二个卷积层"><span class="nav-text">(3). 第二个卷积层</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4-第三个卷积层"><span class="nav-text">(4). 第三个卷积层</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-第四个卷积层"><span class="nav-text">(5). 第四个卷积层</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#6-第五个卷积层"><span class="nav-text">(6). 第五个卷积层</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#7-第六个全连接层"><span class="nav-text">(7). 第六个全连接层</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#8-第七个全连接层"><span class="nav-text">(8). 第七个全连接层</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#9-第八个全连接层"><span class="nav-text">(9). 第八个全连接层</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-FCN-AlexNet求解函数（solve-py）"><span class="nav-text">2.3 FCN-AlexNet求解函数（solve.py）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-点云分割试验结果"><span class="nav-text">3. 点云分割试验结果</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zeyu"
      src="/images/bear.jpg">
  <p class="site-author-name" itemprop="name">Zeyu</p>
  <div class="site-description" itemprop="description">Done is better than perfect.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
        
          <span class="site-state-item-count">25</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags">
          
        <span class="site-state-item-count">19</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zeyu-hello" title="GitHub → https://github.com/zeyu-hello" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zengzeyu@hotmail.com" title="E-mail → mailto:zengzeyu@hotmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-mail</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2017 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="id-card"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zeyu</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>






<script>
  (function() {
    function leancloudSelector(url) {
      url = encodeURI(url);
      return document.getElementById(url).querySelector('.leancloud-visitors-count');
    }

    function addCount(Counter) {
      var visitors = document.querySelector('.leancloud_visitors');
      var url = decodeURI(visitors.id);
      var title = visitors.dataset.flagTitle;

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url })))
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length > 0) {
            var counter = results[0];
            leancloudSelector(url).innerText = counter.time + 1;
            Counter('put', '/classes/Counter/' + counter.objectId, { time: { '__op': 'Increment', 'amount': 1 } })
              .catch(error => {
                console.error('Failed to save visitor count', error);
              });
          } else {
              Counter('post', '/classes/Counter', { title, url, time: 1 })
                .then(response => response.json())
                .then(() => {
                  leancloudSelector(url).innerText = 1;
                })
                .catch(error => {
                  console.error('Failed to create', error);
                });
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    function showTime(Counter) {
      var visitors = document.querySelectorAll('.leancloud_visitors');
      var entries = [...visitors].map(element => {
        return decodeURI(element.id);
      });

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url: { '$in': entries } })))
        .then(response => response.json())
        .then(({ results }) => {
          for (let url of entries) {
            let target = results.find(item => item.url === url);
            leancloudSelector(url).innerText = target ? target.time : 0;
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    let { app_id, app_key, server_url } = {"enable":true,"app_id":"g992xG0S8k31XQHoAEAhRQbE-gzGzoHsz","app_key":"BdWgkDuuoBKUAUvH1b0e3RJF","server_url":null,"security":false};
    function fetchData(api_server) {
      var Counter = (method, url, data) => {
        return fetch(`${api_server}/1.1${url}`, {
          method,
          headers: {
            'X-LC-Id'     : app_id,
            'X-LC-Key'    : app_key,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      if (CONFIG.page.isPost) {
        if (CONFIG.hostname !== location.hostname) return;
        addCount(Counter);
      } else if (document.querySelectorAll('.post-title-link').length >= 1) {
        showTime(Counter);
      }
    }

    let api_server = app_id.slice(-9) !== '-MdYXbMMI' ? server_url : `https://${app_id.slice(0, 8).toLowerCase()}.api.lncldglobal.com`;

    if (api_server) {
      fetchData(api_server);
    } else {
      fetch('https://app-router.leancloud.cn/2/route?appId=' + app_id)
        .then(response => response.json())
        .then(({ api_server }) => {
          fetchData('https://' + api_server);
        });
    }
  })();
</script>


      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  
  <script>
    (function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();
  </script>




  
<script src="/js/local-search.js"></script>













  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'g992xG0S8k31XQHoAEAhRQbE-gzGzoHsz',
      appKey     : 'BdWgkDuuoBKUAUvH1b0e3RJF',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : true,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
