<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[NumPy学习笔记]]></title>
    <url>%2F2018%2F03%2F08%2FNumpy%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[新建Numpy结构型数据： 12345import numpy as np student = np.dtype([(&apos;name&apos;,&apos;S20&apos;), (&apos;age&apos;,np.int8), (&apos;marks&apos;, np.float4)]) a = np.array([(&apos;abc&apos;, 21, 50),(&apos;xyz&apos;, 18, 75)], dtype = student) print a#输出[(&apos;abc&apos;, 21, 50.0), (&apos;xyz&apos;, 18, 75.0)] 其中，string类型数据用S20表示（20可更改），其余数据类型如np.int8和np.float4均有内建数据表示。 Numpy数组属性：调整数组大小12345678import numpy as np a = np.array([[1,2,3],[4,5,6]]) b = a.reshape(3,2) print b#输出[[1, 2] [3, 4] [5, 6]] 三维数组1234567891011121314151617# 一维数组 import numpy as np a = np.arange(24) a.ndim # 现在调整其大小# 2*4*3： 2个二维数组，每个数组大小4*3b = a.reshape(2,4,3) print b #输出# b 现在拥有三个维度[[[ 0, 1, 2] [ 3, 4, 5] [ 6, 7, 8] [ 9, 10, 11]] [[12, 13, 14] [15, 16, 17] [18, 19, 20] [21, 22, 23]]] Numpy 来自现有数据的数组12345678# 将列表转换为 ndarray import numpy as np x = [1,2,3] a = np.asarray(x) print a#输出[1 2 3] 12345678# 来自元组的 ndarray import numpy as np x = (1,2,3) a = np.asarray(x) print a#输出[1 2 3] Numpy-frombuffer123456import numpy as np s = &apos;Hello World&apos; a = np.frombuffer(s, dtype = &apos;S1&apos;) print a#输出[&apos;H&apos; &apos;e&apos; &apos;l&apos; &apos;l&apos; &apos;o&apos; &apos; &apos; &apos;W&apos; &apos;o&apos; &apos;r&apos; &apos;l&apos; &apos;d&apos;] Numpy-切片和索引基本切片是 Python 中基本切片概念到 n 维的扩展。 通过将start，stop和step参数提供给内置的slice函数来构造一个 Python slice对象。 此slice对象被传递给数组来提取数组的一部分。123456import numpy as npa = np.arange(10)s = slice(2,7,1) # 2返回值为2的索引，7返回值为7的索引，1为步长print a[s]#输出[2 3 4 5 6] 在上面的例子中，ndarray对象由arange()函数创建。 然后，分别用起始，终止和步长值2，7和2定义切片对象。 当这个切片对象传递给ndarray时，会对它的一部分进行切片，从索引2到7，步长为2。 NumPy - 数组上的迭代12345678910111213141516import numpy as npa = np.arange(0,60,5) a = a.reshape(3,4) print &apos;原始数组是：&apos; print a print &apos;\n&apos; print &apos;修改后的数组是：&apos; for x in np.nditer(a): print x#输出原始数组是：[[ 0 5 10 15] [20 25 30 35] [40 45 50 55]]修改后的数组是：0 5 10 15 20 25 30 35 40 45 50 55 注意：迭代的顺序匹配数组的内容布局，而不考虑特定的排序。 这可以通过迭代上述数组的转置来看到。1234567891011121314151617181920212223import numpy as np a = np.arange(0,60,5) a = a.reshape(3,4) print &apos;原始数组是：&apos; print a print &apos;\n&apos; print &apos;原始数组的转置是：&apos; b = a.Tprint bprint &apos;\n&apos; print &apos;修改后的数组是：&apos; for x in np.nditer(b): print x,#输出原始数组是： [[ 0 5 10 15] [20 25 30 35] [40 45 50 55]] 原始数组的转置是： [[ 0 20 40] [ 5 25 45] [10 30 50] [15 35 55]] 修改后的数组是： 0 5 10 15 20 25 30 35 40 45 50 55 numpy.ndarray.flatten 该函数返回折叠为一维的数组副本，函数接受下列参数：1ndarray.flatten(order) 其中： order：C – 按行，F– 按列，A – 原顺序，k – 元素在内存中的出现顺序。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Caffe源代码学习 — AlexNet(Caffenet.py)]]></title>
    <url>%2F2018%2F03%2F08%2FCaffe%E6%BA%90%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E4%B9%8BAlexNet_Caffenet_py%2F</url>
    <content type="text"><![CDATA[导言源码位置：caffe/examples/pycaffe/caffenet.py该文件源代码是经典模型AlexNet的Caffe实现，有兴趣的小伙伴去拜读一下论文: ImageNet Classification with Deep Convolutional Neural Networks.pdf). 源码解读1. 导入模块123from __future__ import print_functionfrom caffe import layers as L, params as P, to_protofrom caffe.proto import caffe_pb2 2. 定义Layer函数包括： 卷积层（Convolution Layer）、全连接层（Full Connected Layer）和池化层（Pooling Layer） 2.1 卷积层（Convolution Layer）函数1234def conv_relu(bottom, ks, nout, stride=1, pad=0, group=1): conv = L.Convolution(bottom, kernel_size=ks, stride=stride, num_output=nout, pad=pad, group=group) return conv, L.ReLU(conv, in_place=True) 1. 函数输入 bottom - 输入节点（blob）名 ks - 卷积核尺寸（kernel size） nout - 输出深度尺寸（number output） stride - 卷积核滑窗距离 pad - 图像边缘添加尺寸，即在图像周围一周添加尺寸为pad的空白像素 group - 将数据进行分开训练堆数目 2. 调用Caffe卷基层生成函数 conv = L.Convolution(bottom, kernel_size=ks, stride=stride,num_output=nout, pad=pad, group=group) 3. 返回参数 conv - 卷积层配置 L.ReLU(conv, in_place=True) - 卷积后的数据经过ReLU激活函数得到的数据2.2 全连接层（Full Connected Layer）123def fc_relu(bottom, nout): fc = L.InnerProduct(bottom, num_output=nout) return fc, L.ReLU(fc, in_place=True) 1. 调用Caffe内积函数 fc = L.InnerProduct(bottom, num_output=nout) 2. 返回参数 fc, L.ReLU(fc, in_place=True) - 全连接分类之后数据通过ReLU函数2.3 池化层（Pooling Layer）12def max_pool(bottom, ks, stride=1): return L.Pooling(bottom, pool=P.Pooling.MAX, kernel_size=ks, stride=stride) 调用Caffe池化层生成函数 L.Pooling)（） pool=P.Pooling.MAX - 池化类型选择MAX，即取模板内最大值输出3. 定义网络结构1234567891011121314151617181920212223242526data, label = L.Data(source=lmdb, backend=P.Data.LMDB, batch_size=batch_size, ntop=2, transform_param=dict(crop_size=227, mean_value=[104, 117, 123], mirror=True)) # the net itself conv1, relu1 = conv_relu(data, 11, 96, stride=4) pool1 = max_pool(relu1, 3, stride=2) norm1 = L.LRN(pool1, local_size=5, alpha=1e-4, beta=0.75) conv2, relu2 = conv_relu(norm1, 5, 256, pad=2, group=2) pool2 = max_pool(relu2, 3, stride=2) norm2 = L.LRN(pool2, local_size=5, alpha=1e-4, beta=0.75) conv3, relu3 = conv_relu(norm2, 3, 384, pad=1) conv4, relu4 = conv_relu(relu3, 3, 384, pad=1, group=2) conv5, relu5 = conv_relu(relu4, 3, 256, pad=1, group=2) pool5 = max_pool(relu5, 3, stride=2) fc6, relu6 = fc_relu(pool5, 4096) drop6 = L.Dropout(relu6, in_place=True) fc7, relu7 = fc_relu(drop6, 4096) drop7 = L.Dropout(relu7, in_place=True) fc8 = L.InnerProduct(drop7, num_output=1000) loss = L.SoftmaxWithLoss(fc8, label) if include_acc: acc = L.Accuracy(fc8, label) return to_proto(loss, acc) else: return to_proto(loss) 1. 函数输入 lmdb - 文件名 batch_size - 每次训练输入样本数目 include_acc - 加速？ 2. 调用Caffe数据层输入函数（Data）L.Data(source=lmdb, backend=P.Data.LMDB, batch_size=batch_size, ntop=2, transform_param=dict(crop_size=227, mean_value=[104, 117, 123], mirror=True)) backend - 数据类型 ntop - 输出blob数目，因为数据层处理数据输出data和label，所以值为 2 transform_param - 对单个图片处理： crop_size图片剪裁大小，mean_valueRGB图像需要减去的值（目的是更好突出特征）和mirror镜像处理。 3. 网络结构此博客绘制了AlexNet网络结构图和数据流动图，方便直观理解网络结构，可移步：深度学习之图像分类模型AlexNet解读第1-5层为卷积层，如下表所示：| Layer | Operation | Output || :—- | :————————————— | :——————————-: || Data | crop_size:227, mean_value: [104, 117, 123], mirror: true | data: 227x227x3; label: 227x227x1 || 1 | conv1 -&gt; relu1 -&gt; pool1 -&gt; norm1 | 27x27x96 || 2 | conv2 -&gt; relu2 -&gt; pool2 -&gt; norm2 | 13x13x256 || 3 | conv3 -&gt; relu3 | 11x11x384 || 4 | conv4 -&gt; relu4 | 11x11x384 || 5 | conv5 -&gt; relu5 -&gt; pool5 | 6x6x256 || 6 | fc6 -&gt; relu6 -&gt; drop6 | 4096 || 7 | fc7 -&gt; relu7 -&gt; drop7 | 4096 || 8 | fc8 -&gt; loss | 1000 | 以第1层代码为例进行分析: 第1层 = 卷积层（conv1+relu1） + 池化层（pool1） + 归一化（norm1） （1）. 第1层 - 卷积层（conv1+relu1）作用：提取局部特征，使用ReLU作为CNN的激活函数，并验证其效果在较深的网络超过了Sigmoid，成功解决了Sigmoid在网络较深时的梯度弥散问题。conv1, relu1 = conv_relu(data, 11, 96, stride=4) 数据：数据层输出data数据 卷积核大小： 11 输出节点深度： 96 滑窗距离： 4 （2）. 第1层 - 池化层（pool1）作用：提取最大值，避免平均池化的模糊化效果。在AlexNet中提出让步长比池化核的尺寸小，这样池化层的输出之间会有重叠和覆盖，提升了特征的丰富性。pool1 = max_pool(relu1, 3, stride=2) 数据： relu1 模板核大小： 3 滑窗距离： 2 （3）. 第1层 - 局部响应归一化（Local Response Normalize）（norm1）作用：对局部神经元的活动创建竞争机制，使得其中响应比较大的值变得相对更大，并抑制其他反馈较小的神经元，增强了模型的泛化能力norm1 = L.LRN(pool1, local_size=5, alpha=1e-4, beta=0.75) 数据： pool1 取值模板尺寸： 5 alpha: 0.0001 beta: 0.75 ###4. 输出网络结构文件（.prototxt）123456def make_net(): with open(&apos;train.prototxt&apos;, &apos;w&apos;) as f: print(caffenet(&apos;/path/to/caffe-train-lmdb&apos;), file=f) with open(&apos;test.prototxt&apos;, &apos;w&apos;) as f: print(caffenet(&apos;/path/to/caffe-val-lmdb&apos;, batch_size=50, include_acc=True), file=f) ###5. 运行12if __name__ == &apos;__main__&apos;: make_net() 总结Caffene.py是入门Caffe较好的源代码，结合原论文看，同时能加深对网络结构的理解，补充理论知识。下面根据这个example形式构建自己的网络结构，其中第一步，也是学习深度学习最重要的一步，编写自己的数据类型接口层程序。 以上。 附： AlexNet网络总结 深度学习之图像分类模型AlexNet解读]]></content>
      <categories>
        <category>Caffe</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DL</tag>
        <tag>Caffe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ROS Node 之间通信打断操作实例]]></title>
    <url>%2F2018%2F03%2F08%2FROS_Node%E4%B9%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E6%89%93%E6%96%AD%E6%93%8D%E4%BD%9C%E5%AE%9E%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[前言公司开发小工具，对文件夹下点云PCD文件进行读取和相应操作，目标功能： 读取文件夹下PCD文件，按照文件名进行排序； 通过Qt开发UI界面，界面包括操作按钮： continue: 循环播放PCD文件并发布 next，pre： 后一帧或前一帧PCD文件 save index： 保存当前帧PCD文件名到.txt文件 当continue操作正在进行时，点击其余按钮，实现打断停止功能 分析 将UI界面和实际后台操作分开进行多线程操作，否则在进行continue过程中时，无法通过外部改变判断条件进行打断； ROS的一个Node默认为是一个进程，所以采用double Node实现多线程； ROS的单个Node可以同时实现subscribe和publish多个消息。本文假设UI界面为Node 1，包括：读取PCD文件，对点击操作进行反应并发送按钮消息到后端；后台实现为Node 2，包括：按钮消息的实现代码。 UI界面 Node 2关键代码由于ROSNode之间特殊的通信机制，如果将条件判断机制放在Node 2的子函数中，那么Node 2在接收Node 1的消息时，如果continue操作正在进行，则必须当continue执行完毕之后再收到Node 1的消息。所以，必须将判断条件房子ROS的Master部分，通过Master对Node 1当前消息进行反应，可实时打断Node 2正在进行的continue操作，马上进行当前消息的操作。以下是Node 2中的main函数的ROS循环部分代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455enum recv_sign &#123; none_sign = 0, stop_sign = 1, continue_sign = 2, load_sign = 3 &#125;;while(ros::ok()) &#123; if( g_con_signal == continue_sign ) &#123; if ( g_cur_index &lt; g_pcd_filelist.size() - 1 ) &#123; publishPCD(); g_cur_index++; &#125; else g_cur_index = 0; &#125; else if ( g_con_signal == stop_sign ) &#123; if ( g_pcd_info == &quot;pre_pcd_signal&quot; ) &#123; if ( g_cur_index &gt; 0 ) &#123; g_cur_index--; publishPCD(); &#125; else std::cerr &lt;&lt; &quot;Reach 1st file!!&quot; &lt;&lt; std::endl; &#125; else if ( g_pcd_info == &quot;next_pcd_signal&quot; ) &#123; if ( g_cur_index &lt; g_pcd_filelist.size() - 1 ) g_cur_index ++; else g_cur_index = 0; publishPCD(); &#125; else if ( g_pcd_info == &quot;save_index&quot; ) &#123; g_outfile &lt;&lt; g_pcd_filelist[g_cur_index] &lt;&lt; std::endl; &#125; g_con_signal = none_sign; &#125; else if ( g_con_signal == load_sign ) &#123; g_file_root_path = g_pcd_info; std::cout &lt;&lt; g_file_root_path &lt;&lt; std::endl; read_filelists( g_file_root_path + &quot;/&quot;, g_pcd_filelist, &quot;.pcd&quot; ); for (int i = 0; i &lt; g_pcd_filelist.size(); ++i) &#123; std::cout &lt;&lt; g_pcd_filelist[i] &lt;&lt; std::endl; &#125; g_con_signal = none_sign; &#125; ros::spinOnce(); &#125; 代码说明： Node 1同时发送2个std_msgs::String：g_con_signal用于控制是否执行循环条件；g_pcd_info用于在不执行continue操作时进行细分操作划分，包括：save index操作的文件路径和loadPCD文件时文件路径。 g_con_signal可以取4个值：enum recv_sign { none_sign = 0, stop_sign = 1, continue_sign = 2, load_sign = 3 };，分别对应不同操作，其中none_sign用于执行除continue操作之外的跳出当前循环，达到只需执行一次的目的，防止陷入死循环（无线循环）。 ros::spinOnce()用于刷新ROS执行条件，每次进入while(ros::ok())循环时，就会内部条件进行判断。 后续：Node 2当前帧文件名返回给Node 1用于显示于UI界面功能尚待加入。 以上。]]></content>
      <categories>
        <category>ROS</category>
      </categories>
      <tags>
        <tag>ROS</tag>
        <tag>PCL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开篇2017]]></title>
    <url>%2F2017%2F06%2F26%2F%E5%BC%80%E7%AF%872017%2F</url>
    <content type="text"><![CDATA[欢迎来到曾泽宇的个人博客，此博客将用作记录自己的一些技术上的问题和解决方法，借助这一个平台，希望给自己一个记录，让自己多年以后回过头来看看自己也曾经少年过，哈哈！]]></content>
      <tags>
        <tag>MarkDown Writting</tag>
        <tag>Personal</tag>
      </tags>
  </entry>
</search>