<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[My Paper Lib 2019]]></title>
    <url>%2F2019%2F03%2F24%2F19_3_24%2FMy-Paper-Lib-2019%2F</url>
    <content type="text"><![CDATA[2019. No. PAPER SOURCE 1 Visualizing the Loss Landscape of Neural Nets PDF/video/code 2 3D Backbone Network for 3D Object Detection PDF/video/code 3 PersonLab : Person Pose Estimation and Instance Segmentation with a Bottom-Up , Part-Based , Geometric Embedding Model PDF/video/code 4 DeeperLab : Single-Shot Image Parser PDF/video/code 5 Multi-Task Learning as Multi-Objective Optimization PDF/video/code 6 Rethinking on Multi-Stage Networks for Human Pose Estimation PDF/video/code 7 RePr: Improved Training of Convolutional Filters PDF/video/code ——— Date: 03-24 ———- 8 Group Normalization PDF/video/code 9 Weight Standardization PDF/video/code 10 Pruning Filters for Efficient ConvNets PDF/video/code 11 High Performance Convolutional Neural Networks for Document Processing PDF/video/code 12 Group normalization PDF/video/code 13 Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks(DCGAN) PDF/video/code 14 Generative Adversarial Networks(GAN) PDF/video/code 15 Adversarial Learning for Semi-Supervised Semantic Segmentation PDF/video/code 16 Wasserstein GAN PDF/video/code 17 FVNet: 3D Front-View Proposal Generation for Real-Time Object Detection from Point Clouds PDF/video/code 18 YOLOv3: An Incremental Improvement PDF/video/code ———- Date: 05-03 ———- -]]></content>
      <tags>
        <tag>DL</tag>
        <tag>Paper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[My Paper Lib 2018]]></title>
    <url>%2F2019%2F03%2F24%2F19_3_24%2FMy-Paper-Lib-2018%2F</url>
    <content type="text"><![CDATA[2018. paper source O-CNN : Octree-based Convolutional Neural Networks for 3D Shape Analysis PDF/video/code OctNet: Learning Deep 3D Representations at High Resolutions PDF/video/code Parallel Separable 3D Convolution for Video and Volumetric Data Understanding PDF/video/code PIXOR : Real-time 3D Object Detection from Point Clouds PDF/video/code PointCNN PDF/video/code PointNet : Deep Learning on Point Sets for 3D Classification and Segmentation PDF/video/code PointNet ++ : Deep Hierarchical Feature Learning on Point Sets in a Metric Space PDF/video/code Receptive Field Block Net for Accurate and Fast Object Detection PDF/video/code Deep Residual Learning for Image Recognition(ResNet) PDF/video/code Rethinking Atrous Convolution for Semantic Image Segmentation PDF/video/code Rich feature hierarchies for accurate object detection and semantic segmentation PDF/video/code Sparse 3D convolutional neural networks PDF/video/code SPLATNet : Sparse Lattice Networks for Point Cloud Processing PDF/video/code SqueezeSeg: Convolutional Neural Nets with Recurrent CRF for Real-Time Road-Object Segmentation from 3D LiDAR Point Cloud PDF/video/code The Devil of Face Recognition is in the Noise PDF/video/code Understanding Convolution for Semantic Segmentation PDF/video/code V-Net : Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation PDF/video/code VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection PDF/video/code Xception: Deep Learning with Depthwise Separable Convolutions PDF/video/code PointFusion : Deep Sensor Fusion for 3D Bounding Box Estimation PDF/video/code Efficient Convolutions for Real-Time Semantic Segmentation of 3D Point Clouds PDF/video/code Exploring Spatial Context for 3D Semantic Segmentation of Point Clouds PDF/video/code Factorized Convolutional Neural Networks PDF/video/code Fast Bilateral Solver for Semantic Video Segmentation PDF/video/code Fast LIDAR-based Road Detection Using Fully Convolutional Neural Networks PDF/video/code FishNet : A Versatile Backbone for Image , Region , and Pixel Level Prediction PDF/video/code Flattened Convolutional Neural Networks for Feedforward Acceleration PDF/video/code Focal Loss for Dense Object Detection PDF/video/code Frustum PointNets for 3D Object Detection from RGB-D Data PDF/video/code Full-Resolution Residual Networks for Semantic Segmentation in Street Scenes PDF/video/code Fully Convolutional Networks for Semantic Segmentation PDF/video/code Fully-Convolutional Point Networks for Large-Scale Point Clouds PDF/video/code Fast R-CNN PDF/video/code Going Deeper with Convolutions（GoogLeNet） PDF/video/code Ground Estimation and Point Cloud Segmentation using SpatioTemporal Conditional Random Field PDF/video/code HDNET : Exploiting HD Maps for 3D Object Detection PDF/video/code Inception-V4, Inception-ResNet ad the Impact of Residual Connections on Learning PDF/video/code Instance-aware Semantic Segmentation via Multi-task Network Cascades PDF/video/code Joint 3D Proposal Generation and Object Detection from View Aggregation(AVOD) PDF/video/code Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs PDF/video/code Learning 3D Shape Completion from Laser Scan Data with Weak Supervision PDF/video/code Learning a Real-Time 3D Point Cloud Obstacle Discriminator via Bootstrapping PDF/video/code Learning Spatio-Temporal Representation with Pseudo-3D Residual Networks PDF/video/code Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics PDF/video/code Multi-View 3D Object Detection Network for Autonomous Driving PDF/video/code Not All Pixels Are Equal : Difficulty-Aware Semantic Segmentation via Deep Layer Cascade PDF/video/code 3D Fully Convolutional Network for Vehicle Detection in Point Cloud PDF/video/code 3D Semantic Segmentation with Submanifold Sparse Convolutional Networks PDF/video/code 3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation PDF/video/code Deconvolutional Networks for Point-Cloud Vehicle Detection and Tracking in Driving Scenarios PDF/video/code Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour PDF/video/code Acquisition of Localization Confidence for Accurate Object Detection(IouNet) PDF/video/code A Hybrid Conditional Random Field for Estimating the Underlying Ground Surface from Airborne LiDAR Data PDF/video/code Batch Normalization : Accelerating Deep Network Training by Reducing Internal Covariate Shift PDF/video/code BiSeNet : Bilateral Segmentation Network for Real-time Semantic Segmentation PDF/video/code CNN for Very Fast Ground Segmentation in Velodyne LiDAR Data PDF/video/code Complex-YOLO: An Euler-Region-Proposal for Real-time 3D Object Detection on Point Clouds PDF/video/code CornerNet: Detecting Objects as Paired Keypoints PDF/video/code Conditional Random Fields Meet Deep Neural Networks for Semantic Segmentation PDF/video/code Decoupled Networks PDF/video/code Deep Feature Pyramid Reconfiguration for Object Detection PDF/video/code DropBlock : A regularization method for convolutional networks PDF/video/code RoarNet: A Robust 3D Object Detection based on RegiOn Approximation Refinement PDF/video/code Dropout: A simple way to prevent neural networks from overfitting PDF/video/code SECOND: Sparsely Embedded Convolutional Detection PDF/video/code Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks PDF/video/code Bag of Tricks for Image Classification with Convolutional Neural Networks PDF/video/code Deformable ConvNets v2: More Deformable, Better Results PDF/video/code Non-local Neural Networks PDF/video/code PointPillars: Fast Encoders for Object Detection from Point Clouds PDF/video/code Box2Pix : Single-Shot Instance Segmentation by Assigning Pixels to Object Boxes PDF/video/code IPOD: Intensive Point-based Object Detector for Point Cloud PDF/video/code Densely connected convolutional networks PDF/video/code SqueezeSegV2: Improved Model Structure and Unsupervised Domain Adaptation for Road-Object Segmentation from a LiDAR Point Cloud PDF/video/code SSD: Single Shot MultiBox Detector PDF/video/code Residual Networks Behave Like Ensembles of Relatively Shallow Networks PDF/video/code Single-Shot Refinement Neural Network for Object Detection (RefineDet) PDF/video/code MIXED PRECISION TRAINING PDF/video/code Gradient Harmonized Single-stage Detector PDF/video/code Gather-Excite: Exploiting Feature Context in Convolutional Neural Networks PDF/video/code GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks PDF/video/code]]></content>
      <tags>
        <tag>DL</tag>
        <tag>Paper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mixed-Precision Training of Deep Neural Networks]]></title>
    <url>%2F2019%2F01%2F16%2F19_1_16%2FMixed-Precision%20Training%20of%20Deep%20Neural%20Networks%2F</url>
    <content type="text"><![CDATA[By: zengzeyu 2019.01.16 1. Introduction由于FP16的精度损失问题，如果我们在神经网络的训练过程中直接将网络参数以FP16的形式进行计算，可能会出现数值不稳定的情况而导致模型性能下降。 对此，百度和NVIDIA的研究院在Mixed Precision Training这一论文中提出混合精度训练的方法，在充分利用FP16加速运算的优点的同时保证了模型的精度。下面介绍其论文中的主要要点。 FP32 master copy of weigths FP32 master copy即维护一份网络中FP16精度参数的FP32精度的拷贝。 计算过程如下图所示，在前向传播过程中，使用由master copy类型转换得到的FP16精度参数进行运算； 而在反向传播计算完梯度后，将梯度作用到master copy上以在FP32精度上进行参数更新。 FP32 master copy 这么做的主要原因有两个。 第一是由于若直接在FP16精度下进行参数更新，存在梯度过小而导致更新值为0的情况。 下图是某次模型训练过程汇总网络参数的梯度的分布直方图，有5%的梯度值是分布在小于2-24的区间内的。 若优化器直接将这部分梯度乘上学习率作用到FP16精度参数的更新上，那么更新值将为0。 这将影响到模型的准确率。 但是如果是更新值是作用到FP32精度的master copy上时，则不会出现更新值下溢为0的情况。 第二是如果参数相较于其更新值过大的话，也可能会由于浮点数加法机制的缘故而导致更新值为0。 在浮点数加法过程中，需要将两数对齐进行运算。 如果参数的大小是其更新值的2048倍或者更大的话，那么更新值的小数位需要右移至少11位才能与前者对齐，这超出了FP16精度的表示范围。 在FP32精度下则一般不会出现这种问题。 gradient histogram loss scaling loss scaling即将loss值放大，以保证反向传播过程当中梯度落在FP16精度能表示的范围之间。 下图是Multibox SSD网络在训练过程过程中激活单元梯度的分布情况。其中有67%的梯度落在了小于2-24的范围内，在FP16精度下无法表示。 如果不对梯度进行放大，在FP16精度下对该网络进行训练将导致发散。 对激活梯度进行放大，再对参数梯度缩小相应倍数，即可解决该问题。 activation gradients 根据梯度计算的链式法则，对梯度放大的最简单的方法就是放大loss。 放大因子的大小选择没有固定的标准，对于上述Multibox SSD网络，作者尝试了8-32K的放大因子，均训练成功了。 只要保证放大后的梯度不超过FP16精度的表示上限（65504），选择较大的放大因子并无副作用。[1] 2. Related Materials Nvidia Reources: https://github.com/NvidiaResources/nvidia_mixed_precision_training Nvidia: Mixed-Precision Training of Deep Neural Networks: https://devblogs.nvidia.com/mixed-precision-training-deep-neural-networks/ 3. Method2.1 直接在python2的pytorch训练框架中修改可实现：https://github.com/suvojit-0x55aa/mixed-precision-pytorch 2.2 使用Nvidia apex库库地址：https://github.com/NVIDIA/apex Nvidia 官方apex使用教程：http://on-demand.gputechconf.com/gtc-cn/2018/pdf/CH8302.pdf Reference 混合精度训练]]></content>
      <tags>
        <tag>DL</tag>
        <tag>Paper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PCL 点云索引方法K维树（KD-tree）和八叉树（octree）介绍]]></title>
    <url>%2F2018%2F03%2F30%2F18_3_30%2Fpcl_kdtree_and_octree%2F</url>
    <content type="text"><![CDATA[欢迎访问我的个人博客：zengzeyu.com 前言 通过雷达、激光扫描、立体摄像机等三维测量设备获取的点云数据，具有数据量大、分布不均匀等特点。作为三维领域中一个重要的数据来源，点云数据主要是表征目标表面的海量点集合，并不具备传统网格数据的集合拓扑信息。所以点云数据处理中最为核心的问题就是建立离散点间的拓扑关系，实现基于邻域关系的快速查找。建立空间索引在点云数据处理中已被广泛应用，常见空间索引一般是自顶向下逐级划分空间的各种空间索引结构，比较有代表性的包括 BSP树、 KD树、 KDB树、 R树、 R+树、 CELL树、四叉树和八叉树等索引结构，而在这些结构中KD树和八叉树在3D点云数据组织中应用较为广泛，PCL对上述两者进行了实现。 1. K维树（KD-tree） 1.1 KD-tree 概念简介KD-tree 又称 K 维树是计算机科学中使用的一种数据结构，用来组织表示 K 维空间中点集合。它是一种带有其他约束条件的二分查找树。KD-tree对于区间和近邻搜索十分有用。我们为了达到目的，通常只在三个维度中进行处理，因此所有的 KD-tree 都将是三维 KD-tree。 如下图所示（动图，慢慢看）， KD-tree 的每一级在指定维度上分开所有的子节点。在树的根部所有子节点是以第一个指定的维度上被分开（即如果第一维坐标小于根节点的点它将被分在左边的子树中，如果大于根节点的点它将分在右边的子树中）。 树的每一级都在下一个维度上分开，所有其他的维度用完之后就回到第一个维度，建立 KD-tree 最高效的方法是像快速分类一样使用分割法，把指定维度的值放在根上，在该维度上包含较小数值的在左子树，较大的在右子树。然后分别在左边和右边的子树上重复这个过程，直到用户准备分类的最后一个树仅仅由一个元素组成。 1.2 PCL中KD-tree使用1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980#include &lt;pcl/point_cloud.h&gt;#include &lt;pcl/kdtree/kdtree_flann.h&gt;#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;ctime&gt;intmain (int argc, char** argv)&#123; srand (time (NULL)); pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr cloud (new pcl::PointCloud&lt;pcl::PointXYZ&gt;); // Generate pointcloud data cloud-&gt;width = 1000; cloud-&gt;height = 1; cloud-&gt;points.resize (cloud-&gt;width * cloud-&gt;height); for (size_t i = 0; i &lt; cloud-&gt;points.size (); ++i) &#123; cloud-&gt;points[i].x = 1024.0f * rand () / (RAND_MAX + 1.0f); cloud-&gt;points[i].y = 1024.0f * rand () / (RAND_MAX + 1.0f); cloud-&gt;points[i].z = 1024.0f * rand () / (RAND_MAX + 1.0f); &#125; pcl::KdTreeFLANN&lt;pcl::PointXYZ&gt; kdtree; kdtree.setInputCloud (cloud); pcl::PointXYZ searchPoint; searchPoint.x = 1024.0f * rand () / (RAND_MAX + 1.0f); searchPoint.y = 1024.0f * rand () / (RAND_MAX + 1.0f); searchPoint.z = 1024.0f * rand () / (RAND_MAX + 1.0f); // K nearest neighbor search int K = 10; std::vector&lt;int&gt; pointIdxNKNSearch(K); std::vector&lt;float&gt; pointNKNSquaredDistance(K); std::cout &lt;&lt; "K nearest neighbor search at (" &lt;&lt; searchPoint.x &lt;&lt; " " &lt;&lt; searchPoint.y &lt;&lt; " " &lt;&lt; searchPoint.z &lt;&lt; ") with K=" &lt;&lt; K &lt;&lt; std::endl; if ( kdtree.nearestKSearch (searchPoint, K, pointIdxNKNSearch, pointNKNSquaredDistance) &gt; 0 ) &#123; for (size_t i = 0; i &lt; pointIdxNKNSearch.size (); ++i) std::cout &lt;&lt; " " &lt;&lt; cloud-&gt;points[ pointIdxNKNSearch[i] ].x &lt;&lt; " " &lt;&lt; cloud-&gt;points[ pointIdxNKNSearch[i] ].y &lt;&lt; " " &lt;&lt; cloud-&gt;points[ pointIdxNKNSearch[i] ].z &lt;&lt; " (squared distance: " &lt;&lt; pointNKNSquaredDistance[i] &lt;&lt; ")" &lt;&lt; std::endl; &#125; // Neighbors within radius search std::vector&lt;int&gt; pointIdxRadiusSearch; std::vector&lt;float&gt; pointRadiusSquaredDistance; float radius = 256.0f * rand () / (RAND_MAX + 1.0f); std::cout &lt;&lt; "Neighbors within radius search at (" &lt;&lt; searchPoint.x &lt;&lt; " " &lt;&lt; searchPoint.y &lt;&lt; " " &lt;&lt; searchPoint.z &lt;&lt; ") with radius=" &lt;&lt; radius &lt;&lt; std::endl; if ( kdtree.radiusSearch (searchPoint, radius, pointIdxRadiusSearch, pointRadiusSquaredDistance) &gt; 0 ) &#123; for (size_t i = 0; i &lt; pointIdxRadiusSearch.size (); ++i) std::cout &lt;&lt; " " &lt;&lt; cloud-&gt;points[ pointIdxRadiusSearch[i] ].x &lt;&lt; " " &lt;&lt; cloud-&gt;points[ pointIdxRadiusSearch[i] ].y &lt;&lt; " " &lt;&lt; cloud-&gt;points[ pointIdxRadiusSearch[i] ].z &lt;&lt; " (squared distance: " &lt;&lt; pointRadiusSquaredDistance[i] &lt;&lt; ")" &lt;&lt; std::endl; &#125; return 0;&#125; 代码解读 设置kdtree搜索对象和输入数据，然后使用随机坐标搜索方式 123456789pcl::KdTreeFLANN&lt;pcl::PointXYZ&gt; kdtree; kdtree.setInputCloud (cloud); pcl::PointXYZ searchPoint; searchPoint.x = 1024.0f * rand () / (RAND_MAX + 1.0f); searchPoint.y = 1024.0f * rand () / (RAND_MAX + 1.0f); searchPoint.z = 1024.0f * rand () / (RAND_MAX + 1.0f); 设置临近点个数 （10），两个向量来存储搜索到的 K 近邻，两个向量中一个存储搜索到查询点近邻的索引，另一个存储对应近邻的距离平方 1234567891011 // K nearest neighbor searchint K = 10;std::vector&lt;int&gt; pointIdxNKNSearch(K);std::vector&lt;float&gt; pointNKNSquaredDistance(K);std::cout &lt;&lt; &quot;K nearest neighbor search at (&quot; &lt;&lt; searchPoint.x &lt;&lt; &quot; &quot; &lt;&lt; searchPoint.y &lt;&lt; &quot; &quot; &lt;&lt; searchPoint.z &lt;&lt; &quot;) with K=&quot; &lt;&lt; K &lt;&lt; std::endl; 1.3 KD-tree 算法伪代码1234567891011121314function kdtree (list of points pointList, int depth)&#123; // Select axis based on depth so that axis cycles through all valid values var int axis := depth mod k; // Sort point list and choose median as pivot element select median by axis from pointList; // Create node and construct subtree node.location := median; node.leftChild := kdtree(points in pointList before median, depth+1); node.rightChild := kdtree(points in pointList after median, depth+1); return node;&#125; 2. 八叉树（octree） 2.1 octree 概念简介八叉树结构是由 Hunter 博士于1978年首次提出的一种数据模型。八叉树结构通过对三维空间的几何实体进行体元剖分，每个体元具有相同的时间和空间复杂度，通过循环递归的划分方法对大小为( 2 n x 2 n x 2 n ) 的三维空间的几何对象进行剖分，从而构成一个具有根节点的方向图。在八叉树结构中如果被划分的体元具有相同的属性，则该体元构成一个叶节点；否则继续对该体元剖分成8个子立方体，依次递剖分，对于( 2 n x 2 n x 2 n ) 大小的空间对象，最多剖分 n 次，如下图所示。 2.2 PCL中octree 在压缩点云数据方面应用点云由海量的数据集组成，这些数据通过距离、颜色、法线等附加信息来描述空间三维点。此外，点云能以非常高的速率被创建出来，因此需要占用相当大的存储资源，一旦点云需要存储或者通过速率受限制的通信信道进行传输，提供针对这种数据的压缩方法就变得十分有用。PCL库提供了点云压缩功能，它允许编码压缩所有类型的点云，包括无序点云，它具有无参考点和变化的点尺寸、分辨率、分布密度和点顺序等结构特征。而且，底层的 octree 数据结构允许从几个输入源高效地合并点云数据。下面解释单个点云和点云数据流是如何高效压缩的，在给出的例子中用PCL点云压缩技术来压缩用 OpenNIGrabber 抓取到的点云。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899#include &lt;pcl/point_cloud.h&gt;#include &lt;pcl/point_types.h&gt;#include &lt;pcl/io/openni_grabber.h&gt;#include &lt;pcl/visualization/cloud_viewer.h&gt;#include &lt;pcl/compression/octree_pointcloud_compression.h&gt;#include &lt;stdio.h&gt;#include &lt;sstream&gt;#include &lt;stdlib.h&gt;#ifdef WIN32# define sleep(x) Sleep((x)*1000)#endifclass SimpleOpenNIViewer&#123;public: SimpleOpenNIViewer () : viewer (&quot; Point Cloud Compression Example&quot;) &#123; &#125; void cloud_cb_ (const pcl::PointCloud&lt;pcl::PointXYZRGBA&gt;::ConstPtr &amp;cloud) &#123; if (!viewer.wasStopped ()) &#123; // stringstream to store compressed point cloud std::stringstream compressedData; // output pointcloud pcl::PointCloud&lt;pcl::PointXYZRGBA&gt;::Ptr cloudOut (new pcl::PointCloud&lt;pcl::PointXYZRGBA&gt; ()); // compress point cloud PointCloudEncoder-&gt;encodePointCloud (cloud, compressedData); // decompress point cloud PointCloudDecoder-&gt;decodePointCloud (compressedData, cloudOut); // show decompressed point cloud viewer.showCloud (cloudOut); &#125; &#125; void run () &#123; bool showStatistics = true; // for a full list of profiles see: /io/include/pcl/compression/compression_profiles.h pcl::io::compression_Profiles_e compressionProfile = pcl::io::MED_RES_ONLINE_COMPRESSION_WITH_COLOR; // instantiate point cloud compression for encoding and decoding PointCloudEncoder = new pcl::io::OctreePointCloudCompression&lt;pcl::PointXYZRGBA&gt; (compressionProfile, showStatistics); PointCloudDecoder = new pcl::io::OctreePointCloudCompression&lt;pcl::PointXYZRGBA&gt; (); // create a new grabber for OpenNI devices pcl::Grabber* interface = new pcl::OpenNIGrabber (); // make callback function from member function boost::function&lt;void (const pcl::PointCloud&lt;pcl::PointXYZRGBA&gt;::ConstPtr&amp;)&gt; f = boost::bind (&amp;SimpleOpenNIViewer::cloud_cb_, this, _1); // connect callback function for desired signal. In this case its a point cloud with color values boost::signals2::connection c = interface-&gt;registerCallback (f); // start receiving point clouds interface-&gt;start (); while (!viewer.wasStopped ()) &#123; sleep (1); &#125; interface-&gt;stop (); // delete point cloud compression instances delete (PointCloudEncoder); delete (PointCloudDecoder); &#125; pcl::visualization::CloudViewer viewer; pcl::io::OctreePointCloudCompression&lt;pcl::PointXYZRGBA&gt;* PointCloudEncoder; pcl::io::OctreePointCloudCompression&lt;pcl::PointXYZRGBA&gt;* PointCloudDecoder;&#125;;intmain (int argc, char **argv)&#123; SimpleOpenNIViewer v; v.run (); return (0);&#125; 2.3 octree算法 Matlab 伪代码1234567891011121314151617181920212223242526272829303132function [binDepths,binParents,binCorners,pointBins] = OcTree(points)binDepths = [0] % Initialize an array of bin depths with this single base-level binbinParents = [0] % This base level bin is not a child of other binsbinCorners = [min(points) max(points)] % It surrounds all points in XYZ spacepointBins(:) = 1 % Initially, all points are assigned to this first bindivide(1) % Begin dividing this first binfunction divide(binNo)​ % If this bin meets any exit conditions, do not divide it any further.binPointCount = nnz(pointBins==binNo)binEdgeLengths = binCorners(binNo,1:3) - binCorners(binNo,4:6)binDepth = binDepths(binNo)exitConditionsMet = binPointCount&lt;value || min(binEdgeLengths)&lt;value || binDepth&gt;valueif exitConditionsMet return; % Exit recursive functionend% Otherwise, split this bin into 8 new sub-bins with a new division pointnewDiv = (binCorners(binNo,1:3) + binCorners(binNo,4:6)) / 2for i = 1:8 newBinNo = length(binDepths) + 1 binDepths(newBinNo) = binDepths(binNo) + 1 binParents(newBinNo) = binNo binCorners(newBinNo) = [one of the 8 pairs of the newDiv with minCorner or maxCorner] oldBinMask = pointBins==binNo % Calculate which points in pointBins==binNo now belong in newBinNo pointBins(newBinMask) = newBinNo % Recursively divide this newly created bin divide(newBinNo)end 以上。 参考文献： 点云库PCL学习教程 k-d tree wiki PCL官方KD-tree使用教程]]></content>
      <categories>
        <category>PCL</category>
      </categories>
      <tags>
        <tag>PCL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[激光雷达点云数据内部空点补全算法]]></title>
    <url>%2F2018%2F03%2F28%2F18_3_30%2Ffix_nan_point_in_point_cloud%2F</url>
    <content type="text"><![CDATA[欢迎访问我的个人博客：zengzeyu.com 前言 点云数据区别于图像数据，不管是二维图像还是三维图像，图像数据都充满整个区域，二维图像中每个像素点都有值，灰度值、RGB值等；三维图像中有体数据（Voxel），根据光线投影算法等，可计算出每个体数据对应值，从而显示于显示器中。点云数据由于其扫描生成数据过程的特性，就决定了其在数据方面与图像数据不同，以机械式激光雷达为例，当出现以下情况时，该位置扫描生成的点云数据不存在（即为NAN点）： 激光发射器发射出去的激光未收到返回光束 激光接收器接收到的返回激光强度超出阈值范围 另外，在数据处理阶段，可根据需要对部分数据进行滤波处理，赋值为NAN点，也能造成该出点云缺失情况。 PCL库中有自带判断点云数据是否含有NAN点的函数： pcl::PointCloud&lt;pcl::PointXYZ&gt;::is_dense()， 以及过滤NAN点函数：pcl::removeNaNFromPointCloud()。 本文旨在补全内部空洞点，而不是去掉空洞点。 点云NAN点补全 本文补全原则基于有序点云（organised）进行处理，非有序点云无法进行处理（unorganised）。以自动驾驶中使用的机械式激光雷达速腾聚创16线激光雷达RS-LiDAR-16为例，其生成的有序点云（organised）点云尺寸为 16 x 2016： 16为激光线数，2016为每一线激光绕中心一周旋转储存的点个数，因此有 16 x 2016 = 32256 个点，而实际得到的点数据基本不可能是32256，必有缺失。 补全规则在每一线激光扫描得到一行点数据中，查找与NAN点最近的点进行补全，如果本行数据全部为NAN（虽然不可能发生），则此行可删除，调整点云尺寸。该规则基于的原则：在同一线激光扫描得到的点中，由于水平方向数据分辨率很高，所以一行数据中每个点与其邻域内点相似。 算法设计算法思路为了简化叙述，本文将一线激光扫描得到数据缩小为 360 个点，即一帧点云尺寸变为 16x360。以一线激光扫描数据为例，默认激光旋转方向为顺时针方向，采用线性差值方法进行补全，由于一线激光扫描一圈得到的数据在360°内任意位置都是对偶的，所以在空点附近查找两边非空点，用其值进行补全，具体参考下图示意。图上半部分为一线激光雷达扫描得到数据鸟瞰图，其中黑色方块代表非空点，白色方块代表空点；下半部分为点距离图，根据线性插值方法可以补全非空点。非空点距离计算采用极坐标方式，首先得到线性插值得到的range，再使用当前转角转换到笛卡尔坐标系下，可得到其 x， y 坐标值，z 坐标值也采用同样的插值方法计算。 其中一个特殊情况：转角为 0° 与转角为 360° 是等效的，在查找过程中，当转角顺时针查找到 360 °时则置为 0°，当转角逆时针查找到 0° 时则置为 360°。 算法流程根据以上思路，设计算法如下:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576def fix_nan_point(self, in_cloud): #fix edeg nan point 1st in_cloud = self.fix_left_edge_nan_point( in_cloud ) in_cloud = self.fix_right_edge_nan_point( in_cloud ) #fix centrol nan point for i in range(in_cloud.shape[0]): for j in range(1, in_cloud.shape[1]): if in_cloud[i, j, -1] == -1: nan_size = 1 left = j - 1 right = j + 1 while in_cloud[i, left, -1] == -1: left -= 1 nan_size += 1 while in_cloud[i, right, -1] == -1: right += 1 nan_size += 1 height_diff_cell = (in_cloud[i, right, 2] - in_cloud[i, left, 2]) / nan_size range_diff_cell = (in_cloud[i, right, 3] - in_cloud[i, left, 3]) / nan_size in_cloud[i, j, 2] = in_cloud[i, left, 2] + (j - left) * height_diff_cell in_cloud[i, j, 3] = in_cloud[i, left, 3] + (j - left) * range_diff_cell if abs(j - left) &lt; abs(right-j): in_cloud[i, j, -1] = in_cloud[i, left, -1] else: in_cloud[i, j, -1] = in_cloud[i, right, -1] return in_clouddef fix_left_edge_nan_point(self, in_cloud): for i in range(in_cloud.shape[0]): if in_cloud[i, 0, -1] == -1: nan_size = 1 left = 359 right = 1 while in_cloud[i,left,-1] == -1: left -= 1 nan_size += 1 while in_cloud[i,right,-1] == -1: right += 1 nan_size +=1 height_diff_cell = (in_cloud[i, right, 2] - in_cloud[i, left, 2]) / nan_size range_diff_cell = (in_cloud[i, right, 3] - in_cloud[i, left, 3]) / nan_size in_cloud[i, 0, 2] = in_cloud[i, left, 2] + (360 - left) * height_diff_cell in_cloud[i, 0, 3] = in_cloud[i, left, 3] + (360 - left) * range_diff_cell if abs(360 - left) &lt; right: in_cloud[i, 0, -1] = in_cloud[i, left, -1] else: in_cloud[i, 0, -1] = in_cloud[i, right, -1] return in_clouddef fix_right_edge_nan_point(self, in_cloud): for i in range(in_cloud.shape[0]): if in_cloud[i, in_cloud.shape[1]-1, -1] == -1: nan_size = 1 left = in_cloud.shape[1]-2 right = 0 while in_cloud[i,left,-1] == -1: left -= 1 nan_size += 1 while in_cloud[i,right,-1] == -1: right += 1 nan_size +=1 height_diff_cell = (in_cloud[i, right, 2] - in_cloud[i, left, 2]) / nan_size range_diff_cell = (in_cloud[i, right, 3] - in_cloud[i, left, 3]) / nan_size in_cloud[i, in_cloud.shape[1]-1, 2] = in_cloud[i, left, 2] + (in_cloud.shape[1]-1 - left) * height_diff_cell in_cloud[i, in_cloud.shape[1]-1, 3] = in_cloud[i, left, 3] + (in_cloud.shape[1]-1 - left) * range_diff_cell if abs(in_cloud.shape[1]-1 - left) &lt; right + 1: in_cloud[i, in_cloud.shape[1]-1, -1] = in_cloud[i, left, -1] else: in_cloud[i, in_cloud.shape[1]-1, -1] = in_cloud[i, right, -1] return in_cloud 算法结果下图结果为源数据先经过降采样之后，再进行补全NAN点操作。源数据中的 label 有三个值 [-1, 0, 1]， 经过降采样然后补全操作只剩下 label 为[0， 1] 的点。 以上。 参考文献： PCL点云变换与移除NaN 速腾聚创自动驾驶激光雷达]]></content>
      <categories>
        <category>ROS</category>
      </categories>
      <tags>
        <tag>ROS</tag>
        <tag>PCL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[KITTI 原始点云数据（PCL）地面点分割]]></title>
    <url>%2F2018%2F03%2F28%2F18_3_30%2Fkitti_ground_point_seg%2F</url>
    <content type="text"><![CDATA[欢迎访问我的个人博客网站：zengzeyu.com 前言 自动驾驶系统中，对激光雷达获取的点云数据进行地面点分割是第一步，地面点分割结果的好坏直接影响聚类，识别和追踪效果。在对地面点分割过程中，前人尝试了许多方法，部分方法结果请参考本人博文《基于几何特征的地面点云分割》。所以，地面点分割是自动驾驶激光雷达点云处理永恒的话题。目前，基于几何特征的地面点分割都基于各自的前提假设，大多数的原理是根据地面点与非地面点的特征不同而进行区分，如法向量、高度、高度差等。 本文利用现有的KITTI点云数据进行地面点分割，通过不同方法组合，试验出结果相对较好的方法，并予以结果显示。 地面点分割 相关工作本文相关的一些工作，请参考本博客前博文： 1. 《KITTI 原始bin数据转pcd数据》 2. 《KITTI 无序点云数据转有序点云数据》 3. 《基于几何特征的地面点云分割》 地面点分割流程算法流程：1. 法向量分割 2. 平均高度分割 3. 校准平面 4. 栅格内高度差分割 5. 平均高度分割 部分代码：1234567891011121314void KittiPCL::generateGroundCloud(PointCloudXYZI::Ptr &amp;out_cloud, visualization_msgs::MarkerPtr &amp;plane_marker)&#123; PointCloudXYZI::Ptr temp_cloud_1 ( new PointCloudXYZI ); PointCloudXYZI::Ptr temp_cloud_2 ( new PointCloudXYZI ); *temp_cloud_1 = *kitti_organised_cloud_ptr_; // calibration this-&gt;filtCloudWithNormalZ( temp_cloud_1, temp_cloud_2 ); this-&gt;filtWithAverageHeight( temp_cloud_2, kitti_organised_cloud_ptr_, temp_cloud_1 ); this-&gt;estimateGroundPlane( temp_cloud_1, transform_cloud_ptr_, plane_marker ); // grid this-&gt;generateGridMap( transform_cloud_ptr_, temp_cloud_2, 75.0f, 0.2f ); this-&gt;computePtsCloudFeature(transform_cloud_ptr_); *out_cloud = *temp_cloud_2;&#125; 试验结果 为了客观合理展示试验结果，选取了直道路和十字路口的点云进行分割结果展示。同时，统计时间，在 Release 模式下，处理一帧平均耗时 130ms。 平台配置：CPU: Intel® Xeon(R) CPU E3-1230 v3 @ 3.30GHz × 8GPU: GeForce GT 730/PCIe/SSE2System: 64-bit 最后一张图片右上方，可发现有大块地面点未被分割出来，原因是该十字路口地面不平，本文算法还无法适用于这种情况，后续需要改进。 以上。]]></content>
      <categories>
        <category>ROS</category>
      </categories>
      <tags>
        <tag>ROS</tag>
        <tag>PCL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CNN for Very Fast Ground Segmentation in Velodyne LiDAR Data]]></title>
    <url>%2F2018%2F03%2F24%2F18_3_24%2FCNN%20for%20Very%20Fast%20Ground%20Segmentation%20in%20Velodyne%20LiDAR%20Data%2F</url>
    <content type="text"><![CDATA[前言 本文提出了一种新型的去地面点云方法。一种对3D点云数据编码来给CNN进行训练，最后来分割地面点云的方法。 地面点分割方法 训练数据说明 首先说明，根据Velodyne HDL-64E 生成的KITTI原始点云数据分析得知，每一帧点云尺寸大概为 64x4500，本文每一帧数据为 64x360 ，所以要对原始数据进行降采样。在每一帧点云中，每一线激光绕中心旋转一圈得到的点云按照 1° 的归类分为 360 份，每一份点云的信息提取某一个点或者平均信息作为点代表，代表点的特征和 label 填入格子中生成CNN所需训练数据。每个点 label 进行二分类，分为地面点和分地面点。点特征包括 P = [Px, Py, Pz, Pi, Pr] ([ 坐标x， 坐标y， 坐标z， 反射强度intensity， 距离range ])。 A. 数据准备（Encoding Sparse 3D Data Into a Dense 2D Matrix） 为了将稀疏的3D点云数据应用的2D的CNN中，本文将其编码为2D的多信号通道数据储存在矩阵 M 中，如下图所示。 矩阵M尺寸为 64x360 ，降采样过程中，对一个格子内多个点进行平均取值作为代表。同时为了简化数据，[x,z] 计算得到的值代表距离，因为本文默认 Y 轴为高度方向，所以 x， z 值为对偶，可以采取此种方式进行简化数据。对于空格子，则从临近格子进行线性插值来生成该格子内值。 B. 训练数据集（Training Dataset） 训练数据集的重要性不容多说，本文自行开发了基于人工种子点选取的点云分割工具（semiautomatic tool for ground annotation，原理参考图像中的区域增长算法，只不过此处将点之间距离作为判断条件代替灰度值，同时发现当上下限为[0.03, 0.07]米时分割效果最好。选取了KITTI不同场景下共252帧点云作为人工分割数据，将分割好的数据按照7:3比例分为[训练集，评价集]。由于上面得到的数据量太少，所以本文又通过其他一些方法对剩下的19k帧数据，生成了训练所需数据集，基与点云特征有：最低高度，高度变化值，两线激光点云之间的距离和高度差。本文也尝试过自动生成数据（artificial 3D LiDAR data），但是效果较差。 C. 网络结构以及训练方法（Topology and Training of the Proposed Networks） 因为生成的训练数据较少，所以只采用浅层的CNN网络结构（shallow CNN architectures），类型为全卷积（fully convolutional）。卷积层和反卷积层都包含非线性的ReLU神经元（ReLU non-linearities），采用梯度下降方法进行训练。网络结构如下图所示： 上文 A. 中得到的矩阵 M 作为网络输入，因为是逐点（pixel）进行分类，所以网络的输出尺寸与输入尺寸相同，根据分类： ground = 1，其余点根据softmax函数概率映射进行输出。反卷积层（Deconvolutionallayers，广泛应用于语义分割（semantic segmentation）领域）在本文提出的4个网络结构中的中3个都有应用，其中包括效果最好的 L05+deconv （上图中第一个）。 CNN的输入数据先要进行归一化（normalize）和剪裁（rescale），高度方面KITTI数据集将 3m 以上的数据进行了滤波处理，深度 d 通道方面则使用 log 进行归一化处理。 实验结果 以上。 参考文献：CNN for Very Fast Ground Segmentation in Velodyne LiDAR Data.PDF 欢迎访问我的个人博客： zengzeyu.com]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>PCL</tag>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Effective c++ 1.0]]></title>
    <url>%2F2018%2F03%2F21%2F18_3_22%2FEffective-c%2B%2B-1.0%2F</url>
    <content type="text"><![CDATA[欢迎访问我的个人博客： zengzeyu.com Tip在针对类中非 public 成员函数编写函数接口时，不应该像 public 成员函数一样不写传参变量。非 public 成员函数传参变量在函数内部被调用时，有利于及时输出数据进行可视化，在调用该非 public 成员函数的函数内部进行调试时，可只对数据输入输出进行观察，而不用关心非 public 成员函数内部实现细节，内部实现细节应该和调试阶段分开。同时，对每一个输出非 public 成员函数的形参变量，在调用该非 public 成员函数内部的开始应进行数据清楚，以达到在调用该函数的内部相同类型临时变量容器的重复利用，这样做的目的是节省内存运行空间。 实例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556bool KittiPCL::filtCloudWithNormalZ(const PointCloudXYZI::ConstPtr &amp;in_cloud, PointCloudXYZI::Ptr &amp;out_cloud, const float &amp;beam_range)&#123; if ( beam_range &lt;= 0 || beam_range &gt; 1 ) &#123; std::cerr &lt;&lt; &quot;KittiPCL::filtCloudWithNormalZ(): Beam range NOT correct!&quot; &lt;&lt; std::endl; return false; &#125; out_cloud-&gt;clear(); //classify point with normal z PointCloudXYZINormal::Ptr cloud_normal ( new PointCloudXYZINormal ); this-&gt;computeNormal( in_cloud, cloud_normal ); int beam_size; beam_size = static_cast&lt;int &gt;( 1 / beam_range ); std::vector&lt;PointCloudXYZI&gt; classify_cloud_vec; classify_cloud_vec.resize( beam_size ); int beam_num = 0; for (int i = 0; i &lt; cloud_normal-&gt;size(); ++i) &#123; if ( isnan( cloud_normal-&gt;at(i).x ) ) continue; if ( cloud_normal-&gt;at(i).normal_z &lt; 0 ) beam_num = - static_cast&lt; int &gt; ( cloud_normal-&gt;at(i).normal_z / beam_range ); else beam_num = static_cast&lt; int &gt; ( cloud_normal-&gt;at(i).normal_z / beam_range ); if ( beam_num &gt;= 0 &amp;&amp; beam_num &lt; beam_size ) classify_cloud_vec[ beam_num ].push_back( in_cloud-&gt;at(i) ); &#125; //find the largest size point cloud size_t pts_size = 0; size_t largest_num = 0; for (int j = 0; j &lt; classify_cloud_vec.size(); ++j) &#123; if ( pts_size &lt; classify_cloud_vec[j].size() ) &#123; pts_size = classify_cloud_vec[j].size(); largest_num = j; &#125; &#125; *out_cloud = classify_cloud_vec[largest_num]; return true;&#125;void KittiPCL::generateGroundCloud(PointCloudXYZI::Ptr &amp;out_cloud, visualization_msgs::MarkerPtr &amp;plane_marker)&#123; PointCloudXYZI::Ptr operat_cloud ( new PointCloudXYZI ); *operat_cloud = *kitti_organised_cloud_ptr_; //1. compute transform matrix PointCloudXYZI::Ptr normal_filt_cloud ( new PointCloudXYZI ); this-&gt;filtCloudWithNormalZ( operat_cloud, normal_filt_cloud );&#125;]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[点云降采样输入到caffe数据输入层]]></title>
    <url>%2F2018%2F03%2F21%2F18_3_30%2Fdown_sample_for_caffe_data_layer%2F</url>
    <content type="text"><![CDATA[欢迎访问我的个人博客：zegnzeyu.com 前言 KITTI 数据根据上篇博文 KITTI unorganised cloud to organised cloud 输出尺寸为 HxW = 64x4500， 本文准备复现论文 CNN for Very Fast Ground Segmentation in Velodyne LiDAR Data， 根据论文内CNN网络结构需要对数据尺寸进行调整，调整尺寸为 HxW = 64x360， 相当于读源数据进行了降采样（downsampling），由于无法使用 pooling 池化操作来达到此目的，所以进行手工调整。 点云数据调整 调整规则 尺寸调整规则将点云数据由 HxW = 64x4500 调整为 HxW = 64x360，可见数据在 H 高度方向上不发生改变， W 水平方向上由 4500 调整为 360，本文依据以下规则进行调整： 调整前尺寸： |- - - - - - - - - - - - - - - - - - - - . . . 4500 . . . - - - - - - - - - - - - - - - - - - - - - - |调整后尺寸： | - 12 - | - 13 - | - 12 - | - 13 - | . . . . . . . . . . . . .| - 12 - | - 13 - | - 12 - | - 13 - | 将 12 与 13 个与卷积 kernel 类似的结构定义为卷积容器，上述两个尺寸的卷积容器交替进行采样，得到最终结构输出尺寸为 4500 / 25 x 2 = 360。 数据调整 对每一个卷积容器内的数据进行提取操作，依据不同的数据使用不同的数据提取规则。以一个卷积容器为例，假设已经得到了容器内的数据，下面将对卷积容器内不同情况进行讨论。 1. 明确提取代表点的原则，目标假设要提取的点为 A = [ r, c, h, w, l ] 点提取代表点不是为了正确反应卷积容器内的所有点的特征分布，而是，A点自身的特征能和容器内最相近的数据点label能一一对应，这样才能保证训练网络时的数据准确性。因为我们的目标是，最后训练得到网络之后，通过网络来进行预测，那么，对于测试数据，也要进行尺寸 rescale 为 4500 / 25 x 2 = 360 操作，最后，根据对代表点 label 的预测，将 label 赋值到同卷积容器内的其他点。 2. 当容器内数据不为空，选取代表数据规则可进行下面三个方向的思考： 采用平均值方法： 依据容器内数据个数取 [range, height] 平均值，并根据二者数据的权重方向思考寻找容器内与计算得出的平均值特征最近的点，用作代替，但是，用哪个做代表值作为寻找代替点的依据，需要仔细考量！ 采用最近距离方法： 一次迭代就可查找出结果，直接用最近距离点作为代表点 采用高度方法： 考虑到高度方向的作为障碍物与地面区分的重要特征，可用此方法 数据调整输出 以 label data 为例输出显示，使用matplot进行绘图，python代码如下：​123456789import matplotlib.pyplot as pltin_label = in_file[:,:,0]fig = plt.figure()origin_label = fig.add_subplot(121)origin_label.imshow(in_label)rescale_label = plt.show(fig)​ 调整前后数据（源数据）由下图可看出，点颜色有三种，分别是代表三个 label 值： [ -1, 0, 1 ] 调整尺寸后点颜色有二种，分别代表两个 label 值： [ 0, 1 ] 12]]></content>
      <categories>
        <category>ROS</category>
      </categories>
      <tags>
        <tag>ROS</tag>
        <tag>PCL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于几何特征的地面点云分割]]></title>
    <url>%2F2018%2F03%2F21%2F18_3_22%2Fgeometry_feature_segmentation_for_ground_point%2F</url>
    <content type="text"><![CDATA[欢迎访问我的个人博客： zengzeyu.com 前言 激光雷达扫描得到的点云含有大部分地面点，这对后续障碍物点云的分类、识别和跟踪带来麻烦，所以需要首先滤波滤掉。传统的基于几何特征的滤波是最基本最简单的方法，目前本文尝试的有如下几种： 水平面校准 法向量 栅格高度差 栅格最低高度以上0.2米 绝对高度 平均高度 以上方法基于假设是地面点云所构成的地面为平面，而不是弧面，当然对于有倾斜角度的地面也是可以先通过水平面校准然后再进行后处理来达到目标。下面将针对以上几种方法，通过实验结果比对各自方法优劣。 1. 激光雷达地面点云分割方法 1.1 水平面校准 水平面校准顾名思义就是通过找到地面点所在平面，然后进行校准点云的方法。通过此步可将数据采集阶段，采集道德地面点云相对于激光雷达 z 轴不平行校准为与之平行。目的是为后续处理提供更易于处理的点云。 方法过程： 分割出大致地面点 找到地点所在平面 通过变换矩阵校准平面 1. 分割出大致地面点这一步可使用栅格高度差、绝对高度、法向量等方法来进行分割，目的只需要找到大部分地面点即可，不用进行精确的分割。本文通过法向量进行分割找到地面点。 2. 找到地点所在平面通过PCL自带函数进行处理。123456789101112131415bool estimateGroundPlane(PointCloudXYZI::Ptr &amp;in_cloud, PointCloudXYZI::Ptr &amp;out_cloud, visualization_msgs::MarkerPtr &amp;plane_marker, const float in_distance_thre)&#123; //plane segmentation pcl::SACSegmentation&lt;pcl::PointXYZI&gt; plane_seg; pcl::PointIndices::Ptr plane_inliers ( new pcl::PointIndices ); pcl::ModelCoefficients::Ptr plane_coefficients ( new pcl::ModelCoefficients ); plane_seg.setOptimizeCoefficients (true); plane_seg.setModelType ( pcl::SACMODEL_PLANE ); plane_seg.setMethodType ( pcl::SAC_RANSAC ); plane_seg.setDistanceThreshold ( in_distance_thre ); plane_seg.setInputCloud ( in_cloud ); plane_seg.segment ( *plane_inliers, *plane_coefficients ); return true;&#125; 通过上述代码找到平面之后，确定平面法向量就可以找到其到 z 轴的变换矩阵 T 。 3. 通过变换矩阵校准平面将原始点云与变换矩阵 T 作点积就可得到校准后点云。从图左下方可观察到校准后点云与原始点云有一定距离，说明激光雷达在采集数据时，其 z 轴与地面法向量不平行，而且这种情况随时都在发生。自动驾驶车辆行驶过程中，路面随时都有小的颠簸，偶尔还会有较大颠簸，如通过城市道路中的减速带，转弯时速度过大等等情况。所以校准点云是很有必要的。 1.2 栅格高度差方法 方法过程： 根据栅格尺寸生成栅格 计算每个栅格最低点与最高点高度差 比较 h 与预设高度差阈值 threshold 大小，对栅格进行分类 根据栅格分类，对栅格内点进行分类 方法结果 结果分析依据对每个栅格的高度差的大小进行分类，栅格高度差方法依赖于点云数据。栅格内地面点高度差特征符合栅格高度差方法，但是对于高平台仍然符合该特征，所以对于进行栅格话之后的高平台点仍然被分类为地面点。但是，该方法的分类出的地面点包含真实的地面点。 1.3 法向量方法 法向量方法基于假设为计算得到的地面点法向量为竖直向上或向下，即地面点法向量值为 （0, 0, 1） 或 （0, 0, -1） 。 方法过程： 计算点法向量 设定法向量阈值 threshold 进行点分类 方法结果 结果分析根据法向量方法的假设，一定要先对点云进行校正，如果不进行校正，那么很可能出现某一帧没有地面点被分割出来的极端情况（激光雷达倾斜角度过大）。法向量方法与高度差方法结果类似，对于平台类型障碍物生成的点无法有效区分。所以可以看到右视图中有部分店漂浮与真实地面点上方。 1.4 栅格最低高度以上0.2米方法 栅格最低高度以上 0.2 米方法中的数值 0.2 可在 0.2 附近进行选取，有论文设置为 0.15 。此方法与栅格高度差方法类似，也是基于栅格内点的高度信息来进行点分类。不过该方法并没有对栅格进行地面栅格或障碍物栅格分类，而在每个栅格内进行点的分类，最后将所有栅格内的点汇总得到地面点。 方法过程： 生成栅格地图 找到栅格内最低点，并储存其高度 h 找到栅格内点高度小于 h + 0.2，分类为地面点 方法结果 结果分析栅格最低高度以上0.2米方法依赖于栅格内的最低点选取，当最地点正好是真实地面点时，结果较为正确，反之则不然。与栅格高度差方法类似，该方法对悬浮物无法处理。 1.5 绝对高度方法 绝对高度方法根据校准后点云高度进行分割，通过设定阈值将点云分为地面点和障碍物点。 方法过程： 校准点云 根据高度阈值 threshold 对点进行分类 方法结果 结果分析绝对高度方法必须对校准点云进行操作，根据校准后点云通过设定高度阈值进行分类。从鸟瞰图可看出，远处有一部分地面点被分割为障碍物点，从结果右视图可看出，该方法对悬浮物可很好处理。 1.6 平均高度方法 平均高度方法是对预处理后已经包含大部分地面点进行的处理，而不能单独进行使用。本文采用栅格最低点高度以上 0.2 米方法作为预处理，其他地面点预处理也可。该方法基于假设为，预处理分割后得到点中地面点为绝大部分点，从而可根据平均高度作为进一步滤波。 方法过程： 栅格最低点高度以上 0.2 米方法分割出地面点 计算 过程 1. 得到地面点的平均高度 h 以 h 为阈值再进行分割得到地面点 方法结果 结果分析平均高度方法作为其他方法的一个小的补充，可对分割出的点悬浮物点进行进一步滤波。但对当大平台场景无法处理。 结论 本文对基于几何特征方法 水平面校准方法、法向量方法、栅格高度差方法、栅格最低高度以上0.2米方法、绝对高度方法、平均高度方法 等方法进行了分别分析，对各自方法优缺点进行了探讨。各个方法可以进行合理组合来达到地面点分割效果。这些方法可作为机器学习方法的数据集生成，为机器学习方法做好数据准备。 欢迎访问我的个人博客： zengzeyu.com]]></content>
      <categories>
        <category>ROS</category>
      </categories>
      <tags>
        <tag>ROS</tag>
        <tag>PCL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[KITTI unorganised cloud to organised cloud]]></title>
    <url>%2F2018%2F03%2F21%2F18_3_22%2Fkitti_unorganised_point_to_organised_cloud%2F</url>
    <content type="text"><![CDATA[欢迎访问我的个人博客： zengzeyu.com 前言 KITTI 点云数据集 bin 格式转 pcd 格式请参照本人博客文章： 《KITTI - 二进制点云数据集》。KITTI下载点云数据集为 unorganised ， 这为计算带来了麻烦，本文将无序点云进行排序生成有序点（organiesd）。 解决方案 KITTI 点云数据集是原始激光雷达点云经过了预处理之后的点云，预处理包括： 将高度为2米以上点过滤（2米为估计，没有考证） 噪点过滤 思路 1： 将垂直方向上的激光束按照64个水平高度格子进行分类 在每一个水平高度上，按照水平角度分辨率计算此排激光束排序 根据水平面上的 x、y 坐标值进行排序预期问题： 每一束激光的角度对应格子，不一定能正好对上，也就是说，可能存在数据偏差，结果导致某一个格子没有点，某个格子有多个点情况。当然，这种情况在激光雷达生成原始数据中就存在。重要问题： 1. 怎样判断哪一堆点云属于一束激光扫出来的？或者说，怎样判断在 unorganised 点云中哪里是下一帧点云的分隔标识？通过哪些信息来定义这个标识，从而能保证分隔正确？思路：KITTI数据集存储是按照一束激光的所有扫描数据存储完之后再存储下一束激光的数据，所以标识可以通过计算点在水平面上的转角值之差来得到。解决方法：因为每一束激光扫描起始点转角为0°附近值，结束点转角为360°附近值，所以在unorganised点云中，当相邻两个点转角值差大于100°（或者更大，值可任意取，但建议不要超过300°）时，可认定为两束激光扫描点云储存在unorganised点云中的分界标识。 2. 如何确定每一排格子数目？怎样将每一束激光点云储存在对应的此排格子中？思路：a. 由官方提供水平角分辨率0.08°进行格子数确定b. 统计每排最小转角 alpha ，以此作为水平角分辨率解决方法：根据方法b计算得出alpha值在0.08附近： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263640: 0.07661671: 0.07661672: 0.07661673: 0.07912944: 0.08156475: 0.07401876: 0.08156477: 0.07661678: 0.07912949: 0.076616710: 0.079129411: 0.081564712: 0.081564713: 0.081564714: 0.079129415: 0.076616716: 0.081564717: 0.079129418: 0.079129419: 0.079129420: 0.081564721: 0.081564722: 0.081564723: 0.079129424: 0.079129425: 0.074018726: 0.076616727: 0.076616728: 0.076616729: 0.076616730: 0.076616731: 0.076616732: 0.06852833: 0.065610634: 0.06852835: 0.074018736: 0.074018737: 0.074018738: 0.074018739: 0.071326340: 0.076616741: 0.071326342: 0.071326343: 0.074018744: 0.065610645: 0.065610646: 0.071326347: 0.074018748: 0.074018749: 0.071326350: 0.065610651: 0.065610652: 0.071326353: 0.071326354: 0.071326355: 0.06852856: 0.06852857: 0.06852858: 0.06852859: 0.065610660: 0.055952961: 0.06852862: 0.062557363: 0.0656106 同时，根据官方给定数据水平角分辨率 0.08° 进行计算，得到最大点格子数为：max col: 4499因此，本文决定依据官方给定数据水平角分辨率 0.08° 进行计算，结果得到每一束激光扫描得到点个数为：360° / 0.08° = 4500 （个） 3. PCL中的 Organiesd cloud 属性设置PCL中通过如下代码，设置初始点云为 organised ： 1234567bool initialKittiOrganiseCloud(const int &amp;row_size, const int &amp;col_size,pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr&amp; in_cloud)&#123; in_cloud-&gt;resize( row_size * col_size ); in_cloud-&gt;height = row_size; in_cloud-&gt;width = col_size; return true;&#125; 4. 关于C++：为何在构造函数内进行的对变量的初始化值会在后续函数中发现该函数并未达到初始化的效果？而当将初始化变量函数放到其他函数内，后续函数并不会报错？具体如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// 初始化变量函数bool GroundRemove::initialKittiOrganiseCloud(const int &amp;row_size, const int &amp;col_size)&#123; kitti_organised_cloud_ptr_-&gt;height = row_size; kitti_organised_cloud_ptr_-&gt;width = col_size; kitti_organised_cloud_ptr_-&gt;resize( row_size * col_size ); for (int i = 0; i &lt; kitti_organised_cloud_ptr_-&gt;height; ++i) &#123; for (int j = 0; j &lt; kitti_organised_cloud_ptr_-&gt;width; ++j) &#123; kitti_organised_cloud_ptr_-&gt;at( j,i ).x = NAN; kitti_organised_cloud_ptr_-&gt;at( j,i ).y = NAN; kitti_organised_cloud_ptr_-&gt;at( j,i ).z = NAN; &#125; &#125; return true; &#125;//构造函数GroundRemove::GroundRemove()&#123; kitti_organised_cloud_ptr_.reset( new PointCloudXYZI ); this-&gt;initialKittiOrganiseCloud(64, 4500)&#125;//后续函数bool GroundRemove::arrangePointInOrganise(std::vector&lt;PointCloudXYZI&gt; &amp;in_cloud, PointCloudXYZI::Ptr &amp;out_cloud)&#123; if ( in_cloud.empty() ) &#123; std::cerr &lt;&lt; &quot;Input cloud vector is EMPTY!&quot; &lt;&lt; std::endl; return false; &#125; else if ( !out_cloud-&gt;isOrganized() ) &#123; std::cerr &lt;&lt; &quot;Input point cloud is UNORGANISED!&quot; &lt;&lt; std::endl; return false; &#125; float angle = 0.0; float distance = 0.0; int col_num = 0; int tmp_vec_point = 0; for (int i = 0; i &lt; in_cloud.size(); ++i) &#123; for (int j = 0; j &lt; in_cloud[i].size(); ++j) &#123; angle = this-&gt;computeHorResoluteAngle( in_cloud[i].at(j) ) / M_PI * 180.0f; col_num = static_cast&lt;int &gt; ( angle / velodyne_angle_res ); out_cloud-&gt;at(col_num,i) = in_cloud[i].at(j) &#125; &#125; return true;&#125; 当把 initialKittiOrganiseCloud()函数放在构造函数中时，arrangePointInOrganise()内在检测会发生Input point cloud is UNORGANISED!输出，而当把initialKittiOrganiseCloud()函数放在其他函数中时，该检测会通过。思路：猜测与构造函数的机制有关，也有可能与PCL有关。解决方法：如果非要在构造函数中使用该函数，尚未找到解决办法。记录于此，待解决。 5. 为何每次储存点云相对于原数据会少300个点？具体如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354bool GroundRemove::arrangePointInOrganise(std::vector&lt;PointCloudXYZI&gt; &amp;in_cloud, PointCloudXYZI::Ptr &amp;out_cloud)&#123; if ( in_cloud.empty() ) &#123; std::cerr &lt;&lt; &quot;Input cloud vector is EMPTY!&quot; &lt;&lt; std::endl; return false; &#125; else if ( !out_cloud-&gt;isOrganized() ) &#123; std::cerr &lt;&lt; &quot;Input point cloud is UNORGANISED!&quot; &lt;&lt; std::endl; return false; &#125; float angle = 0.0f; float distance = 0.0f; int col_num = 0; int tmp_vec_point = 0; for (int i = 0; i &lt; in_cloud.size(); ++i) &#123; for (int j = 0; j &lt; in_cloud[i].size(); ++j) &#123; angle = this-&gt;computeHorResoluteAngle( in_cloud[i].at(j) ) / M_PI * 180.0f; col_num = static_cast&lt;int &gt; ( angle / velodyne_angle_res ); out_cloud-&gt;at(col_num,i) = in_cloud[i].at(j); &#125; tmp_vec_point += in_cloud[i].size(); &#125; int tmp_pt_point = 0; int tmp_nan_point = 0; for (int k = 0; k &lt; out_cloud-&gt;size(); ++k) &#123; if (isnanf(out_cloud-&gt;at(k).x)) tmp_nan_point ++; else tmp_pt_point ++; &#125; std::cout &lt;&lt; &quot;origin point size: &quot; &lt;&lt; origin_cloud_ptr_-&gt;size() &lt;&lt; std::endl; std::cout &lt;&lt; &quot;tmp_vec_point: &quot; &lt;&lt; tmp_vec_point &lt;&lt; std::endl; std::cout &lt;&lt; &quot;tmp_pt_point: &quot; &lt;&lt; tmp_pt_point &lt;&lt; std::endl; std::cout &lt;&lt; &quot;num diff: &quot; &lt;&lt; tmp_vec_point - tmp_pt_point &lt;&lt; std::endl; std::cout &lt;&lt; &quot;nan point: &quot; &lt;&lt; tmp_nan_point + tmp_pt_point &lt;&lt; std::endl; return true;&#125;// 某一帧输出origin point size: 120805tmp_vec_point: 120804tmp_pt_point: 120482num diff: 322nan point: 288000 思路：在out_cloud-&gt;at(col_num,i) = in_cloud[i].at(j);这行代码中，有这样的逻辑：只管填入点，不管out_cloud-&gt;at(col_num,i)此前是否已经有点，这就会导致点的损失。解决方法：这种情况无法避免，当同一个格子中时，只能选取更优的点，选取原则：格子中距离雷达最近距离的点。 以上。欢迎访问我的个人博客： zengzeyu.com]]></content>
      <categories>
        <category>ROS</category>
      </categories>
      <tags>
        <tag>ROS</tag>
        <tag>PCL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FCN-PCL 应用解析]]></title>
    <url>%2F2018%2F03%2F15%2F18_3_15%2Ffcn_alexnet_pcl%2F</url>
    <content type="text"><![CDATA[前言 FCN(fully convolutional networks， 全卷积神经网络)的图片语义分割（semantic segmentation）论文：Fully Convolutional Networks for Semantic Segmentation。全卷积网络首现于这篇文章。这篇文章是将CNN结构应用到图像语义分割领域并取得突出结果的开山之作，因而拿到了CVPR 2015年的Best paper honorable mention。图像语义分割，简而言之就是对一张图片上的所有像素点进行分类。如下图就是一个语义分割例子，不同颜色像素代表不同类别： UCB的FCN源码Github地址：https://github.com/shelhamer/fcn.berkeleyvision.org源码中一共包含了4种网络结构模型：nyud-fcn、pascalcontext-fcn、siftflow-fcn、voc-fcn。每一种网络结构根据提取卷积层不同，又分了3-4个不等的网络类别。工作中个人的数据类型和格式不一定与voc-fcn-alexnet源代码提供的数据接口相同或类似（图片），如本文接下来要输入网络模型的数据类型为由激光雷达（LiDAR）扫描得到的点云数据（.pcd），那么如何进行实际操作呢？下面一步一步进行。 1. 激光雷达数据转换 1.1 激光雷达点云数据介绍首先介绍机械式旋转激光雷达生成的数据格式，激光雷达内部电机以一定角速度旋转，通过固定于其上的激光发射器和激光接收器测量激光雷达到障碍物的距离。以速腾聚创公司生产的16线激光雷达RS-LiDAR-16为例，每秒进行10次360°旋转(10Hz)，每次旋转扫描得到周围场景的信息，每一线激光旋转一周得到2016个点，储存在 .pcd 格式文件中。以二维彩色图像的方式（如.png）来理解.pcd文件，16线代表图片高度，2016代表图片宽度，一共16x2016=32256个像素点。每个点 point 的数据有[x, y, z, intensity]，与二维图片中的RGB通道（RGB chanel）是同样的道理，每一个数据代表一个通道。 1.2 点云预处理根据点云数据特征属性对其进行预处理，每个 point 的处理后特征有[row, column, height, range, mark]分别代表 point 的：[行序号， 列标号， 高度， 距离， 属性]，其中 height 与 z 值相等，range 由 sqrt(x^2 + y^2 + z^2) 计算得出， mark 为通过决策树（Decision tree）方式对 point 进行分类得到属性：障碍物点（obstacle mark）或地面点（ground mark），与ground true图片道理相同，作为训练预测分类的结果参考标准用于计算loss。这里作用相当于，人工添加了更多的特征通道，方便进行分类和预测。以上预处理得到的数据通过cnpy库转换为 .npy 格式的二进制文件，方便NumPy对数据进行读取，cnpy库使用教程请移步：cnpy库使用笔记以及官方example。每一帧点云数据储存为一个 .npy 格式文件，命名方式越简单越好，方便读取排序，本文直接以序号作为文件名[0.npy, 1.npy, …, n.npy ]。 2. FCN-AlexNet的点云数据分类任务 FCN-AlexNet的点云数据分类任务工程包含： 5个Python文件： pcl_data_layer.py， net.py， solver.py， surgery.py， score.py 3个prototxt文件: train.prototxt， val.prototxt， solver.prototxt 1个caffe_model文件： fcn-alexnet-pascal.caffemodel 2.1 FCN-AlexNet读取数据层（Data layer）文件命名为pcl_data_layer.py，该文件内包含class PCLSegDataLayer()类函数：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758import caffeimport numpy as npimport randomimport osclass PCLSegDataLayer(caffe.Layer): def setup(self, bottom, top): params = eval(self.param_str) self.npy_dir = params[&quot;pcl_dir&quot;] self.list_name = list() # two tops: data and label if len(top) != 2: raise Exception(&quot;Need to define two tops: data and label.&quot;) # data layers have no bottoms if len(bottom) != 0: raise Exception(&quot;Do not define a bottom.&quot;) self.load_file_name( self.npy_dir, self.list_name ) self.idx = 0 def reshape(self, bottom, top): self.data, self.label = self.load_file( self.idx ) # reshape tops to fit (leading 1 is for batch dimension) top[0].reshape(1, *self.data.shape) top[1].reshape(1, *self.label.shape) def forward(self, bottom, top): # assign output top[0].data[...] = self.data top[1].data[...] = self.label # pick next input self.idx += 1 if self.idx == len(self.list_name): self.idx = 0 def backward(self, top, propagate_down, bottom): pass def load_file(self, idx): in_file = np.load(self.list_name[idx]) #[mark, row, col, height, range] in_data = in_file[:,:,1:-1] in_data = in_data.transpose((2, 0, 1)) in_label = in_file[:,:,0] return in_data, in_label def load_file_name(self, path, list_name): for file in os.listdir(path): file_path = os.path.join(path, file) if os.path.isdir(file_path): os.listdir(file_path, list_name) else: list_name.append(file_path) setup()： 建立类时的参数 reshape()： 根据输入调整模型入口大小 forward()： 前向传播，由于是数据输入层，所以输出为原点云数据及其分类label backward()： 后向传播，数据层没有后向传播，所以舍弃 load_file_name()： 读取指定文件夹内 .npy 格式文件并储存如列表list load_file()： 载入单个.npy 文件，并按照储存顺序对属性进行分类，输出data和label 2.2 FCN-AlexNet模型定义函数（net.py）net.py文件用于生成net.prototxt文件，其定义了整个模型的结构和模型每层的各个参数。当然，模型网络结构可以利用官方已经训练好的fcn-alexnet-pascal.caffemodel来导出，也可以使用net.py自己生成，为了简化操作，本文使用fcn-alexnet-pascal.caffemodel来导出模型网络结构。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162import syssys.path.append(&apos;../../python&apos;)import caffefrom caffe import layers as L, params as Pfrom caffe.coord_map import cropdef conv_relu(bottom, ks, nout, stride=1, pad=0, group=1): conv = L.Convolution(bottom, kernel_size=ks, stride=stride, num_output=nout, pad=pad, group=group) return conv, L.ReLU(conv, in_place=True)def max_pool(bottom, ks, stride=1): return L.Pooling(bottom, pool=P.Pooling.MAX, kernel_size=ks, stride=stride)def fcn(split): n = caffe.NetSpec() pydata_params = dict() pydata_params[&apos;pcl_dir&apos;] = &apos;../fcn_data_gen/data/npy&apos; #.npy files path pylayer = &apos;PCLSegDataLayer&apos; n.data, n.label = L.Python(module=&apos;pcl_data_layer&apos;, layer=pylayer, ntop=2, param_str=str(pydata_params)) # the base net n.conv1, n.relu1 = conv_relu(n.data, 11, 96, stride=4, pad=100) n.pool1 = max_pool(n.relu1, 3, stride=2) n.norm1 = L.LRN(n.pool1, local_size=5, alpha=1e-4, beta=0.75) n.conv2, n.relu2 = conv_relu(n.norm1, 5, 256, pad=2, group=2) n.pool2 = max_pool(n.relu2, 3, stride=2) n.norm2 = L.LRN(n.pool2, local_size=5, alpha=1e-4, beta=0.75) n.conv3, n.relu3 = conv_relu(n.norm2, 3, 384, pad=1) n.conv4, n.relu4 = conv_relu(n.relu3, 3, 384, pad=1, group=2) n.conv5, n.relu5 = conv_relu(n.relu4, 3, 256, pad=1, group=2) n.pool5 = max_pool(n.relu5, 3, stride=2) # fully conv n.fc6, n.relu6 = conv_relu(n.pool5, 6, 4096) n.drop6 = L.Dropout(n.relu6, dropout_ratio=0.5, in_place=True) n.fc7, n.relu7 = conv_relu(n.drop6, 1, 4096) n.drop7 = L.Dropout(n.relu7, dropout_ratio=0.5, in_place=True) n.score_fr = L.Convolution(n.drop7, num_output=21, kernel_size=1, pad=0, param=[dict(lr_mult=1, decay_mult=1), dict(lr_mult=2, decay_mult=0)]) n.upscore = L.Deconvolution(n.score_fr, convolution_param=dict(num_output=21, kernel_size=63, stride=32, bias_term=False), param=[dict(lr_mult=0)]) n.score = crop(n.upscore, n.data) n.loss = L.SoftmaxWithLoss(n.score, n.label, loss_param=dict(normalize=True, ignore_label=255)) return n.to_proto()def make_net(): with open(&apos;train.prototxt&apos;, &apos;w&apos;) as f: f.write(str(fcn(&apos;train&apos;))) with open(&apos;val.prototxt&apos;, &apos;w&apos;) as f: f.write(str(fcn(&apos;seg11valid&apos;)))if __name__ == &apos;__main__&apos;: make_net() conv_relu()： 定义卷积层输入参数 max_pool()： 定义池化层输入参数 fcn()： 定义模型网络结构 fcn()模型结构详解这里建议结合AlexNet原论文ImageNet Classification with Deep Convolutional Neural Networks一起看，并参考AlexNet模型结构图例来进行比较好理解每个参数的意义。 (1). 数据输入层123456n = caffe.NetSpec()pydata_params = dict()pydata_params[&apos;pcl_dir&apos;] = &apos;../fcn_data_gen/data/npy&apos; #.npy files pathpylayer = &apos;PCLSegDataLayer&apos;n.data, n.label = L.Python(module=&apos;pcl_data_layer&apos;, layer=pylayer, ntop=2, param_str=str(pydata_params)) 找到pcl_data_layer.py文件中的PCLSegDataLayer函数，使用该类处理数据方式作为模型数据输入层函数。 (2). 第一个卷积层123n.conv1, n.relu1 = conv_relu(n.data, 11, 96, stride=4, pad=100)n.pool1 = max_pool(n.relu1, 3, stride=2)n.norm1 = L.LRN(n.pool1, local_size=5, alpha=1e-4, beta=0.75) 关于为何pad=100，此文中有详细解释：FCN学习:Semantic Segmentation (3). 第二个卷积层123n.conv2, n.relu2 = conv_relu(n.norm1, 5, 256, pad=2, group=2)n.pool2 = max_pool(n.relu2, 3, stride=2)n.norm2 = L.LRN(n.pool2, local_size=5, alpha=1e-4, beta=0.75) (4). 第三个卷积层1n.conv3, n.relu3 = conv_relu(n.norm2, 3, 384, pad=1) (5). 第四个卷积层1n.conv4, n.relu4 = conv_relu(n.relu3, 3, 384, pad=1, group=2) (6). 第五个卷积层12n.conv5, n.relu5 = conv_relu(n.relu4, 3, 256, pad=1, group=2)n.pool5 = max_pool(n.relu5, 3, stride=2) (7). 第六个全连接层12n.fc6, n.relu6 = conv_relu(n.pool5, 6, 4096)n.drop6 = L.Dropout(n.relu6, dropout_ratio=0.5, in_place=True) (8). 第七个全连接层12n.fc7, n.relu7 = conv_relu(n.drop6, 1, 4096)n.drop7 = L.Dropout(n.relu7, dropout_ratio=0.5, in_place=True) (9). 第八个全连接层123456789n.score_fr = L.Convolution(n.drop7, num_output=21, kernel_size=1, pad=0, param=[dict(lr_mult=1, decay_mult=1), dict(lr_mult=2, decay_mult=0)])n.upscore = L.Deconvolution(n.score_fr, convolution_param=dict(num_output=21, kernel_size=63, stride=32, bias_term=False), param=[dict(lr_mult=0)])n.score = crop(n.upscore, n.data)n.loss = L.SoftmaxWithLoss(n.score, n.label, loss_param=dict(normalize=True, ignore_label=255)) 2.3 FCN-AlexNet求解函数（solve.py）solve.py 文件是整个模型的入口，它整合各个文件，输入外部参数，对结果进行求解并输出。由 solve.py 生成的 solver.prototxt 文件定义了求解函数的结构。 1234567891011121314151617181920212223242526272829303132import caffeimport surgery, scoreimport numpy as npimport osimport systry: import setproctitle setproctitle.setproctitle(os.path.basename(os.getcwd()))except: passweights = &apos;../ilsvrc-nets/fcn-alexnet-pascal.caffemodel&apos;# init# caffe.set_device(int(sys.argv[0]))# caffe.set_mode_gpu()solver = caffe.SGDSolver(&apos;solver.prototxt&apos;)solver.net.copy_from(weights)# surgeriesinterp_layers = [k for k in solver.net.params.keys() if &apos;up&apos; in k]surgery.interp(solver.net, interp_layers)# scoringval = np.loadtxt(&apos;../data/pascal/seg11valid.txt&apos;, dtype=str)for _ in range(25): solver.step(4000) score.seg_tests(solver, False, val, layer=&apos;score&apos;) weights = &#39;../ilsvrc-nets/fcn-alexnet-pascal.caffemodel&#39;： 导入训练好的模型，可在[Netscope]中输入net.prototxt来进行网络结构可视化 # caffe.set_device(int(sys.argv[0]))# caffe.set_mode_gpu()： 设置gpu来进行训练，本人电脑使用gpu报错，所以没有使用 solver = caffe.SGDSolver(&#39;solver.prototxt&#39;)solver.net.copy_from(weights)：设置求解器模型 # surgeries： （待补充） # scoring ： （待补充） 3. 点云分割试验结果 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062072082092102112122132142152162172182192202212222232242252262272282292302312322332342352362372382392402412422432442452462472482492502512522532542552562572582592602612622632642652662672682692702712722732742752762772782792802812822832842852862872882892902912922932942952962972982993003013023033043053063073083093103113123133143153163173183193203213223233243253263273283293303313323333343353363373383393403413423433443453463473483493503513523533543553563573583593603613623633643653663673683693703713723733743753763773783793803813823833843853863873883893903913923933943953963973983994004014024034044054064074084094104114124134144154164174184194204214224234244254264274284294304314324334344354364374384394404414424434444454464474484494504514524534544554564574584594604614624634644654664674684694704714724734744754764774784794804814824834844854864874884894904914924934944954964974984995005015025035045055065075085095105115125135145155165175185195205215225235245255265275285295305315325335345355365375385395405415425435445455465475485495505515525535545555565575585595605615625635645655665675685695705715725735745755765775785795805815825835845855865875885895905915925935945955965975985996006016026036046056066076086096106116126136146156166176186196206216226236246256266276286296306316326336346356366376386396406416426436446456466476486496506516526536546556566576586596606616626636646656666676686696706716726736746756766776786796806816826836846856866876886896906916926936946956966976986997007017027037047057067077087097107117127137147157167177187197207217227237247257267277287297307317327337347357367377387397407417427437447457467477487497507517527537547557567577587597607617627637647657667677687697707717727737747757767777787797807817827837847857867877887897907917927937947957967977987998008018028038048058068078088098108118128138148158168178188198208218228238248258268278288298308318328338348358368378388398408418428438448458468478488498508518528538548558568578588598608618628638648658668678688698708718728738748758768778788798808818828838848858868878888898908918928938948958968978988999009019029039049059069079089099109119129139149159169179189199209219229239249259269279289299309319329339349359369379389399409419429439449459469479489499509519529539549559569579589599609619629639649659669679689699709719729739749759769779789799809819829839849859869879889899909919929939949959969979989991000100110021003100410051006100710081009101010111012101310141015101610171018101910201021102210231024102510261027102810291030103110321033103410351036103710381039104010411042104310441045104610471048104910501051105210531054105510561057105810591060106110621063106410651066106710681069107010711072107310741075107610771078pydev debugger: process 9249 is connectingConnected to pydev debugger (build 173.4301.16)WARNING: Logging before InitGoogleLogging() is written to STDERRI0313 11:41:39.369604 9249 solver.cpp:45] Initializing solver from parameters: train_net: &quot;train.prototxt&quot;test_net: &quot;val.prototxt&quot;test_iter: 736test_interval: 999999999base_lr: 0.0001display: 20max_iter: 100000lr_policy: &quot;fixed&quot;momentum: 0.9weight_decay: 0.0005snapshot: 4000snapshot_prefix: &quot;snapshot/train&quot;test_initialization: falseaverage_loss: 20iter_size: 20I0313 11:41:39.369671 9249 solver.cpp:92] Creating training net from train_net file: train.prototxtI0313 11:41:39.370101 9249 net.cpp:51] Initializing net from parameters: state &#123; phase: TRAIN&#125;layer &#123; name: &quot;data&quot; type: &quot;Python&quot; top: &quot;data&quot; top: &quot;label&quot; python_param &#123; module: &quot;pcl_data_layer&quot; layer: &quot;PCLSegDataLayer&quot; param_str: &quot;&#123;\&apos;pcl_dir\&apos;: \&apos;/home/zzy/CLionProjects/ROS_Project/ws/src/fcn_data_gen/data/npy\&apos;&#125;&quot; &#125;&#125;layer &#123; name: &quot;conv1&quot; type: &quot;Convolution&quot; bottom: &quot;data&quot; top: &quot;conv1&quot; convolution_param &#123; num_output: 96 pad: 100 kernel_size: 11 group: 1 stride: 4 &#125;&#125;layer &#123; name: &quot;relu1&quot; type: &quot;ReLU&quot; bottom: &quot;conv1&quot; top: &quot;conv1&quot;&#125;layer &#123; name: &quot;pool1&quot; type: &quot;Pooling&quot; bottom: &quot;conv1&quot; top: &quot;pool1&quot; pooling_param &#123; pool: MAX kernel_size: 3 stride: 2 &#125;&#125;layer &#123; name: &quot;norm1&quot; type: &quot;LRN&quot; bottom: &quot;pool1&quot; top: &quot;norm1&quot; lrn_param &#123; local_size: 5 alpha: 0.0001 beta: 0.75 &#125;&#125;layer &#123; name: &quot;conv2&quot; type: &quot;Convolution&quot; bottom: &quot;norm1&quot; top: &quot;conv2&quot; convolution_param &#123; num_output: 256 pad: 2 kernel_size: 5 group: 2 stride: 1 &#125;&#125;layer &#123; name: &quot;relu2&quot; type: &quot;ReLU&quot; bottom: &quot;conv2&quot; top: &quot;conv2&quot;&#125;layer &#123; name: &quot;pool2&quot; type: &quot;Pooling&quot; bottom: &quot;conv2&quot; top: &quot;pool2&quot; pooling_param &#123; pool: MAX kernel_size: 3 stride: 2 &#125;&#125;layer &#123; name: &quot;norm2&quot; type: &quot;LRN&quot; bottom: &quot;pool2&quot; top: &quot;norm2&quot; lrn_param &#123; local_size: 5 alpha: 0.0001 beta: 0.75 &#125;&#125;layer &#123; name: &quot;conv3&quot; type: &quot;Convolution&quot; bottom: &quot;norm2&quot; top: &quot;conv3&quot; convolution_param &#123; num_output: 384 pad: 1 kernel_size: 3 group: 1 stride: 1 &#125;&#125;layer &#123; name: &quot;relu3&quot; type: &quot;ReLU&quot; bottom: &quot;conv3&quot; top: &quot;conv3&quot;&#125;layer &#123; name: &quot;conv4&quot; type: &quot;Convolution&quot; bottom: &quot;conv3&quot; top: &quot;conv4&quot; convolution_param &#123; num_output: 384 pad: 1 kernel_size: 3 group: 2 stride: 1 &#125;&#125;layer &#123; name: &quot;relu4&quot; type: &quot;ReLU&quot; bottom: &quot;conv4&quot; top: &quot;conv4&quot;&#125;layer &#123; name: &quot;conv5&quot; type: &quot;Convolution&quot; bottom: &quot;conv4&quot; top: &quot;conv5&quot; convolution_param &#123; num_output: 256 pad: 1 kernel_size: 3 group: 2 stride: 1 &#125;&#125;layer &#123; name: &quot;relu5&quot; type: &quot;ReLU&quot; bottom: &quot;conv5&quot; top: &quot;conv5&quot;&#125;layer &#123; name: &quot;pool5&quot; type: &quot;Pooling&quot; bottom: &quot;conv5&quot; top: &quot;pool5&quot; pooling_param &#123; pool: MAX kernel_size: 3 stride: 2 &#125;&#125;layer &#123; name: &quot;fc6&quot; type: &quot;Convolution&quot; bottom: &quot;pool5&quot; top: &quot;fc6&quot; convolution_param &#123; num_output: 4096 pad: 0 kernel_size: 6 group: 1 stride: 1 &#125;&#125;layer &#123; name: &quot;relu6&quot; type: &quot;ReLU&quot; bottom: &quot;fc6&quot; top: &quot;fc6&quot;&#125;layer &#123; name: &quot;drop6&quot; type: &quot;Dropout&quot; bottom: &quot;fc6&quot; top: &quot;fc6&quot; dropout_param &#123; dropout_ratio: 0.5 &#125;&#125;layer &#123; name: &quot;fc7&quot; type: &quot;Convolution&quot; bottom: &quot;fc6&quot; top: &quot;fc7&quot; convolution_param &#123; num_output: 4096 pad: 0 kernel_size: 1 group: 1 stride: 1 &#125;&#125;layer &#123; name: &quot;relu7&quot; type: &quot;ReLU&quot; bottom: &quot;fc7&quot; top: &quot;fc7&quot;&#125;layer &#123; name: &quot;drop7&quot; type: &quot;Dropout&quot; bottom: &quot;fc7&quot; top: &quot;fc7&quot; dropout_param &#123; dropout_ratio: 0.5 &#125;&#125;layer &#123; name: &quot;score_fr&quot; type: &quot;Convolution&quot; bottom: &quot;fc7&quot; top: &quot;score_fr&quot; param &#123; lr_mult: 1 decay_mult: 1 &#125; param &#123; lr_mult: 2 decay_mult: 0 &#125; convolution_param &#123; num_output: 21 pad: 0 kernel_size: 1 &#125;&#125;layer &#123; name: &quot;upscore&quot; type: &quot;Deconvolution&quot; bottom: &quot;score_fr&quot; top: &quot;upscore&quot; param &#123; lr_mult: 0 &#125; convolution_param &#123; num_output: 21 bias_term: false kernel_size: 63 stride: 32 &#125;&#125;layer &#123; name: &quot;score&quot; type: &quot;Crop&quot; bottom: &quot;upscore&quot; bottom: &quot;data&quot; top: &quot;score&quot; crop_param &#123; axis: 2 offset: 18 &#125;&#125;layer &#123; name: &quot;loss&quot; type: &quot;SoftmaxWithLoss&quot; bottom: &quot;score&quot; bottom: &quot;label&quot; top: &quot;loss&quot; loss_param &#123; ignore_label: 255 normalize: true &#125;&#125;I0313 11:41:39.370163 9249 layer_factory.hpp:77] Creating layer dataI0313 11:41:39.370743 9249 net.cpp:84] Creating Layer dataI0313 11:41:39.370753 9249 net.cpp:380] data -&gt; dataI0313 11:41:39.370759 9249 net.cpp:380] data -&gt; labelI0313 11:41:39.372340 9249 net.cpp:122] Setting up dataI0313 11:41:39.372354 9249 net.cpp:129] Top shape: 1 3 16 2016 (96768)I0313 11:41:39.372357 9249 net.cpp:129] Top shape: 1 16 2016 (32256)I0313 11:41:39.372360 9249 net.cpp:137] Memory required for data: 516096I0313 11:41:39.372364 9249 layer_factory.hpp:77] Creating layer data_data_0_splitI0313 11:41:39.372370 9249 net.cpp:84] Creating Layer data_data_0_splitI0313 11:41:39.372372 9249 net.cpp:406] data_data_0_split &lt;- dataI0313 11:41:39.372376 9249 net.cpp:380] data_data_0_split -&gt; data_data_0_split_0I0313 11:41:39.372382 9249 net.cpp:380] data_data_0_split -&gt; data_data_0_split_1I0313 11:41:39.372387 9249 net.cpp:122] Setting up data_data_0_splitI0313 11:41:39.372391 9249 net.cpp:129] Top shape: 1 3 16 2016 (96768)I0313 11:41:39.372395 9249 net.cpp:129] Top shape: 1 3 16 2016 (96768)I0313 11:41:39.372397 9249 net.cpp:137] Memory required for data: 1290240I0313 11:41:39.372400 9249 layer_factory.hpp:77] Creating layer conv1I0313 11:41:39.372406 9249 net.cpp:84] Creating Layer conv1I0313 11:41:39.372409 9249 net.cpp:406] conv1 &lt;- data_data_0_split_0I0313 11:41:39.372412 9249 net.cpp:380] conv1 -&gt; conv1I0313 11:41:39.372515 9249 net.cpp:122] Setting up conv1I0313 11:41:39.372521 9249 net.cpp:129] Top shape: 1 96 52 552 (2755584)I0313 11:41:39.372524 9249 net.cpp:137] Memory required for data: 12312576I0313 11:41:39.372531 9249 layer_factory.hpp:77] Creating layer relu1I0313 11:41:39.372535 9249 net.cpp:84] Creating Layer relu1I0313 11:41:39.372539 9249 net.cpp:406] relu1 &lt;- conv1I0313 11:41:39.372541 9249 net.cpp:367] relu1 -&gt; conv1 (in-place)I0313 11:41:39.372546 9249 net.cpp:122] Setting up relu1I0313 11:41:39.372550 9249 net.cpp:129] Top shape: 1 96 52 552 (2755584)I0313 11:41:39.372552 9249 net.cpp:137] Memory required for data: 23334912I0313 11:41:39.372555 9249 layer_factory.hpp:77] Creating layer pool1I0313 11:41:39.372558 9249 net.cpp:84] Creating Layer pool1I0313 11:41:39.372560 9249 net.cpp:406] pool1 &lt;- conv1I0313 11:41:39.372565 9249 net.cpp:380] pool1 -&gt; pool1I0313 11:41:39.372573 9249 net.cpp:122] Setting up pool1I0313 11:41:39.372576 9249 net.cpp:129] Top shape: 1 96 26 276 (688896)I0313 11:41:39.372579 9249 net.cpp:137] Memory required for data: 26090496I0313 11:41:39.372581 9249 layer_factory.hpp:77] Creating layer norm1I0313 11:41:39.372586 9249 net.cpp:84] Creating Layer norm1I0313 11:41:39.372588 9249 net.cpp:406] norm1 &lt;- pool1I0313 11:41:39.372593 9249 net.cpp:380] norm1 -&gt; norm1I0313 11:41:39.372599 9249 net.cpp:122] Setting up norm1I0313 11:41:39.372602 9249 net.cpp:129] Top shape: 1 96 26 276 (688896)I0313 11:41:39.372604 9249 net.cpp:137] Memory required for data: 28846080I0313 11:41:39.372607 9249 layer_factory.hpp:77] Creating layer conv2I0313 11:41:39.372611 9249 net.cpp:84] Creating Layer conv2I0313 11:41:39.372613 9249 net.cpp:406] conv2 &lt;- norm1I0313 11:41:39.372617 9249 net.cpp:380] conv2 -&gt; conv2I0313 11:41:39.373008 9249 net.cpp:122] Setting up conv2I0313 11:41:39.373013 9249 net.cpp:129] Top shape: 1 256 26 276 (1837056)I0313 11:41:39.373015 9249 net.cpp:137] Memory required for data: 36194304I0313 11:41:39.373021 9249 layer_factory.hpp:77] Creating layer relu2I0313 11:41:39.373025 9249 net.cpp:84] Creating Layer relu2I0313 11:41:39.373028 9249 net.cpp:406] relu2 &lt;- conv2I0313 11:41:39.373030 9249 net.cpp:367] relu2 -&gt; conv2 (in-place)I0313 11:41:39.373034 9249 net.cpp:122] Setting up relu2I0313 11:41:39.373039 9249 net.cpp:129] Top shape: 1 256 26 276 (1837056)I0313 11:41:39.373040 9249 net.cpp:137] Memory required for data: 43542528I0313 11:41:39.373042 9249 layer_factory.hpp:77] Creating layer pool2I0313 11:41:39.373046 9249 net.cpp:84] Creating Layer pool2I0313 11:41:39.373049 9249 net.cpp:406] pool2 &lt;- conv2I0313 11:41:39.373052 9249 net.cpp:380] pool2 -&gt; pool2I0313 11:41:39.373057 9249 net.cpp:122] Setting up pool2I0313 11:41:39.373061 9249 net.cpp:129] Top shape: 1 256 13 138 (459264)I0313 11:41:39.373064 9249 net.cpp:137] Memory required for data: 45379584I0313 11:41:39.373065 9249 layer_factory.hpp:77] Creating layer norm2I0313 11:41:39.373070 9249 net.cpp:84] Creating Layer norm2I0313 11:41:39.373071 9249 net.cpp:406] norm2 &lt;- pool2I0313 11:41:39.373075 9249 net.cpp:380] norm2 -&gt; norm2I0313 11:41:39.373080 9249 net.cpp:122] Setting up norm2I0313 11:41:39.373082 9249 net.cpp:129] Top shape: 1 256 13 138 (459264)I0313 11:41:39.373085 9249 net.cpp:137] Memory required for data: 47216640I0313 11:41:39.373087 9249 layer_factory.hpp:77] Creating layer conv3I0313 11:41:39.373091 9249 net.cpp:84] Creating Layer conv3I0313 11:41:39.373093 9249 net.cpp:406] conv3 &lt;- norm2I0313 11:41:39.373096 9249 net.cpp:380] conv3 -&gt; conv3I0313 11:41:39.373900 9249 net.cpp:122] Setting up conv3I0313 11:41:39.373906 9249 net.cpp:129] Top shape: 1 384 13 138 (688896)I0313 11:41:39.373909 9249 net.cpp:137] Memory required for data: 49972224I0313 11:41:39.373914 9249 layer_factory.hpp:77] Creating layer relu3I0313 11:41:39.373919 9249 net.cpp:84] Creating Layer relu3I0313 11:41:39.373921 9249 net.cpp:406] relu3 &lt;- conv3I0313 11:41:39.373924 9249 net.cpp:367] relu3 -&gt; conv3 (in-place)I0313 11:41:39.373929 9249 net.cpp:122] Setting up relu3I0313 11:41:39.373931 9249 net.cpp:129] Top shape: 1 384 13 138 (688896)I0313 11:41:39.373934 9249 net.cpp:137] Memory required for data: 52727808I0313 11:41:39.373936 9249 layer_factory.hpp:77] Creating layer conv4I0313 11:41:39.373941 9249 net.cpp:84] Creating Layer conv4I0313 11:41:39.373944 9249 net.cpp:406] conv4 &lt;- conv3I0313 11:41:39.373947 9249 net.cpp:380] conv4 -&gt; conv4I0313 11:41:39.374778 9249 net.cpp:122] Setting up conv4I0313 11:41:39.374783 9249 net.cpp:129] Top shape: 1 384 13 138 (688896)I0313 11:41:39.374785 9249 net.cpp:137] Memory required for data: 55483392I0313 11:41:39.374789 9249 layer_factory.hpp:77] Creating layer relu4I0313 11:41:39.374794 9249 net.cpp:84] Creating Layer relu4I0313 11:41:39.374795 9249 net.cpp:406] relu4 &lt;- conv4I0313 11:41:39.374800 9249 net.cpp:367] relu4 -&gt; conv4 (in-place)I0313 11:41:39.374804 9249 net.cpp:122] Setting up relu4I0313 11:41:39.374807 9249 net.cpp:129] Top shape: 1 384 13 138 (688896)I0313 11:41:39.374809 9249 net.cpp:137] Memory required for data: 58238976I0313 11:41:39.374811 9249 layer_factory.hpp:77] Creating layer conv5I0313 11:41:39.374816 9249 net.cpp:84] Creating Layer conv5I0313 11:41:39.374819 9249 net.cpp:406] conv5 &lt;- conv4I0313 11:41:39.374824 9249 net.cpp:380] conv5 -&gt; conv5I0313 11:41:39.375376 9249 net.cpp:122] Setting up conv5I0313 11:41:39.375382 9249 net.cpp:129] Top shape: 1 256 13 138 (459264)I0313 11:41:39.375385 9249 net.cpp:137] Memory required for data: 60076032I0313 11:41:39.375392 9249 layer_factory.hpp:77] Creating layer relu5I0313 11:41:39.375397 9249 net.cpp:84] Creating Layer relu5I0313 11:41:39.375399 9249 net.cpp:406] relu5 &lt;- conv5I0313 11:41:39.375402 9249 net.cpp:367] relu5 -&gt; conv5 (in-place)I0313 11:41:39.375406 9249 net.cpp:122] Setting up relu5I0313 11:41:39.375409 9249 net.cpp:129] Top shape: 1 256 13 138 (459264)I0313 11:41:39.375412 9249 net.cpp:137] Memory required for data: 61913088I0313 11:41:39.375414 9249 layer_factory.hpp:77] Creating layer pool5I0313 11:41:39.375421 9249 net.cpp:84] Creating Layer pool5I0313 11:41:39.375422 9249 net.cpp:406] pool5 &lt;- conv5I0313 11:41:39.375425 9249 net.cpp:380] pool5 -&gt; pool5I0313 11:41:39.375432 9249 net.cpp:122] Setting up pool5I0313 11:41:39.375434 9249 net.cpp:129] Top shape: 1 256 6 69 (105984)I0313 11:41:39.375437 9249 net.cpp:137] Memory required for data: 62337024I0313 11:41:39.375439 9249 layer_factory.hpp:77] Creating layer fc6I0313 11:41:39.375444 9249 net.cpp:84] Creating Layer fc6I0313 11:41:39.375447 9249 net.cpp:406] fc6 &lt;- pool5I0313 11:41:39.375452 9249 net.cpp:380] fc6 -&gt; fc6I0313 11:41:39.404399 9249 net.cpp:122] Setting up fc6I0313 11:41:39.404426 9249 net.cpp:129] Top shape: 1 4096 1 64 (262144)I0313 11:41:39.404430 9249 net.cpp:137] Memory required for data: 63385600I0313 11:41:39.404438 9249 layer_factory.hpp:77] Creating layer relu6I0313 11:41:39.404445 9249 net.cpp:84] Creating Layer relu6I0313 11:41:39.404449 9249 net.cpp:406] relu6 &lt;- fc6I0313 11:41:39.404453 9249 net.cpp:367] relu6 -&gt; fc6 (in-place)I0313 11:41:39.404460 9249 net.cpp:122] Setting up relu6I0313 11:41:39.404464 9249 net.cpp:129] Top shape: 1 4096 1 64 (262144)I0313 11:41:39.404466 9249 net.cpp:137] Memory required for data: 64434176I0313 11:41:39.404469 9249 layer_factory.hpp:77] Creating layer drop6I0313 11:41:39.404474 9249 net.cpp:84] Creating Layer drop6I0313 11:41:39.404476 9249 net.cpp:406] drop6 &lt;- fc6I0313 11:41:39.404481 9249 net.cpp:367] drop6 -&gt; fc6 (in-place)I0313 11:41:39.404486 9249 net.cpp:122] Setting up drop6I0313 11:41:39.404489 9249 net.cpp:129] Top shape: 1 4096 1 64 (262144)I0313 11:41:39.404492 9249 net.cpp:137] Memory required for data: 65482752I0313 11:41:39.404495 9249 layer_factory.hpp:77] Creating layer fc7I0313 11:41:39.404500 9249 net.cpp:84] Creating Layer fc7I0313 11:41:39.404503 9249 net.cpp:406] fc7 &lt;- fc6I0313 11:41:39.404506 9249 net.cpp:380] fc7 -&gt; fc7I0313 11:41:39.417629 9249 net.cpp:122] Setting up fc7I0313 11:41:39.417654 9249 net.cpp:129] Top shape: 1 4096 1 64 (262144)I0313 11:41:39.417657 9249 net.cpp:137] Memory required for data: 66531328I0313 11:41:39.417665 9249 layer_factory.hpp:77] Creating layer relu7I0313 11:41:39.417672 9249 net.cpp:84] Creating Layer relu7I0313 11:41:39.417676 9249 net.cpp:406] relu7 &lt;- fc7I0313 11:41:39.417680 9249 net.cpp:367] relu7 -&gt; fc7 (in-place)I0313 11:41:39.417687 9249 net.cpp:122] Setting up relu7I0313 11:41:39.417690 9249 net.cpp:129] Top shape: 1 4096 1 64 (262144)I0313 11:41:39.417693 9249 net.cpp:137] Memory required for data: 67579904I0313 11:41:39.417696 9249 layer_factory.hpp:77] Creating layer drop7I0313 11:41:39.417703 9249 net.cpp:84] Creating Layer drop7I0313 11:41:39.417706 9249 net.cpp:406] drop7 &lt;- fc7I0313 11:41:39.417709 9249 net.cpp:367] drop7 -&gt; fc7 (in-place)I0313 11:41:39.417713 9249 net.cpp:122] Setting up drop7I0313 11:41:39.417716 9249 net.cpp:129] Top shape: 1 4096 1 64 (262144)I0313 11:41:39.417719 9249 net.cpp:137] Memory required for data: 68628480I0313 11:41:39.417721 9249 layer_factory.hpp:77] Creating layer score_frI0313 11:41:39.417727 9249 net.cpp:84] Creating Layer score_frI0313 11:41:39.417729 9249 net.cpp:406] score_fr &lt;- fc7I0313 11:41:39.417734 9249 net.cpp:380] score_fr -&gt; score_frI0313 11:41:39.417858 9249 net.cpp:122] Setting up score_frI0313 11:41:39.417865 9249 net.cpp:129] Top shape: 1 21 1 64 (1344)I0313 11:41:39.417867 9249 net.cpp:137] Memory required for data: 68633856I0313 11:41:39.417871 9249 layer_factory.hpp:77] Creating layer upscoreI0313 11:41:39.417877 9249 net.cpp:84] Creating Layer upscoreI0313 11:41:39.417881 9249 net.cpp:406] upscore &lt;- score_frI0313 11:41:39.417884 9249 net.cpp:380] upscore -&gt; upscoreI0313 11:41:39.419461 9249 net.cpp:122] Setting up upscoreI0313 11:41:39.419472 9249 net.cpp:129] Top shape: 1 21 63 2079 (2750517)I0313 11:41:39.419476 9249 net.cpp:137] Memory required for data: 79635924I0313 11:41:39.419484 9249 layer_factory.hpp:77] Creating layer scoreI0313 11:41:39.419497 9249 net.cpp:84] Creating Layer scoreI0313 11:41:39.419499 9249 net.cpp:406] score &lt;- upscoreI0313 11:41:39.419503 9249 net.cpp:406] score &lt;- data_data_0_split_1I0313 11:41:39.419507 9249 net.cpp:380] score -&gt; scoreI0313 11:41:39.419517 9249 net.cpp:122] Setting up scoreI0313 11:41:39.419539 9249 net.cpp:129] Top shape: 1 21 16 2016 (677376)I0313 11:41:39.419543 9249 net.cpp:137] Memory required for data: 82345428I0313 11:41:39.419544 9249 layer_factory.hpp:77] Creating layer lossI0313 11:41:39.419554 9249 net.cpp:84] Creating Layer lossI0313 11:41:39.419558 9249 net.cpp:406] loss &lt;- scoreI0313 11:41:39.419560 9249 net.cpp:406] loss &lt;- labelI0313 11:41:39.419564 9249 net.cpp:380] loss -&gt; lossI0313 11:41:39.419572 9249 layer_factory.hpp:77] Creating layer lossI0313 11:41:39.420116 9249 net.cpp:122] Setting up lossI0313 11:41:39.420122 9249 net.cpp:129] Top shape: (1)I0313 11:41:39.420125 9249 net.cpp:132] with loss weight 1I0313 11:41:39.420135 9249 net.cpp:137] Memory required for data: 82345432I0313 11:41:39.420137 9249 net.cpp:198] loss needs backward computation.I0313 11:41:39.420140 9249 net.cpp:198] score needs backward computation.I0313 11:41:39.420143 9249 net.cpp:198] upscore needs backward computation.I0313 11:41:39.420145 9249 net.cpp:198] score_fr needs backward computation.I0313 11:41:39.420148 9249 net.cpp:198] drop7 needs backward computation.I0313 11:41:39.420151 9249 net.cpp:198] relu7 needs backward computation.I0313 11:41:39.420155 9249 net.cpp:198] fc7 needs backward computation.I0313 11:41:39.420156 9249 net.cpp:198] drop6 needs backward computation.I0313 11:41:39.420159 9249 net.cpp:198] relu6 needs backward computation.I0313 11:41:39.420161 9249 net.cpp:198] fc6 needs backward computation.I0313 11:41:39.420164 9249 net.cpp:198] pool5 needs backward computation.I0313 11:41:39.420167 9249 net.cpp:198] relu5 needs backward computation.I0313 11:41:39.420169 9249 net.cpp:198] conv5 needs backward computation.I0313 11:41:39.420172 9249 net.cpp:198] relu4 needs backward computation.I0313 11:41:39.420176 9249 net.cpp:198] conv4 needs backward computation.I0313 11:41:39.420177 9249 net.cpp:198] relu3 needs backward computation.I0313 11:41:39.420181 9249 net.cpp:198] conv3 needs backward computation.I0313 11:41:39.420183 9249 net.cpp:198] norm2 needs backward computation.I0313 11:41:39.420186 9249 net.cpp:198] pool2 needs backward computation.I0313 11:41:39.420189 9249 net.cpp:198] relu2 needs backward computation.I0313 11:41:39.420192 9249 net.cpp:198] conv2 needs backward computation.I0313 11:41:39.420194 9249 net.cpp:198] norm1 needs backward computation.I0313 11:41:39.420197 9249 net.cpp:198] pool1 needs backward computation.I0313 11:41:39.420200 9249 net.cpp:198] relu1 needs backward computation.I0313 11:41:39.420203 9249 net.cpp:198] conv1 needs backward computation.I0313 11:41:39.420207 9249 net.cpp:200] data_data_0_split does not need backward computation.I0313 11:41:39.420210 9249 net.cpp:200] data does not need backward computation.I0313 11:41:39.420212 9249 net.cpp:242] This network produces output lossI0313 11:41:39.420224 9249 net.cpp:255] Network initialization done.I0313 11:41:39.420586 9249 solver.cpp:190] Creating test net (#0) specified by test_net file: val.prototxtI0313 11:41:39.420764 9249 net.cpp:51] Initializing net from parameters: state &#123; phase: TEST&#125;layer &#123; name: &quot;data&quot; type: &quot;Python&quot; top: &quot;data&quot; top: &quot;label&quot; python_param &#123; module: &quot;pcl_data_layer&quot; layer: &quot;PCLSegDataLayer&quot; param_str: &quot;&#123;\&apos;pcl_dir\&apos;: \&apos;/home/zzy/CLionProjects/ROS_Project/ws/src/fcn_data_gen/data/npy\&apos;&#125;&quot; &#125;&#125;layer &#123; name: &quot;conv1&quot; type: &quot;Convolution&quot; bottom: &quot;data&quot; top: &quot;conv1&quot; convolution_param &#123; num_output: 96 pad: 100 kernel_size: 11 group: 1 stride: 4 &#125;&#125;layer &#123; name: &quot;relu1&quot; type: &quot;ReLU&quot; bottom: &quot;conv1&quot; top: &quot;conv1&quot;&#125;layer &#123; name: &quot;pool1&quot; type: &quot;Pooling&quot; bottom: &quot;conv1&quot; top: &quot;pool1&quot; pooling_param &#123; pool: MAX kernel_size: 3 stride: 2 &#125;&#125;layer &#123; name: &quot;norm1&quot; type: &quot;LRN&quot; bottom: &quot;pool1&quot; top: &quot;norm1&quot; lrn_param &#123; local_size: 5 alpha: 0.0001 beta: 0.75 &#125;&#125;layer &#123; name: &quot;conv2&quot; type: &quot;Convolution&quot; bottom: &quot;norm1&quot; top: &quot;conv2&quot; convolution_param &#123; num_output: 256 pad: 2 kernel_size: 5 group: 2 stride: 1 &#125;&#125;layer &#123; name: &quot;relu2&quot; type: &quot;ReLU&quot; bottom: &quot;conv2&quot; top: &quot;conv2&quot;&#125;layer &#123; name: &quot;pool2&quot; type: &quot;Pooling&quot; bottom: &quot;conv2&quot; top: &quot;pool2&quot; pooling_param &#123; pool: MAX kernel_size: 3 stride: 2 &#125;&#125;layer &#123; name: &quot;norm2&quot; type: &quot;LRN&quot; bottom: &quot;pool2&quot; top: &quot;norm2&quot; lrn_param &#123; local_size: 5 alpha: 0.0001 beta: 0.75 &#125;&#125;layer &#123; name: &quot;conv3&quot; type: &quot;Convolution&quot; bottom: &quot;norm2&quot; top: &quot;conv3&quot; convolution_param &#123; num_output: 384 pad: 1 kernel_size: 3 group: 1 stride: 1 &#125;&#125;layer &#123; name: &quot;relu3&quot; type: &quot;ReLU&quot; bottom: &quot;conv3&quot; top: &quot;conv3&quot;&#125;layer &#123; name: &quot;conv4&quot; type: &quot;Convolution&quot; bottom: &quot;conv3&quot; top: &quot;conv4&quot; convolution_param &#123; num_output: 384 pad: 1 kernel_size: 3 group: 2 stride: 1 &#125;&#125;layer &#123; name: &quot;relu4&quot; type: &quot;ReLU&quot; bottom: &quot;conv4&quot; top: &quot;conv4&quot;&#125;layer &#123; name: &quot;conv5&quot; type: &quot;Convolution&quot; bottom: &quot;conv4&quot; top: &quot;conv5&quot; convolution_param &#123; num_output: 256 pad: 1 kernel_size: 3 group: 2 stride: 1 &#125;&#125;layer &#123; name: &quot;relu5&quot; type: &quot;ReLU&quot; bottom: &quot;conv5&quot; top: &quot;conv5&quot;&#125;layer &#123; name: &quot;pool5&quot; type: &quot;Pooling&quot; bottom: &quot;conv5&quot; top: &quot;pool5&quot; pooling_param &#123; pool: MAX kernel_size: 3 stride: 2 &#125;&#125;layer &#123; name: &quot;fc6&quot; type: &quot;Convolution&quot; bottom: &quot;pool5&quot; top: &quot;fc6&quot; convolution_param &#123; num_output: 4096 pad: 0 kernel_size: 6 group: 1 stride: 1 &#125;&#125;layer &#123; name: &quot;relu6&quot; type: &quot;ReLU&quot; bottom: &quot;fc6&quot; top: &quot;fc6&quot;&#125;layer &#123; name: &quot;drop6&quot; type: &quot;Dropout&quot; bottom: &quot;fc6&quot; top: &quot;fc6&quot; dropout_param &#123; dropout_ratio: 0.5 &#125;&#125;layer &#123; name: &quot;fc7&quot; type: &quot;Convolution&quot; bottom: &quot;fc6&quot; top: &quot;fc7&quot; convolution_param &#123; num_output: 4096 pad: 0 kernel_size: 1 group: 1 stride: 1 &#125;&#125;layer &#123; name: &quot;relu7&quot; type: &quot;ReLU&quot; bottom: &quot;fc7&quot; top: &quot;fc7&quot;&#125;layer &#123; name: &quot;drop7&quot; type: &quot;Dropout&quot; bottom: &quot;fc7&quot; top: &quot;fc7&quot; dropout_param &#123; dropout_ratio: 0.5 &#125;&#125;layer &#123; name: &quot;score_fr&quot; type: &quot;Convolution&quot; bottom: &quot;fc7&quot; top: &quot;score_fr&quot; param &#123; lr_mult: 1 decay_mult: 1 &#125; param &#123; lr_mult: 2 decay_mult: 0 &#125; convolution_param &#123; num_output: 21 pad: 0 kernel_size: 1 &#125;&#125;layer &#123; name: &quot;upscore&quot; type: &quot;Deconvolution&quot; bottom: &quot;score_fr&quot; top: &quot;upscore&quot; param &#123; lr_mult: 0 &#125; convolution_param &#123; num_output: 21 bias_term: false kernel_size: 63 stride: 32 &#125;&#125;layer &#123; name: &quot;score&quot; type: &quot;Crop&quot; bottom: &quot;upscore&quot; bottom: &quot;data&quot; top: &quot;score&quot; crop_param &#123; axis: 2 offset: 18 &#125;&#125;layer &#123; name: &quot;loss&quot; type: &quot;SoftmaxWithLoss&quot; bottom: &quot;score&quot; bottom: &quot;label&quot; top: &quot;loss&quot; loss_param &#123; ignore_label: 255 normalize: true &#125;&#125;I0313 11:41:39.420830 9249 layer_factory.hpp:77] Creating layer dataI0313 11:41:39.420866 9249 net.cpp:84] Creating Layer dataI0313 11:41:39.420871 9249 net.cpp:380] data -&gt; dataI0313 11:41:39.420877 9249 net.cpp:380] data -&gt; labelI0313 11:41:39.422286 9249 net.cpp:122] Setting up dataI0313 11:41:39.422296 9249 net.cpp:129] Top shape: 1 3 16 2016 (96768)I0313 11:41:39.422299 9249 net.cpp:129] Top shape: 1 16 2016 (32256)I0313 11:41:39.422302 9249 net.cpp:137] Memory required for data: 516096I0313 11:41:39.422305 9249 layer_factory.hpp:77] Creating layer data_data_0_splitI0313 11:41:39.422310 9249 net.cpp:84] Creating Layer data_data_0_splitI0313 11:41:39.422313 9249 net.cpp:406] data_data_0_split &lt;- dataI0313 11:41:39.422317 9249 net.cpp:380] data_data_0_split -&gt; data_data_0_split_0I0313 11:41:39.422322 9249 net.cpp:380] data_data_0_split -&gt; data_data_0_split_1I0313 11:41:39.422327 9249 net.cpp:122] Setting up data_data_0_splitI0313 11:41:39.422332 9249 net.cpp:129] Top shape: 1 3 16 2016 (96768)I0313 11:41:39.422334 9249 net.cpp:129] Top shape: 1 3 16 2016 (96768)I0313 11:41:39.422338 9249 net.cpp:137] Memory required for data: 1290240I0313 11:41:39.422339 9249 layer_factory.hpp:77] Creating layer conv1I0313 11:41:39.422346 9249 net.cpp:84] Creating Layer conv1I0313 11:41:39.422349 9249 net.cpp:406] conv1 &lt;- data_data_0_split_0I0313 11:41:39.422353 9249 net.cpp:380] conv1 -&gt; conv1I0313 11:41:39.422446 9249 net.cpp:122] Setting up conv1I0313 11:41:39.422451 9249 net.cpp:129] Top shape: 1 96 52 552 (2755584)I0313 11:41:39.422454 9249 net.cpp:137] Memory required for data: 12312576I0313 11:41:39.422461 9249 layer_factory.hpp:77] Creating layer relu1I0313 11:41:39.422466 9249 net.cpp:84] Creating Layer relu1I0313 11:41:39.422469 9249 net.cpp:406] relu1 &lt;- conv1I0313 11:41:39.422472 9249 net.cpp:367] relu1 -&gt; conv1 (in-place)I0313 11:41:39.422477 9249 net.cpp:122] Setting up relu1I0313 11:41:39.422479 9249 net.cpp:129] Top shape: 1 96 52 552 (2755584)I0313 11:41:39.422482 9249 net.cpp:137] Memory required for data: 23334912I0313 11:41:39.422484 9249 layer_factory.hpp:77] Creating layer pool1I0313 11:41:39.422488 9249 net.cpp:84] Creating Layer pool1I0313 11:41:39.422490 9249 net.cpp:406] pool1 &lt;- conv1I0313 11:41:39.422495 9249 net.cpp:380] pool1 -&gt; pool1I0313 11:41:39.422502 9249 net.cpp:122] Setting up pool1I0313 11:41:39.422504 9249 net.cpp:129] Top shape: 1 96 26 276 (688896)I0313 11:41:39.422507 9249 net.cpp:137] Memory required for data: 26090496I0313 11:41:39.422508 9249 layer_factory.hpp:77] Creating layer norm1I0313 11:41:39.422513 9249 net.cpp:84] Creating Layer norm1I0313 11:41:39.422516 9249 net.cpp:406] norm1 &lt;- pool1I0313 11:41:39.422519 9249 net.cpp:380] norm1 -&gt; norm1I0313 11:41:39.422524 9249 net.cpp:122] Setting up norm1I0313 11:41:39.422528 9249 net.cpp:129] Top shape: 1 96 26 276 (688896)I0313 11:41:39.422529 9249 net.cpp:137] Memory required for data: 28846080I0313 11:41:39.422531 9249 layer_factory.hpp:77] Creating layer conv2I0313 11:41:39.422536 9249 net.cpp:84] Creating Layer conv2I0313 11:41:39.422539 9249 net.cpp:406] conv2 &lt;- norm1I0313 11:41:39.422543 9249 net.cpp:380] conv2 -&gt; conv2I0313 11:41:39.422933 9249 net.cpp:122] Setting up conv2I0313 11:41:39.422940 9249 net.cpp:129] Top shape: 1 256 26 276 (1837056)I0313 11:41:39.422941 9249 net.cpp:137] Memory required for data: 36194304I0313 11:41:39.422947 9249 layer_factory.hpp:77] Creating layer relu2I0313 11:41:39.422951 9249 net.cpp:84] Creating Layer relu2I0313 11:41:39.422955 9249 net.cpp:406] relu2 &lt;- conv2I0313 11:41:39.422958 9249 net.cpp:367] relu2 -&gt; conv2 (in-place)I0313 11:41:39.422962 9249 net.cpp:122] Setting up relu2I0313 11:41:39.422966 9249 net.cpp:129] Top shape: 1 256 26 276 (1837056)I0313 11:41:39.422967 9249 net.cpp:137] Memory required for data: 43542528I0313 11:41:39.422971 9249 layer_factory.hpp:77] Creating layer pool2I0313 11:41:39.422973 9249 net.cpp:84] Creating Layer pool2I0313 11:41:39.422976 9249 net.cpp:406] pool2 &lt;- conv2I0313 11:41:39.422979 9249 net.cpp:380] pool2 -&gt; pool2I0313 11:41:39.422984 9249 net.cpp:122] Setting up pool2I0313 11:41:39.422988 9249 net.cpp:129] Top shape: 1 256 13 138 (459264)I0313 11:41:39.422991 9249 net.cpp:137] Memory required for data: 45379584I0313 11:41:39.422992 9249 layer_factory.hpp:77] Creating layer norm2I0313 11:41:39.422997 9249 net.cpp:84] Creating Layer norm2I0313 11:41:39.422999 9249 net.cpp:406] norm2 &lt;- pool2I0313 11:41:39.423003 9249 net.cpp:380] norm2 -&gt; norm2I0313 11:41:39.423008 9249 net.cpp:122] Setting up norm2I0313 11:41:39.423012 9249 net.cpp:129] Top shape: 1 256 13 138 (459264)I0313 11:41:39.423013 9249 net.cpp:137] Memory required for data: 47216640I0313 11:41:39.423015 9249 layer_factory.hpp:77] Creating layer conv3I0313 11:41:39.423020 9249 net.cpp:84] Creating Layer conv3I0313 11:41:39.423023 9249 net.cpp:406] conv3 &lt;- norm2I0313 11:41:39.423027 9249 net.cpp:380] conv3 -&gt; conv3I0313 11:41:39.423882 9249 net.cpp:122] Setting up conv3I0313 11:41:39.423888 9249 net.cpp:129] Top shape: 1 384 13 138 (688896)I0313 11:41:39.423892 9249 net.cpp:137] Memory required for data: 49972224I0313 11:41:39.423897 9249 layer_factory.hpp:77] Creating layer relu3I0313 11:41:39.423902 9249 net.cpp:84] Creating Layer relu3I0313 11:41:39.423904 9249 net.cpp:406] relu3 &lt;- conv3I0313 11:41:39.423907 9249 net.cpp:367] relu3 -&gt; conv3 (in-place)I0313 11:41:39.423912 9249 net.cpp:122] Setting up relu3I0313 11:41:39.423914 9249 net.cpp:129] Top shape: 1 384 13 138 (688896)I0313 11:41:39.423918 9249 net.cpp:137] Memory required for data: 52727808I0313 11:41:39.423919 9249 layer_factory.hpp:77] Creating layer conv4I0313 11:41:39.423923 9249 net.cpp:84] Creating Layer conv4I0313 11:41:39.423925 9249 net.cpp:406] conv4 &lt;- conv3I0313 11:41:39.423930 9249 net.cpp:380] conv4 -&gt; conv4I0313 11:41:39.424738 9249 net.cpp:122] Setting up conv4I0313 11:41:39.424744 9249 net.cpp:129] Top shape: 1 384 13 138 (688896)I0313 11:41:39.424747 9249 net.cpp:137] Memory required for data: 55483392I0313 11:41:39.424751 9249 layer_factory.hpp:77] Creating layer relu4I0313 11:41:39.424756 9249 net.cpp:84] Creating Layer relu4I0313 11:41:39.424757 9249 net.cpp:406] relu4 &lt;- conv4I0313 11:41:39.424762 9249 net.cpp:367] relu4 -&gt; conv4 (in-place)I0313 11:41:39.424764 9249 net.cpp:122] Setting up relu4I0313 11:41:39.424767 9249 net.cpp:129] Top shape: 1 384 13 138 (688896)I0313 11:41:39.424770 9249 net.cpp:137] Memory required for data: 58238976I0313 11:41:39.424772 9249 layer_factory.hpp:77] Creating layer conv5I0313 11:41:39.424777 9249 net.cpp:84] Creating Layer conv5I0313 11:41:39.424779 9249 net.cpp:406] conv5 &lt;- conv4I0313 11:41:39.424784 9249 net.cpp:380] conv5 -&gt; conv5I0313 11:41:39.425376 9249 net.cpp:122] Setting up conv5I0313 11:41:39.425384 9249 net.cpp:129] Top shape: 1 256 13 138 (459264)I0313 11:41:39.425385 9249 net.cpp:137] Memory required for data: 60076032I0313 11:41:39.425393 9249 layer_factory.hpp:77] Creating layer relu5I0313 11:41:39.425397 9249 net.cpp:84] Creating Layer relu5I0313 11:41:39.425400 9249 net.cpp:406] relu5 &lt;- conv5I0313 11:41:39.425403 9249 net.cpp:367] relu5 -&gt; conv5 (in-place)I0313 11:41:39.425406 9249 net.cpp:122] Setting up relu5I0313 11:41:39.425410 9249 net.cpp:129] Top shape: 1 256 13 138 (459264)I0313 11:41:39.425412 9249 net.cpp:137] Memory required for data: 61913088I0313 11:41:39.425415 9249 layer_factory.hpp:77] Creating layer pool5I0313 11:41:39.425420 9249 net.cpp:84] Creating Layer pool5I0313 11:41:39.425423 9249 net.cpp:406] pool5 &lt;- conv5I0313 11:41:39.425426 9249 net.cpp:380] pool5 -&gt; pool5I0313 11:41:39.425432 9249 net.cpp:122] Setting up pool5I0313 11:41:39.425436 9249 net.cpp:129] Top shape: 1 256 6 69 (105984)I0313 11:41:39.425437 9249 net.cpp:137] Memory required for data: 62337024I0313 11:41:39.425441 9249 layer_factory.hpp:77] Creating layer fc6I0313 11:41:39.425446 9249 net.cpp:84] Creating Layer fc6I0313 11:41:39.425448 9249 net.cpp:406] fc6 &lt;- pool5I0313 11:41:39.425452 9249 net.cpp:380] fc6 -&gt; fc6I0313 11:41:39.454087 9249 net.cpp:122] Setting up fc6I0313 11:41:39.454115 9249 net.cpp:129] Top shape: 1 4096 1 64 (262144)I0313 11:41:39.454118 9249 net.cpp:137] Memory required for data: 63385600I0313 11:41:39.454126 9249 layer_factory.hpp:77] Creating layer relu6I0313 11:41:39.454134 9249 net.cpp:84] Creating Layer relu6I0313 11:41:39.454138 9249 net.cpp:406] relu6 &lt;- fc6I0313 11:41:39.454143 9249 net.cpp:367] relu6 -&gt; fc6 (in-place)I0313 11:41:39.454149 9249 net.cpp:122] Setting up relu6I0313 11:41:39.454152 9249 net.cpp:129] Top shape: 1 4096 1 64 (262144)I0313 11:41:39.454155 9249 net.cpp:137] Memory required for data: 64434176I0313 11:41:39.454157 9249 layer_factory.hpp:77] Creating layer drop6I0313 11:41:39.454162 9249 net.cpp:84] Creating Layer drop6I0313 11:41:39.454165 9249 net.cpp:406] drop6 &lt;- fc6I0313 11:41:39.454169 9249 net.cpp:367] drop6 -&gt; fc6 (in-place)I0313 11:41:39.454174 9249 net.cpp:122] Setting up drop6I0313 11:41:39.454177 9249 net.cpp:129] Top shape: 1 4096 1 64 (262144)I0313 11:41:39.454180 9249 net.cpp:137] Memory required for data: 65482752I0313 11:41:39.454182 9249 layer_factory.hpp:77] Creating layer fc7I0313 11:41:39.454188 9249 net.cpp:84] Creating Layer fc7I0313 11:41:39.454190 9249 net.cpp:406] fc7 &lt;- fc6I0313 11:41:39.454195 9249 net.cpp:380] fc7 -&gt; fc7I0313 11:41:39.467375 9249 net.cpp:122] Setting up fc7I0313 11:41:39.467401 9249 net.cpp:129] Top shape: 1 4096 1 64 (262144)I0313 11:41:39.467403 9249 net.cpp:137] Memory required for data: 66531328I0313 11:41:39.467411 9249 layer_factory.hpp:77] Creating layer relu7I0313 11:41:39.467418 9249 net.cpp:84] Creating Layer relu7I0313 11:41:39.467422 9249 net.cpp:406] relu7 &lt;- fc7I0313 11:41:39.467427 9249 net.cpp:367] relu7 -&gt; fc7 (in-place)I0313 11:41:39.467433 9249 net.cpp:122] Setting up relu7I0313 11:41:39.467437 9249 net.cpp:129] Top shape: 1 4096 1 64 (262144)I0313 11:41:39.467439 9249 net.cpp:137] Memory required for data: 67579904I0313 11:41:39.467442 9249 layer_factory.hpp:77] Creating layer drop7I0313 11:41:39.467449 9249 net.cpp:84] Creating Layer drop7I0313 11:41:39.467452 9249 net.cpp:406] drop7 &lt;- fc7I0313 11:41:39.467455 9249 net.cpp:367] drop7 -&gt; fc7 (in-place)I0313 11:41:39.467460 9249 net.cpp:122] Setting up drop7I0313 11:41:39.467463 9249 net.cpp:129] Top shape: 1 4096 1 64 (262144)I0313 11:41:39.467465 9249 net.cpp:137] Memory required for data: 68628480I0313 11:41:39.467468 9249 layer_factory.hpp:77] Creating layer score_frI0313 11:41:39.467474 9249 net.cpp:84] Creating Layer score_frI0313 11:41:39.467476 9249 net.cpp:406] score_fr &lt;- fc7I0313 11:41:39.467481 9249 net.cpp:380] score_fr -&gt; score_frI0313 11:41:39.467617 9249 net.cpp:122] Setting up score_frI0313 11:41:39.467622 9249 net.cpp:129] Top shape: 1 21 1 64 (1344)I0313 11:41:39.467624 9249 net.cpp:137] Memory required for data: 68633856I0313 11:41:39.467629 9249 layer_factory.hpp:77] Creating layer upscoreI0313 11:41:39.467635 9249 net.cpp:84] Creating Layer upscoreI0313 11:41:39.467638 9249 net.cpp:406] upscore &lt;- score_frI0313 11:41:39.467643 9249 net.cpp:380] upscore -&gt; upscoreI0313 11:41:39.469235 9249 net.cpp:122] Setting up upscoreI0313 11:41:39.469246 9249 net.cpp:129] Top shape: 1 21 63 2079 (2750517)I0313 11:41:39.469249 9249 net.cpp:137] Memory required for data: 79635924I0313 11:41:39.469259 9249 layer_factory.hpp:77] Creating layer scoreI0313 11:41:39.469266 9249 net.cpp:84] Creating Layer scoreI0313 11:41:39.469269 9249 net.cpp:406] score &lt;- upscoreI0313 11:41:39.469272 9249 net.cpp:406] score &lt;- data_data_0_split_1I0313 11:41:39.469276 9249 net.cpp:380] score -&gt; scoreI0313 11:41:39.469285 9249 net.cpp:122] Setting up scoreI0313 11:41:39.469288 9249 net.cpp:129] Top shape: 1 21 16 2016 (677376)I0313 11:41:39.469290 9249 net.cpp:137] Memory required for data: 82345428I0313 11:41:39.469293 9249 layer_factory.hpp:77] Creating layer lossI0313 11:41:39.469300 9249 net.cpp:84] Creating Layer lossI0313 11:41:39.469301 9249 net.cpp:406] loss &lt;- scoreI0313 11:41:39.469305 9249 net.cpp:406] loss &lt;- labelI0313 11:41:39.469308 9249 net.cpp:380] loss -&gt; lossI0313 11:41:39.469314 9249 layer_factory.hpp:77] Creating layer lossI0313 11:41:39.469894 9249 net.cpp:122] Setting up lossI0313 11:41:39.469900 9249 net.cpp:129] Top shape: (1)I0313 11:41:39.469903 9249 net.cpp:132] with loss weight 1I0313 11:41:39.469913 9249 net.cpp:137] Memory required for data: 82345432I0313 11:41:39.469915 9249 net.cpp:198] loss needs backward computation.I0313 11:41:39.469918 9249 net.cpp:198] score needs backward computation.I0313 11:41:39.469920 9249 net.cpp:198] upscore needs backward computation.I0313 11:41:39.469923 9249 net.cpp:198] score_fr needs backward computation.I0313 11:41:39.469926 9249 net.cpp:198] drop7 needs backward computation.I0313 11:41:39.469929 9249 net.cpp:198] relu7 needs backward computation.I0313 11:41:39.469931 9249 net.cpp:198] fc7 needs backward computation.I0313 11:41:39.469934 9249 net.cpp:198] drop6 needs backward computation.I0313 11:41:39.469936 9249 net.cpp:198] relu6 needs backward computation.I0313 11:41:39.469939 9249 net.cpp:198] fc6 needs backward computation.I0313 11:41:39.469943 9249 net.cpp:198] pool5 needs backward computation.I0313 11:41:39.469945 9249 net.cpp:198] relu5 needs backward computation.I0313 11:41:39.469947 9249 net.cpp:198] conv5 needs backward computation.I0313 11:41:39.469950 9249 net.cpp:198] relu4 needs backward computation.I0313 11:41:39.469952 9249 net.cpp:198] conv4 needs backward computation.I0313 11:41:39.469955 9249 net.cpp:198] relu3 needs backward computation.I0313 11:41:39.469957 9249 net.cpp:198] conv3 needs backward computation.I0313 11:41:39.469960 9249 net.cpp:198] norm2 needs backward computation.I0313 11:41:39.469964 9249 net.cpp:198] pool2 needs backward computation.I0313 11:41:39.469965 9249 net.cpp:198] relu2 needs backward computation.I0313 11:41:39.469969 9249 net.cpp:198] conv2 needs backward computation.I0313 11:41:39.469971 9249 net.cpp:198] norm1 needs backward computation.I0313 11:41:39.469974 9249 net.cpp:198] pool1 needs backward computation.I0313 11:41:39.469979 9249 net.cpp:198] relu1 needs backward computation.I0313 11:41:39.469981 9249 net.cpp:198] conv1 needs backward computation.I0313 11:41:39.469985 9249 net.cpp:200] data_data_0_split does not need backward computation.I0313 11:41:39.469987 9249 net.cpp:200] data does not need backward computation.I0313 11:41:39.469990 9249 net.cpp:242] This network produces output lossI0313 11:41:39.470001 9249 net.cpp:255] Network initialization done.I0313 11:41:39.470055 9249 solver.cpp:57] Solver scaffolding done.I0313 11:42:40.745103 9249 solver.cpp:239] Iteration 0 (-1.4013e-45 iter/s, 61.136s/20 iters), loss = 4.54161I0313 11:42:40.745129 9249 solver.cpp:258] Train net output #0: loss = 4.00278 (* 1 = 4.00278 loss)I0313 11:42:40.745136 9249 sgd_solver.cpp:112] Iteration 0, lr = 0.0001I0313 12:02:52.273387 9249 solver.cpp:239] Iteration 20 (0.0165081 iter/s, 1211.53s/20 iters), loss = 17.0233I0313 12:02:52.273416 9249 solver.cpp:258] Train net output #0: loss = 19.2508 (* 1 = 19.2508 loss)I0313 12:02:52.273422 9249 sgd_solver.cpp:112] Iteration 20, lr = 0.0001I0313 12:23:09.810516 9249 solver.cpp:239] Iteration 40 (0.0164266 iter/s, 1217.54s/20 iters), loss = 26.7316I0313 12:23:09.810544 9249 solver.cpp:258] Train net output #0: loss = 30.1355 (* 1 = 30.1355 loss)I0313 12:23:09.810550 9249 sgd_solver.cpp:112] Iteration 40, lr = 0.0001I0313 12:43:32.716285 9249 solver.cpp:239] Iteration 60 (0.0163545 iter/s, 1222.91s/20 iters), loss = 30.2106I0313 12:43:32.716313 9249 solver.cpp:258] Train net output #0: loss = 22.8696 (* 1 = 22.8696 loss)I0313 12:43:32.716320 9249 sgd_solver.cpp:112] Iteration 60, lr = 0.0001I0313 13:03:49.434516 9249 solver.cpp:239] Iteration 80 (0.0164377 iter/s, 1216.72s/20 iters), loss = 31.0818I0313 13:03:49.434543 9249 solver.cpp:258] Train net output #0: loss = 23.1428 (* 1 = 23.1428 loss)I0313 13:03:49.434551 9249 sgd_solver.cpp:112] Iteration 80, lr = 0.0001I0313 13:23:51.860294 9249 solver.cpp:239] Iteration 100 (0.0166331 iter/s, 1202.43s/20 iters), loss = 32.5238I0313 13:23:51.860322 9249 solver.cpp:258] Train net output #0: loss = 35.1909 (* 1 = 35.1909 loss)I0313 13:23:51.860328 9249 sgd_solver.cpp:112] Iteration 100, lr = 0.0001I0313 13:43:38.481149 9249 solver.cpp:239] Iteration 120 (0.0168546 iter/s, 1186.62s/20 iters), loss = 33.0024I0313 13:43:38.481176 9249 solver.cpp:258] Train net output #0: loss = 40.9104 (* 1 = 40.9104 loss)I0313 13:43:38.481182 9249 sgd_solver.cpp:112] Iteration 120, lr = 0.0001I0313 14:03:27.667078 9249 solver.cpp:239] Iteration 140 (0.0168182 iter/s, 1189.19s/20 iters), loss = 36.4908I0313 14:03:27.667104 9249 solver.cpp:258] Train net output #0: loss = 53.9975 (* 1 = 53.9975 loss)I0313 14:03:27.667111 9249 sgd_solver.cpp:112] Iteration 140, lr = 0.0001I0313 14:23:25.009404 9249 solver.cpp:239] Iteration 160 (0.0167037 iter/s, 1197.34s/20 iters), loss = 52.2285I0313 14:23:25.009431 9249 solver.cpp:258] Train net output #0: loss = 26.9314 (* 1 = 26.9314 loss)I0313 14:23:25.009438 9249 sgd_solver.cpp:112] Iteration 160, lr = 0.0001I0313 14:43:35.026921 9249 solver.cpp:239] Iteration 180 (0.0165287 iter/s, 1210.02s/20 iters), loss = 33.087I0313 14:43:35.026950 9249 solver.cpp:258] Train net output #0: loss = 44.6887 (* 1 = 44.6887 loss)I0313 14:43:35.026957 9249 sgd_solver.cpp:112] Iteration 180, lr = 0.0001I0313 15:03:45.718956 9249 solver.cpp:239] Iteration 200 (0.0165195 iter/s, 1210.69s/20 iters), loss = 33.0793I0313 15:03:45.718984 9249 solver.cpp:258] Train net output #0: loss = 34.2235 (* 1 = 34.2235 loss)I0313 15:03:45.718991 9249 sgd_solver.cpp:112] Iteration 200, lr = 0.0001I0313 15:24:27.503715 9249 solver.cpp:239] Iteration 220 (0.0161059 iter/s, 1241.78s/20 iters), loss = 33.1698I0313 15:24:27.503741 9249 solver.cpp:258] Train net output #0: loss = 45.0323 (* 1 = 45.0323 loss)I0313 15:24:27.503748 9249 sgd_solver.cpp:112] Iteration 220, lr = 0.0001I0313 15:44:53.585564 9249 solver.cpp:239] Iteration 240 (0.0163121 iter/s, 1226.08s/20 iters), loss = 35.7697I0313 15:44:53.585592 9249 solver.cpp:258] Train net output #0: loss = 45.5302 (* 1 = 45.5302 loss)I0313 15:44:53.585598 9249 sgd_solver.cpp:112] Iteration 240, lr = 0.0001I0313 16:04:44.744935 9249 solver.cpp:239] Iteration 260 (0.0167904 iter/s, 1191.16s/20 iters), loss = 29.4003I0313 16:04:44.744963 9249 solver.cpp:258] Train net output #0: loss = 19.9242 (* 1 = 19.9242 loss)I0313 16:04:44.744969 9249 sgd_solver.cpp:112] Iteration 260, lr = 0.0001I0313 16:24:00.216655 9249 solver.cpp:239] Iteration 280 (0.017309 iter/s, 1155.47s/20 iters), loss = 24.0391I0313 16:24:00.216681 9249 solver.cpp:258] Train net output #0: loss = 35.6398 (* 1 = 35.6398 loss)I0313 16:24:00.216687 9249 sgd_solver.cpp:112] Iteration 280, lr = 0.0001I0313 16:43:22.672458 9249 solver.cpp:239] Iteration 300 (0.017205 iter/s, 1162.45s/20 iters), loss = 33.2369I0313 16:43:22.672485 9249 solver.cpp:258] Train net output #0: loss = 38.8301 (* 1 = 38.8301 loss)I0313 16:43:22.672492 9249 sgd_solver.cpp:112] Iteration 300, lr = 0.0001I0313 17:02:56.876072 9249 solver.cpp:239] Iteration 320 (0.0170328 iter/s, 1174.2s/20 iters), loss = 33.7243I0313 17:02:56.876101 9249 solver.cpp:258] Train net output #0: loss = 33.6585 (* 1 = 33.6585 loss)I0313 17:02:56.876106 9249 sgd_solver.cpp:112] Iteration 320, lr = 0.0001 可以看到在未更改其他网络参数的情况下，loss居高不下，本文着重与对Data layer的理解，下一篇文章将对网络结构内部进行优化，以达到点云数据loss达到预期的目标。 参考文献： FCN学习:Semantic Segmentation AlexNet]]></content>
      <categories>
        <category>DL</category>
      </categories>
      <tags>
        <tag>PCL</tag>
        <tag>DL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[c++ string 操作汇总]]></title>
    <url>%2F2018%2F03%2F15%2F18_3_15%2Fcpp_string_operation%2F</url>
    <content type="text"><![CDATA[前言 作为传递信息的载体string数据类型广泛应用于各种编程语言中，尤其在轻量化语言 Python 中发挥的淋漓尽致，通过string传递信息 Python 使各个模块组装在一起完成指定的工作任务，这也是 Python 被称为“胶水语言”的原因。本文着眼于 c++ 中string的应用。首先建议先浏览string在线文档，这其中包含了大多数日常所需函数。 正文1. string 内查找字符串strstd::string::find(str)函数：http://www.cplusplus.com/reference/string/string/find/Example 1234567891011121314151617181920212223242526272829303132// string::find#include &lt;iostream&gt; // std::cout#include &lt;string&gt; // std::stringint main ()&#123; std::string str (&quot;There are two needles in this haystack with needles.&quot;); std::string str2 (&quot;needle&quot;); // different member versions of find in the same order as above: std::size_t found = str.find(str2); if (found!=std::string::npos) std::cout &lt;&lt; &quot;first &apos;needle&apos; found at: &quot; &lt;&lt; found &lt;&lt; &apos;\n&apos;; found=str.find(&quot;needles are small&quot;,found+1,6); if (found!=std::string::npos) std::cout &lt;&lt; &quot;second &apos;needle&apos; found at: &quot; &lt;&lt; found &lt;&lt; &apos;\n&apos;; found=str.find(&quot;haystack&quot;); if (found!=std::string::npos) std::cout &lt;&lt; &quot;&apos;haystack&apos; also found at: &quot; &lt;&lt; found &lt;&lt; &apos;\n&apos;; found=str.find(&apos;.&apos;); if (found!=std::string::npos) std::cout &lt;&lt; &quot;Period found at: &quot; &lt;&lt; found &lt;&lt; &apos;\n&apos;; // let&apos;s replace the first needle: str.replace(str.find(str2),str2.length(),&quot;preposition&quot;); std::cout &lt;&lt; str &lt;&lt; &apos;\n&apos;; return 0;&#125; 其中 npos 值为 -1，用于判断。其他查找功能类函数： rfind： 找到目标str最后一次出现位置 find_first_of： 从起始位置查找目标str find_last_of： 从结束位置往回查找目标str 2. string内删除目标str substr： 本质还是查找目标strExample 12345678910111213141516171819// string::substr#include &lt;iostream&gt;#include &lt;string&gt;int main ()&#123; std::string str=&quot;We think in generalities, but we live in details.&quot;; // (quoting Alfred N. Whitehead) std::string str2 = str.substr (3,5); // &quot;think&quot; std::size_t pos = str.find(&quot;live&quot;); // position of &quot;live&quot; in str std::string str3 = str.substr (pos); // get from &quot;live&quot; to the end std::cout &lt;&lt; str2 &lt;&lt; &apos; &apos; &lt;&lt; str3 &lt;&lt; &apos;\n&apos;; return 0;&#125; 3. 字符串分割字符串分割推荐使用 std::stringstream 作为中间载体和 getline() 函数组合来完成。以分割字符 “ ; ”为例：12345678910void splitPathStr(std::string&amp; path_str)&#123; std::vector&lt;std::string&gt; filelists; std::stringstream sstr( path_str ); std::string token; while(getline(sstr, token, &apos;;&apos;)) &#123; filelists.push_back(token); &#125;&#125; 4. int型与string型互相转换int型转string型 123456void int2str(const int &amp;int_temp,string &amp;string_temp) &#123; stringstream stream; stream&lt;&lt;int_temp; string_temp=stream.str(); //此处也可以用 stream&gt;&gt;string_temp &#125; string型转int型12345void str2int(int &amp;int_temp,const string &amp;string_temp) &#123; stringstream stream(string_temp); stream&gt;&gt;int_temp; &#125; 未完待续… 以上。 参考文献： c++ reference C++中int、string等常见类型转换]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cnpy 库使用笔记]]></title>
    <url>%2F2018%2F03%2F15%2F18_3_15%2Fcnpy_note%2F</url>
    <content type="text"><![CDATA[欢迎访问我的个人博客：zengzeyu.com 前言 在进行网络训练过程中，在生成训练数据时，一般会使用比较底层的传感器来生成数据，如摄像头或雷达，所以大部分使用C++进行开发。为了将数据转为Numpy Array格式供Python调用，cnpy库就是供C++生成这种格式数据的开源库，由国外一名小哥开发。cnpy地址：https://github.com/rogersce/cnpy官方例子：https://github.com/rogersce/cnpy/blob/master/example1.cpp 应用方法 cnpy有两种应用方法： 官网方法：将cnpy库加入到ubuntu系统环境中，当做系统库进行调用，类似于安装好的OpenCV库； ROS package 方法：将cnpy库包含到ROS工作空间下，当做独立的package供调用。 方法1： 按照官网安装教程安装即可： Installation:Default installation directory is /usr/local. To specify a different directory, add -DCMAKE_INSTALL_PREFIX=/path/to/install/dir to the cmake invocation in step 4.1234561. get [cmake](https://github.com/rogersce/cnpy/blob/master/www.cmake.org)2. create a build directory, say $HOME/build3. cd $HOME/build4. cmake /path/to/cnpy5. make6. make install Using:To use, #include&quot;cnpy.h&quot; in your source code. Compile the source code mycode.cpp as1g++ -o mycode mycode.cpp -L/path/to/install/dir -lcnpy -lz --std=c++11 方法2： 将下载好的cnpy文件夹放到与调用cnpy库的 package A 同级目录下，并将以下内容添加到A的package.xml中： 12&lt;build_depend&gt;cnpy&lt;/build_depend&gt; &lt;run_depend&gt;cnpy&lt;/run_depend&gt; 然后以下内容添加到 A 的Cmakelist.txt中： 12345find_package( cnpy )catkin_package( CATKIN_DEPENDS cnpy ) 在 A 中调用的xx.h中按照路径包含即可： 1#include &quot;../../../cnpy/include/cnpy/cnpy.h&quot; 此方法也适用于任何其他想要调用的package，按照上书步骤操作即可。 以上。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>NumPy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[KITTI 原始bin格式数据集转PCD格式]]></title>
    <url>%2F2018%2F03%2F15%2F18_3_15%2Fkitti_bin_to_pcd%2F</url>
    <content type="text"><![CDATA[前言 官网数据集说明：http://www.cvlibs.net/datasets/kitti/raw_data.php数据集详细说明论文：http://www.cvlibs.net/publications/Geiger2013IJRR.pdfKITTI的激光雷达型号为 Velodyne HDL-64E ，具体信息如下：123456789Velodyne HDL-64E rotating 3D laser scanner- 10 Hz- 64 beams- 0.09 degree angular resolution- 2 cm distanceaccuracy- collecting∼1.3 million points/second- field of view: 360°- horizontal, 26.8°- vertical, range: 120 m 针对激光雷达点云数据集使用的信息在 KITTI_README.TXT 中有详细说明，文件下载地址：Code to use the KITTI data set with PCL123456789101112131415161718192021222324252627282930313233343536373839Velodyne 3D laser scan data===========================The velodyne point clouds are stored in the folder &apos;velodyne_points&apos;. Tosave space, all scans have been stored as Nx4 float matrix into a binaryfile using the following code: stream = fopen (dst_file.c_str(),&quot;wb&quot;); fwrite(data,sizeof(float),4*num,stream); fclose(stream);Here, data contains 4*num values, where the first 3 values correspond tox,y and z, and the last value is the reflectance information. All scansare stored row-aligned, meaning that the first 4 values correspond to thefirst measurement. Since each scan might potentially have a differentnumber of points, this must be determined from the file size when readingthe file, where 1e6 is a good enough upper bound on the number of values: // allocate 4 MB buffer (only ~130*4*4 KB are needed) int32_t num = 1000000; float *data = (float*)malloc(num*sizeof(float)); // pointers float *px = data+0; float *py = data+1; float *pz = data+2; float *pr = data+3; // load point cloud FILE *stream; stream = fopen (currFilenameBinary.c_str(),&quot;rb&quot;); num = fread(data,sizeof(float),num,stream)/4; for (int32_t i=0; i&lt;num; i++) &#123; point_cloud.points.push_back(tPoint(*px,*py,*pz,*pr)); px+=4; py+=4; pz+=4; pr+=4; &#125; fclose(stream);x,y and y are stored in metric (m) Velodyne coordinates. KITTI点云数据集读取与转换 官方源代码解读Code to use the KITTI data set with PCL下载的源代码文件夹中的src/kitti2pcd.cpp 中这个函数：12345678910111213141516171819202122232425262728void readKittiPclBinData(std::string &amp;in_file, std::string&amp; out_file)&#123; // load point cloud std::fstream input(in_file.c_str(), std::ios::in | std::ios::binary); if(!input.good())&#123; std::cerr &lt;&lt; &quot;Could not read file: &quot; &lt;&lt; in_file &lt;&lt; std::endl; exit(EXIT_FAILURE); &#125; input.seekg(0, std::ios::beg); pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr points (new pcl::PointCloud&lt;pcl::PointXYZI&gt;); int i; for (i=0; input.good() &amp;&amp; !input.eof(); i++) &#123; pcl::PointXYZI point; input.read((char *) &amp;point.x, 3*sizeof(float)); input.read((char *) &amp;point.intensity, sizeof(float)); points-&gt;push_back(point); &#125; input.close();// g_cloud_pub.publish( points ); std::cout &lt;&lt; &quot;Read KTTI point cloud with &quot; &lt;&lt; i &lt;&lt; &quot; points, writing to &quot; &lt;&lt; out_file &lt;&lt; std::endl; pcl::PCDWriter writer; // Save DoN features writer.write&lt; pcl::PointXYZI &gt; (out_file, *points, false);&#125; 这个函数是最重要的从 KITTI 中读取 .bin 文件转 .pcd 文件。 可运行完整代码下面贴本人完整代码，代码功能： 读取文件夹下.bin 文件 按照文件名进行排序（虽然默认已经排好序） 转为.pcd 文件，并保存 发送到 rviz 进行显示（可选）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394//// Created by zzy on 3/14/18.//#include &lt;ctime&gt;#include &quot;ros/ros.h&quot;#include &quot;fcn_data_gen/ground_remove.h&quot;static ros::Publisher g_cloud_pub;static std::vector&lt;std::string&gt; file_lists;void read_filelists(const std::string&amp; dir_path,std::vector&lt;std::string&gt;&amp; out_filelsits,std::string type)&#123; struct dirent *ptr; DIR *dir; dir = opendir(dir_path.c_str()); out_filelsits.clear(); while ((ptr = readdir(dir)) != NULL)&#123; std::string tmp_file = ptr-&gt;d_name; if (tmp_file[0] == &apos;.&apos;)continue; if (type.size() &lt;= 0)&#123; out_filelsits.push_back(ptr-&gt;d_name); &#125;else&#123; if (tmp_file.size() &lt; type.size())continue; std::string tmp_cut_type = tmp_file.substr(tmp_file.size() - type.size(),type.size()); if (tmp_cut_type == type)&#123; out_filelsits.push_back(ptr-&gt;d_name); &#125; &#125; &#125;&#125;bool computePairNum(std::string pair1,std::string pair2)&#123; return pair1 &lt; pair2;&#125;void sort_filelists(std::vector&lt;std::string&gt;&amp; filists,std::string type)&#123; if (filists.empty())return; std::sort(filists.begin(),filists.end(),computePairNum);&#125;void readKittiPclBinData(std::string &amp;in_file, std::string&amp; out_file)&#123; // load point cloud std::fstream input(in_file.c_str(), std::ios::in | std::ios::binary); if(!input.good())&#123; std::cerr &lt;&lt; &quot;Could not read file: &quot; &lt;&lt; in_file &lt;&lt; std::endl; exit(EXIT_FAILURE); &#125; input.seekg(0, std::ios::beg); pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr points (new pcl::PointCloud&lt;pcl::PointXYZI&gt;); int i; for (i=0; input.good() &amp;&amp; !input.eof(); i++) &#123; pcl::PointXYZI point; input.read((char *) &amp;point.x, 3*sizeof(float)); input.read((char *) &amp;point.intensity, sizeof(float)); points-&gt;push_back(point); &#125; input.close();// g_cloud_pub.publish( points ); std::cout &lt;&lt; &quot;Read KTTI point cloud with &quot; &lt;&lt; i &lt;&lt; &quot; points, writing to &quot; &lt;&lt; out_file &lt;&lt; std::endl; pcl::PCDWriter writer; // Save DoN features writer.write&lt; pcl::PointXYZI &gt; (out_file, *points, false);&#125;int main(int argc, char **argv)&#123;// ros::init(argc, argv, &quot;ground_remove_test&quot;);// ros::NodeHandle n;// g_cloud_pub = n.advertise&lt; pcl::PointCloud&lt; pcl::PointXYZI &gt; &gt; (&quot;point_chatter&quot;, 1); std::string bin_path = &quot;../velodyne/binary/&quot;; std::string pcd_path = &quot;../velodyne/pcd/&quot;; read_filelists( bin_path, file_lists, &quot;bin&quot; ); sort_filelists( file_lists, &quot;bin&quot; ); for (int i = 0; i &lt; file_lists.size(); ++i) &#123; std::string bin_file = bin_path + file_lists[i]; std::string tmp_str = file_lists[i].substr(0, file_lists[i].length() - 4) + &quot;.pcd&quot;; std::string pcd_file = pcd_path + tmp_str; readKittiPclBinData( bin_file, pcd_file ); &#125; return 0;&#125; 以上。]]></content>
      <categories>
        <category>ROS</category>
      </categories>
      <tags>
        <tag>ROS</tag>
        <tag>PCL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ROS Node 之间通信打断操作实例]]></title>
    <url>%2F2018%2F03%2F08%2F18_3_08%2FROS_Node%E4%B9%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E6%89%93%E6%96%AD%E6%93%8D%E4%BD%9C%E5%AE%9E%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[前言公司开发小工具，对文件夹下点云PCD文件进行读取和相应操作，目标功能： 读取文件夹下PCD文件，按照文件名进行排序； 通过Qt开发UI界面，界面包括操作按钮： continue: 循环播放PCD文件并发布 next，pre： 后一帧或前一帧PCD文件 save index： 保存当前帧PCD文件名到.txt文件 当continue操作正在进行时，点击其余按钮，实现打断停止功能 分析 将UI界面和实际后台操作分开进行多线程操作，否则在进行continue过程中时，无法通过外部改变判断条件进行打断； ROS的一个Node默认为是一个进程，所以采用double Node实现多线程； ROS的单个Node可以同时实现subscribe和publish多个消息。本文假设UI界面为Node 1，包括：读取PCD文件，对点击操作进行反应并发送按钮消息到后端；后台实现为Node 2，包括：按钮消息的实现代码。 UI界面 Node 2关键代码由于ROSNode之间特殊的通信机制，如果将条件判断机制放在Node 2的子函数中，那么Node 2在接收Node 1的消息时，如果continue操作正在进行，则必须当continue执行完毕之后再收到Node 1的消息。所以，必须将判断条件房子ROS的Master部分，通过Master对Node 1当前消息进行反应，可实时打断Node 2正在进行的continue操作，马上进行当前消息的操作。以下是Node 2中的main函数的ROS循环部分代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455enum recv_sign &#123; none_sign = 0, stop_sign = 1, continue_sign = 2, load_sign = 3 &#125;;while(ros::ok()) &#123; if( g_con_signal == continue_sign ) &#123; if ( g_cur_index &lt; g_pcd_filelist.size() - 1 ) &#123; publishPCD(); g_cur_index++; &#125; else g_cur_index = 0; &#125; else if ( g_con_signal == stop_sign ) &#123; if ( g_pcd_info == &quot;pre_pcd_signal&quot; ) &#123; if ( g_cur_index &gt; 0 ) &#123; g_cur_index--; publishPCD(); &#125; else std::cerr &lt;&lt; &quot;Reach 1st file!!&quot; &lt;&lt; std::endl; &#125; else if ( g_pcd_info == &quot;next_pcd_signal&quot; ) &#123; if ( g_cur_index &lt; g_pcd_filelist.size() - 1 ) g_cur_index ++; else g_cur_index = 0; publishPCD(); &#125; else if ( g_pcd_info == &quot;save_index&quot; ) &#123; g_outfile &lt;&lt; g_pcd_filelist[g_cur_index] &lt;&lt; std::endl; &#125; g_con_signal = none_sign; &#125; else if ( g_con_signal == load_sign ) &#123; g_file_root_path = g_pcd_info; std::cout &lt;&lt; g_file_root_path &lt;&lt; std::endl; read_filelists( g_file_root_path + &quot;/&quot;, g_pcd_filelist, &quot;.pcd&quot; ); for (int i = 0; i &lt; g_pcd_filelist.size(); ++i) &#123; std::cout &lt;&lt; g_pcd_filelist[i] &lt;&lt; std::endl; &#125; g_con_signal = none_sign; &#125; ros::spinOnce(); &#125; 代码说明： Node 1同时发送2个std_msgs::String：g_con_signal用于控制是否执行循环条件；g_pcd_info用于在不执行continue操作时进行细分操作划分，包括：save index操作的文件路径和loadPCD文件时文件路径。 g_con_signal可以取4个值：enum recv_sign { none_sign = 0, stop_sign = 1, continue_sign = 2, load_sign = 3 };，分别对应不同操作，其中none_sign用于执行除continue操作之外的跳出当前循环，达到只需执行一次的目的，防止陷入死循环（无线循环）。 ros::spinOnce()用于刷新ROS执行条件，每次进入while(ros::ok())循环时，就会内部条件进行判断。 后续：Node 2当前帧文件名返回给Node 1用于显示于UI界面功能尚待加入。 以上。]]></content>
      <categories>
        <category>ROS</category>
      </categories>
      <tags>
        <tag>ROS</tag>
        <tag>PCL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Caffe源代码学习 — AlexNet(Caffenet.py)]]></title>
    <url>%2F2018%2F03%2F08%2F18_3_08%2FCaffe%E6%BA%90%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0%E4%B9%8BAlexNet_Caffenet_py%2F</url>
    <content type="text"><![CDATA[导言源码位置：caffe/examples/pycaffe/caffenet.py该文件源代码是经典模型AlexNet的Caffe实现，有兴趣的小伙伴去拜读一下论文: ImageNet Classification with Deep Convolutional Neural Networks.pdf). 源码解读1. 导入模块123from __future__ import print_functionfrom caffe import layers as L, params as P, to_protofrom caffe.proto import caffe_pb2 2. 定义Layer函数包括： 卷积层（Convolution Layer）、全连接层（Full Connected Layer）和池化层（Pooling Layer） 2.1 卷积层（Convolution Layer）函数1234def conv_relu(bottom, ks, nout, stride=1, pad=0, group=1): conv = L.Convolution(bottom, kernel_size=ks, stride=stride, num_output=nout, pad=pad, group=group) return conv, L.ReLU(conv, in_place=True) 1. 函数输入 bottom - 输入节点（blob）名 ks - 卷积核尺寸（kernel size） nout - 输出深度尺寸（number output） stride - 卷积核滑窗距离 pad - 图像边缘添加尺寸，即在图像周围一周添加尺寸为pad的空白像素 group - 将数据进行分开训练堆数目 2. 调用Caffe卷基层生成函数 conv = L.Convolution(bottom, kernel_size=ks, stride=stride,num_output=nout, pad=pad, group=group) 3. 返回参数 conv - 卷积层配置 L.ReLU(conv, in_place=True) - 卷积后的数据经过ReLU激活函数得到的数据 2.2 全连接层（Full Connected Layer）123def fc_relu(bottom, nout): fc = L.InnerProduct(bottom, num_output=nout) return fc, L.ReLU(fc, in_place=True) 1. 调用Caffe内积函数 fc = L.InnerProduct(bottom, num_output=nout) 2. 返回参数 fc, L.ReLU(fc, in_place=True) - 全连接分类之后数据通过ReLU函数 2.3 池化层（Pooling Layer）12def max_pool(bottom, ks, stride=1): return L.Pooling(bottom, pool=P.Pooling.MAX, kernel_size=ks, stride=stride) 调用Caffe池化层生成函数 L.Pooling)（） pool=P.Pooling.MAX - 池化类型选择MAX，即取模板内最大值输出 3. 定义网络结构1234567891011121314151617181920212223242526data, label = L.Data(source=lmdb, backend=P.Data.LMDB, batch_size=batch_size, ntop=2, transform_param=dict(crop_size=227, mean_value=[104, 117, 123], mirror=True)) # the net itself conv1, relu1 = conv_relu(data, 11, 96, stride=4) pool1 = max_pool(relu1, 3, stride=2) norm1 = L.LRN(pool1, local_size=5, alpha=1e-4, beta=0.75) conv2, relu2 = conv_relu(norm1, 5, 256, pad=2, group=2) pool2 = max_pool(relu2, 3, stride=2) norm2 = L.LRN(pool2, local_size=5, alpha=1e-4, beta=0.75) conv3, relu3 = conv_relu(norm2, 3, 384, pad=1) conv4, relu4 = conv_relu(relu3, 3, 384, pad=1, group=2) conv5, relu5 = conv_relu(relu4, 3, 256, pad=1, group=2) pool5 = max_pool(relu5, 3, stride=2) fc6, relu6 = fc_relu(pool5, 4096) drop6 = L.Dropout(relu6, in_place=True) fc7, relu7 = fc_relu(drop6, 4096) drop7 = L.Dropout(relu7, in_place=True) fc8 = L.InnerProduct(drop7, num_output=1000) loss = L.SoftmaxWithLoss(fc8, label) if include_acc: acc = L.Accuracy(fc8, label) return to_proto(loss, acc) else: return to_proto(loss) 1. 函数输入 lmdb - 文件名 batch_size - 每次训练输入样本数目 include_acc - 加速？ 2. 调用Caffe数据层输入函数（Data）L.Data(source=lmdb, backend=P.Data.LMDB, batch_size=batch_size, ntop=2, transform_param=dict(crop_size=227, mean_value=[104, 117, 123], mirror=True)) backend - 数据类型 ntop - 输出blob数目，因为数据层处理数据输出data和label，所以值为 2 transform_param - 对单个图片处理： crop_size图片剪裁大小，mean_valueRGB图像需要减去的值（目的是更好突出特征）和mirror镜像处理。 3. 网络结构此博客绘制了AlexNet网络结构图和数据流动图，方便直观理解网络结构，可移步：深度学习之图像分类模型AlexNet解读第1-5层为卷积层，如下表所示：| Layer | Operation | Output || :—- | :————————————— | :——————————-: || Data | crop_size:227, mean_value: [104, 117, 123], mirror: true | data: 227x227x3; label: 227x227x1 || 1 | conv1 -&gt; relu1 -&gt; pool1 -&gt; norm1 | 27x27x96 || 2 | conv2 -&gt; relu2 -&gt; pool2 -&gt; norm2 | 13x13x256 || 3 | conv3 -&gt; relu3 | 11x11x384 || 4 | conv4 -&gt; relu4 | 11x11x384 || 5 | conv5 -&gt; relu5 -&gt; pool5 | 6x6x256 || 6 | fc6 -&gt; relu6 -&gt; drop6 | 4096 || 7 | fc7 -&gt; relu7 -&gt; drop7 | 4096 || 8 | fc8 -&gt; loss | 1000 | 以第1层代码为例进行分析: 第1层 = 卷积层（conv1+relu1） + 池化层（pool1） + 归一化（norm1） （1）. 第1层 - 卷积层（conv1+relu1）作用：提取局部特征，使用ReLU作为CNN的激活函数，并验证其效果在较深的网络超过了Sigmoid，成功解决了Sigmoid在网络较深时的梯度弥散问题。conv1, relu1 = conv_relu(data, 11, 96, stride=4) 数据：数据层输出data数据 卷积核大小： 11 输出节点深度： 96 滑窗距离： 4 （2）. 第1层 - 池化层（pool1）作用：提取最大值，避免平均池化的模糊化效果。在AlexNet中提出让步长比池化核的尺寸小，这样池化层的输出之间会有重叠和覆盖，提升了特征的丰富性。pool1 = max_pool(relu1, 3, stride=2) 数据： relu1 模板核大小： 3 滑窗距离： 2 （3）. 第1层 - 局部响应归一化（Local Response Normalize）（norm1）作用：对局部神经元的活动创建竞争机制，使得其中响应比较大的值变得相对更大，并抑制其他反馈较小的神经元，增强了模型的泛化能力norm1 = L.LRN(pool1, local_size=5, alpha=1e-4, beta=0.75) 数据： pool1 取值模板尺寸： 5 alpha: 0.0001 beta: 0.75 4. 输出网络结构文件（.prototxt）123456def make_net(): with open(&apos;train.prototxt&apos;, &apos;w&apos;) as f: print(caffenet(&apos;/path/to/caffe-train-lmdb&apos;), file=f) with open(&apos;test.prototxt&apos;, &apos;w&apos;) as f: print(caffenet(&apos;/path/to/caffe-val-lmdb&apos;, batch_size=50, include_acc=True), file=f) 5. 运行12if __name__ == &apos;__main__&apos;: make_net() 总结Caffene.py是入门Caffe较好的源代码，结合原论文看，同时能加深对网络结构的理解，补充理论知识。下面根据这个example形式构建自己的网络结构，其中第一步，也是学习深度学习最重要的一步，编写自己的数据类型接口层程序。 以上。 附： AlexNet网络总结 深度学习之图像分类模型AlexNet解读]]></content>
      <categories>
        <category>Caffe</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DL</tag>
        <tag>Caffe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NumPy学习笔记]]></title>
    <url>%2F2018%2F03%2F08%2F18_3_08%2FNumpy%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[新建Numpy结构型数据： 12345import numpy as np student = np.dtype([(&apos;name&apos;,&apos;S20&apos;), (&apos;age&apos;,np.int8), (&apos;marks&apos;, np.float4)]) a = np.array([(&apos;abc&apos;, 21, 50),(&apos;xyz&apos;, 18, 75)], dtype = student) print a#输出[(&apos;abc&apos;, 21, 50.0), (&apos;xyz&apos;, 18, 75.0)] 其中，string类型数据用S20表示（20可更改），其余数据类型如np.int8和np.float4均有内建数据表示。 Numpy数组属性：调整数组大小12345678import numpy as np a = np.array([[1,2,3],[4,5,6]]) b = a.reshape(3,2) print b#输出[[1, 2] [3, 4] [5, 6]] 三维数组1234567891011121314151617# 一维数组 import numpy as np a = np.arange(24) a.ndim # 现在调整其大小# 2*4*3： 2个二维数组，每个数组大小4*3b = a.reshape(2,4,3) print b #输出# b 现在拥有三个维度[[[ 0, 1, 2] [ 3, 4, 5] [ 6, 7, 8] [ 9, 10, 11]] [[12, 13, 14] [15, 16, 17] [18, 19, 20] [21, 22, 23]]] Numpy 来自现有数据的数组12345678# 将列表转换为 ndarray import numpy as np x = [1,2,3] a = np.asarray(x) print a#输出[1 2 3] 12345678# 来自元组的 ndarray import numpy as np x = (1,2,3) a = np.asarray(x) print a#输出[1 2 3] Numpy-frombuffer123456import numpy as np s = &apos;Hello World&apos; a = np.frombuffer(s, dtype = &apos;S1&apos;) print a#输出[&apos;H&apos; &apos;e&apos; &apos;l&apos; &apos;l&apos; &apos;o&apos; &apos; &apos; &apos;W&apos; &apos;o&apos; &apos;r&apos; &apos;l&apos; &apos;d&apos;] Numpy-切片和索引基本切片是 Python 中基本切片概念到 n 维的扩展。 通过将start，stop和step参数提供给内置的slice函数来构造一个 Python slice对象。 此slice对象被传递给数组来提取数组的一部分。123456import numpy as npa = np.arange(10)s = slice(2,7,1) # 2返回值为2的索引，7返回值为7的索引，1为步长print a[s]#输出[2 3 4 5 6] 在上面的例子中，ndarray对象由arange()函数创建。 然后，分别用起始，终止和步长值2，7和2定义切片对象。 当这个切片对象传递给ndarray时，会对它的一部分进行切片，从索引2到7，步长为2。 NumPy - 数组上的迭代12345678910111213141516import numpy as npa = np.arange(0,60,5) a = a.reshape(3,4) print &apos;原始数组是：&apos; print a print &apos;\n&apos; print &apos;修改后的数组是：&apos; for x in np.nditer(a): print x#输出原始数组是：[[ 0 5 10 15] [20 25 30 35] [40 45 50 55]]修改后的数组是：0 5 10 15 20 25 30 35 40 45 50 55 注意：迭代的顺序匹配数组的内容布局，而不考虑特定的排序。 这可以通过迭代上述数组的转置来看到。1234567891011121314151617181920212223import numpy as np a = np.arange(0,60,5) a = a.reshape(3,4) print &apos;原始数组是：&apos; print a print &apos;\n&apos; print &apos;原始数组的转置是：&apos; b = a.Tprint bprint &apos;\n&apos; print &apos;修改后的数组是：&apos; for x in np.nditer(b): print x,#输出原始数组是： [[ 0 5 10 15] [20 25 30 35] [40 45 50 55]] 原始数组的转置是： [[ 0 20 40] [ 5 25 45] [10 30 50] [15 35 55]] 修改后的数组是： 0 5 10 15 20 25 30 35 40 45 50 55 numpy.ndarray.flatten 该函数返回折叠为一维的数组副本，函数接受下列参数：1ndarray.flatten(order) 其中： order：C – 按行，F– 按列，A – 原顺序，k – 元素在内存中的出现顺序。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开篇2017]]></title>
    <url>%2F2017%2F06%2F26%2F%E5%BC%80%E7%AF%872017%2F</url>
    <content type="text"><![CDATA[欢迎来到我的个人博客，此博客将用作记录自己的一些技术上的问题和解决方法，借助这一个平台，希望给自己一个记录，让自己多年以后回过头来看看自己也曾经少年过，哈哈！]]></content>
      <tags>
        <tag>MarkDown Writting</tag>
        <tag>Personal</tag>
      </tags>
  </entry>
</search>